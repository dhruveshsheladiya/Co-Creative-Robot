{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "#parser = English()\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "example='''\n",
    "That this House notes the announcement of 300 redundancies at the Nestlé manufacturing factories in York, Fawdon, Halifax and Girvan and that production of the Blue Riband bar will be transferred to Poland; acknowledges in the first three months of 2017 Nestlé achieved £21 billion in sales, a 0.4 per cent increase over the same period in 2016; further notes 156 of these job losses will be in York, a city that in the last six months has seen 2,000 job losses announced and has become the most inequitable city outside of the South East, and a further 110 jobs from Fawdon, Newcastle; recognises the losses come within a month of triggering Article 50, and as negotiations with the EU on the UK leaving the EU and the UK's future with the EU are commencing; further recognises the cost of importing products, including sugar, cocoa and production machinery, has risen due to the weakness of the pound and the uncertainty over the UK's future relationship with the single market and customs union; and calls on the Government to intervene and work with hon. Members, trades unions GMB and Unite and the company to avert these job losses now and prevent further job losses across Nestlé.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities(example, show=True):\n",
    "    if show: print(example)\n",
    "    #parsedEx = parser(example)\n",
    " \n",
    "    print(\"-------------- entities only ---------------\")\n",
    "    # if you just want the entities and nothing else, you can do access the parsed examples \"ents\" property like this:\n",
    "    doc = nlp(example)\n",
    "    ents=doc.ents\n",
    "    print(ents)\n",
    "    tags={}\n",
    "    for entity in ents:\n",
    "        #print(entity.label, entity.label_, ' '.join(t.orth_ for t in entity))\n",
    "        term=' '.join(t.orth_ for t in entity)\n",
    "        if ' '.join(term) not in tags:\n",
    "            tags[term]=[(entity.label, entity.label_)]\n",
    "        else:\n",
    "            tags[term].append((entity.label, entity.label_))\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "That this House notes the announcement of 300 redundancies at the Nestlé manufacturing factories in York, Fawdon, Halifax and Girvan and that production of the Blue Riband bar will be transferred to Poland; acknowledges in the first three months of 2017 Nestlé achieved £21 billion in sales, a 0.4 per cent increase over the same period in 2016; further notes 156 of these job losses will be in York, a city that in the last six months has seen 2,000 job losses announced and has become the most inequitable city outside of the South East, and a further 110 jobs from Fawdon, Newcastle; recognises the losses come within a month of triggering Article 50, and as negotiations with the EU on the UK leaving the EU and the UK's future with the EU are commencing; further recognises the cost of importing products, including sugar, cocoa and production machinery, has risen due to the weakness of the pound and the uncertainty over the UK's future relationship with the single market and customs union; and calls on the Government to intervene and work with hon. Members, trades unions GMB and Unite and the company to avert these job losses now and prevent further job losses across Nestlé.\n",
      "-------------- entities only ---------------\n",
      "(\n",
      ", House, 300, Nestlé, York, Fawdon, Halifax, Girvan, Poland, the first three months of 2017, £21 billion, 0.4 per cent, the same period in, 2016, 156, York, the last six months, 2,000, the South East, 110, Fawdon, Newcastle, a month, Article 50, EU, UK, EU, UK, EU, UK, GMB, Nestlé)\n",
      "{'\\n': [(382, 'GPE')], 'House': [(381, 'ORG')], '300': [(394, 'CARDINAL')], 'Nestlé': [(378, 'PERSON')], 'York': [(382, 'GPE')], 'Fawdon': [(382, 'GPE')], 'Halifax': [(378, 'PERSON')], 'Girvan': [(378, 'PERSON')], 'Poland': [(382, 'GPE')], 'the first three months of 2017': [(388, 'DATE')], '£ 21 billion': [(391, 'MONEY')], '0.4 per cent': [(391, 'MONEY')], 'the same period in': [(388, 'DATE')], '2016': [(388, 'DATE')], '156': [(394, 'CARDINAL')], 'the last six months': [(388, 'DATE')], '2,000': [(394, 'CARDINAL')], 'the South East': [(383, 'LOC')], '110': [(394, 'CARDINAL')], 'Newcastle': [(382, 'GPE')], 'a month': [(388, 'DATE')], 'Article 50': [(448, 'LAW')], 'EU': [(381, 'ORG')], 'UK': [(382, 'GPE')], 'GMB': [(378, 'PERSON')]}\n"
     ]
    }
   ],
   "source": [
    "entities(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob Smith was in the Houses of Parliament the other day\n",
      "-------------- entities only ---------------\n",
      "(Bob Smith, the Houses of Parliament, the other day)\n",
      "{'Bob Smith': [(378, 'PERSON')], 'the Houses of Parliament': [(381, 'ORG')], 'the other day': [(388, 'DATE')]}\n"
     ]
    }
   ],
   "source": [
    "q= \"Bob Smith was in the Houses of Parliament the other day\"\n",
    "entities(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Stanford NER</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "java_path = \"C:/Program Files/Java/jdk1.8.0_151/bin\"\n",
    "os.environ['JAVA_HOME'] = java_path\n",
    "#import nltk\n",
    "#nltk.internals.config_java(\"C:/Program Files/Java/jdk1.6.0_30/bin/java.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use nltk.tag.corenlp.CoreNLPPOSTagger or nltk.tag.corenlp.CoreNLPNERTagger instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tree', 'O'), ('is', 'O'), ('near', 'O'), ('the', 'O'), ('house', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('E:/stanford-ner-2018-02-27/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "  'E:/stanford-ner-2018-02-27/stanford-ner.jar',encoding='utf-8')\n",
    "\n",
    "text = 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.'\n",
    "k = \"Tree is near the house\"\n",
    "\n",
    "tokenized_text = word_tokenize(k)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Let's Code</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using Standford NER for named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Get all category names in quick draw dataset</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_file = open(\"categories.txt\", \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lis = category_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aircraft carrier',\n",
       " 'airplane',\n",
       " 'alarm clock',\n",
       " 'ambulance',\n",
       " 'angel',\n",
       " 'animal migration',\n",
       " 'ant',\n",
       " 'anvil',\n",
       " 'apple',\n",
       " 'arm',\n",
       " 'asparagus',\n",
       " 'axe',\n",
       " 'backpack',\n",
       " 'banana',\n",
       " 'bandage',\n",
       " 'barn',\n",
       " 'baseball',\n",
       " 'baseball bat',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bat',\n",
       " 'bathtub',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'bed',\n",
       " 'bee',\n",
       " 'belt',\n",
       " 'bench',\n",
       " 'bicycle',\n",
       " 'binoculars',\n",
       " 'bird',\n",
       " 'birthday cake',\n",
       " 'blackberry',\n",
       " 'blueberry',\n",
       " 'book',\n",
       " 'boomerang',\n",
       " 'bottlecap',\n",
       " 'bowtie',\n",
       " 'bracelet',\n",
       " 'brain',\n",
       " 'bread',\n",
       " 'bridge',\n",
       " 'broccoli',\n",
       " 'broom',\n",
       " 'bucket',\n",
       " 'bulldozer',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'butterfly',\n",
       " 'cactus',\n",
       " 'cake',\n",
       " 'calculator',\n",
       " 'calendar',\n",
       " 'camel',\n",
       " 'camera',\n",
       " 'camouflage',\n",
       " 'campfire',\n",
       " 'candle',\n",
       " 'cannon',\n",
       " 'canoe',\n",
       " 'car',\n",
       " 'carrot',\n",
       " 'castle',\n",
       " 'cat',\n",
       " 'ceiling fan',\n",
       " 'cello',\n",
       " 'cell phone',\n",
       " 'chair',\n",
       " 'chandelier',\n",
       " 'church',\n",
       " 'circle',\n",
       " 'clarinet',\n",
       " 'clock',\n",
       " 'cloud',\n",
       " 'coffee cup',\n",
       " 'compass',\n",
       " 'computer',\n",
       " 'cookie',\n",
       " 'cooler',\n",
       " 'couch',\n",
       " 'cow',\n",
       " 'crab',\n",
       " 'crayon',\n",
       " 'crocodile',\n",
       " 'crown',\n",
       " 'cruise ship',\n",
       " 'cup',\n",
       " 'diamond',\n",
       " 'dishwasher',\n",
       " 'diving board',\n",
       " 'dog',\n",
       " 'dolphin',\n",
       " 'donut',\n",
       " 'door',\n",
       " 'dragon',\n",
       " 'dresser',\n",
       " 'drill',\n",
       " 'drums',\n",
       " 'duck',\n",
       " 'dumbbell',\n",
       " 'ear',\n",
       " 'elbow',\n",
       " 'elephant',\n",
       " 'envelope',\n",
       " 'eraser',\n",
       " 'eye',\n",
       " 'eyeglasses',\n",
       " 'face',\n",
       " 'fan',\n",
       " 'feather',\n",
       " 'fence',\n",
       " 'finger',\n",
       " 'fire hydrant',\n",
       " 'fireplace',\n",
       " 'firetruck',\n",
       " 'fish',\n",
       " 'flamingo',\n",
       " 'flashlight',\n",
       " 'flip flops',\n",
       " 'floor lamp',\n",
       " 'flower',\n",
       " 'flying saucer',\n",
       " 'foot',\n",
       " 'fork',\n",
       " 'frog',\n",
       " 'frying pan',\n",
       " 'garden',\n",
       " 'garden hose',\n",
       " 'giraffe',\n",
       " 'goatee',\n",
       " 'golf club',\n",
       " 'grapes',\n",
       " 'grass',\n",
       " 'guitar',\n",
       " 'hamburger',\n",
       " 'hammer',\n",
       " 'hand',\n",
       " 'harp',\n",
       " 'hat',\n",
       " 'headphones',\n",
       " 'hedgehog',\n",
       " 'helicopter',\n",
       " 'helmet',\n",
       " 'hexagon',\n",
       " 'hockey puck',\n",
       " 'hockey stick',\n",
       " 'horse',\n",
       " 'hospital',\n",
       " 'hot air balloon',\n",
       " 'hot dog',\n",
       " 'hot tub',\n",
       " 'hourglass',\n",
       " 'house',\n",
       " 'house plant',\n",
       " 'hurricane',\n",
       " 'ice cream',\n",
       " 'jacket',\n",
       " 'jail',\n",
       " 'kangaroo',\n",
       " 'key',\n",
       " 'keyboard',\n",
       " 'knee',\n",
       " 'knife',\n",
       " 'ladder',\n",
       " 'lantern',\n",
       " 'laptop',\n",
       " 'leaf',\n",
       " 'leg',\n",
       " 'light bulb',\n",
       " 'lighter',\n",
       " 'lighthouse',\n",
       " 'lightning',\n",
       " 'line',\n",
       " 'lion',\n",
       " 'lipstick',\n",
       " 'lobster',\n",
       " 'lollipop',\n",
       " 'mailbox',\n",
       " 'map',\n",
       " 'marker',\n",
       " 'matches',\n",
       " 'megaphone',\n",
       " 'mermaid',\n",
       " 'microphone',\n",
       " 'microwave',\n",
       " 'monkey',\n",
       " 'moon',\n",
       " 'mosquito',\n",
       " 'motorbike',\n",
       " 'mountain',\n",
       " 'mouse',\n",
       " 'moustache',\n",
       " 'mouth',\n",
       " 'mug',\n",
       " 'mushroom',\n",
       " 'nail',\n",
       " 'necklace',\n",
       " 'nose',\n",
       " 'ocean',\n",
       " 'octagon',\n",
       " 'octopus',\n",
       " 'onion',\n",
       " 'oven',\n",
       " 'owl',\n",
       " 'paintbrush',\n",
       " 'paint can',\n",
       " 'palm tree',\n",
       " 'panda',\n",
       " 'pants',\n",
       " 'paper clip',\n",
       " 'parachute',\n",
       " 'parrot',\n",
       " 'passport',\n",
       " 'peanut',\n",
       " 'pear',\n",
       " 'peas',\n",
       " 'pencil',\n",
       " 'penguin',\n",
       " 'piano',\n",
       " 'pickup truck',\n",
       " 'picture frame',\n",
       " 'pig',\n",
       " 'pillow',\n",
       " 'pineapple',\n",
       " 'pizza',\n",
       " 'pliers',\n",
       " 'police car',\n",
       " 'pond',\n",
       " 'pool',\n",
       " 'popsicle',\n",
       " 'postcard',\n",
       " 'potato',\n",
       " 'power outlet',\n",
       " 'purse',\n",
       " 'rabbit',\n",
       " 'raccoon',\n",
       " 'radio',\n",
       " 'rain',\n",
       " 'rainbow',\n",
       " 'rake',\n",
       " 'remote control',\n",
       " 'rhinoceros',\n",
       " 'rifle',\n",
       " 'river',\n",
       " 'roller coaster',\n",
       " 'rollerskates',\n",
       " 'sailboat',\n",
       " 'sandwich',\n",
       " 'saw',\n",
       " 'saxophone',\n",
       " 'school bus',\n",
       " 'scissors',\n",
       " 'scorpion',\n",
       " 'screwdriver',\n",
       " 'sea turtle',\n",
       " 'see saw',\n",
       " 'shark',\n",
       " 'sheep',\n",
       " 'shoe',\n",
       " 'shorts',\n",
       " 'shovel',\n",
       " 'sink',\n",
       " 'skateboard',\n",
       " 'skull',\n",
       " 'skyscraper',\n",
       " 'sleeping bag',\n",
       " 'smiley face',\n",
       " 'snail',\n",
       " 'snake',\n",
       " 'snorkel',\n",
       " 'snowflake',\n",
       " 'snowman',\n",
       " 'soccer ball',\n",
       " 'sock',\n",
       " 'speedboat',\n",
       " 'spider',\n",
       " 'spoon',\n",
       " 'spreadsheet',\n",
       " 'square',\n",
       " 'squiggle',\n",
       " 'squirrel',\n",
       " 'stairs',\n",
       " 'star',\n",
       " 'steak',\n",
       " 'stereo',\n",
       " 'stethoscope',\n",
       " 'stitches',\n",
       " 'stop sign',\n",
       " 'stove',\n",
       " 'strawberry',\n",
       " 'streetlight',\n",
       " 'string bean',\n",
       " 'submarine',\n",
       " 'suitcase',\n",
       " 'sun',\n",
       " 'swan',\n",
       " 'sweater',\n",
       " 'swing set',\n",
       " 'sword',\n",
       " 'syringe',\n",
       " 'table',\n",
       " 'teapot',\n",
       " 'teddy-bear',\n",
       " 'telephone',\n",
       " 'television',\n",
       " 'tennis racquet',\n",
       " 'tent',\n",
       " 'The Eiffel Tower',\n",
       " 'The Great Wall of China',\n",
       " 'The Mona Lisa',\n",
       " 'tiger',\n",
       " 'toaster',\n",
       " 'toe',\n",
       " 'toilet',\n",
       " 'tooth',\n",
       " 'toothbrush',\n",
       " 'toothpaste',\n",
       " 'tornado',\n",
       " 'tractor',\n",
       " 'traffic light',\n",
       " 'train',\n",
       " 'tree',\n",
       " 'triangle',\n",
       " 'trombone',\n",
       " 'truck',\n",
       " 'trumpet',\n",
       " 't-shirt',\n",
       " 'umbrella',\n",
       " 'underwear',\n",
       " 'van',\n",
       " 'vase',\n",
       " 'violin',\n",
       " 'washing machine',\n",
       " 'watermelon',\n",
       " 'waterslide',\n",
       " 'whale',\n",
       " 'wheel',\n",
       " 'windmill',\n",
       " 'wine bottle',\n",
       " 'wine glass',\n",
       " 'wristwatch',\n",
       " 'yoga',\n",
       " 'zebra',\n",
       " 'zigzag',\n",
       " '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"WoW!!!! I love cats and dogs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'love', 'cats', 'dogs']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ear', 86)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "process.extractOne('near', category_lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('always', DeprecationWarning)\n",
    "\n",
    "def extract_entities(text):\n",
    "    \n",
    "    st = StanfordNERTagger('E:/stanford-ner-2018-02-27/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                           'E:/stanford-ner-2018-02-27/stanford-ner.jar',encoding='utf-8')\n",
    "    #tokenized_text = word_tokenize(text)\n",
    "    \n",
    "    classified_text = st.tag(text)\n",
    "    return classified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=\"cats and dogs, I love them\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=preprocess_text(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use nltk.tag.corenlp.CoreNLPPOSTagger or nltk.tag.corenlp.CoreNLPNERTagger instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('always', DeprecationWarning)\n",
    "extracted_lis=extract_entities(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 'O'), ('dogs', 'O'), ('love', 'O')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_lis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Load google pretrained word2vec model to match sementic similarity of the category list and the text descriptions</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293122426257508"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('trees','tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "def match_entities_with_dataset(text,category_lis):\n",
    "    word_lis=preprocess_text(text)\n",
    "    word_lis=extract_entities(word_lis)\n",
    "    temp=[]\n",
    "    for k in word_lis:\n",
    "      t = difflib.get_close_matches(k[0], category_lis,1)\n",
    "      if (t):\n",
    "            if((t[0] in model.vocab) and (k[0] in model.vocab)and(model.similarity(k[0],t[0])>0.80)):\n",
    "                \n",
    "                temp.append(t[0])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tree', 'house']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_entities_with_dataset('trees near my House',category_lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Let us use mcTest dataset to get the narrative text description</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df=pd.read_csv('mc500_train.csv', sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('mc500_train.csv', sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc500.train.0</td>\n",
       "      <td>Author: 2778399758;Work Time(s): 839;Qual. sco...</td>\n",
       "      <td>Alyssa got to the beach after a long trip. She...</td>\n",
       "      <td>one: What city is Alyssa in?</td>\n",
       "      <td>trip</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>beach</td>\n",
       "      <td>one: Why did Alyssa go to Miami?</td>\n",
       "      <td>swim</td>\n",
       "      <td>...</td>\n",
       "      <td>multiple: How many friends does Alyssa have?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>multiple: What did Alyssa eat at the restaurant?</td>\n",
       "      <td>steak</td>\n",
       "      <td>soup</td>\n",
       "      <td>salad</td>\n",
       "      <td>catfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mc500.train.1</td>\n",
       "      <td>Author: 3208685851;Work Time(s): 836;Qual. sco...</td>\n",
       "      <td>One morning, Elena woke up, much like she did ...</td>\n",
       "      <td>multiple: What is the very first thing Elena d...</td>\n",
       "      <td>she says hello to the tree</td>\n",
       "      <td>she throws the covers on the floor</td>\n",
       "      <td>she says hello to the sun</td>\n",
       "      <td>she gets out of bed</td>\n",
       "      <td>one: At what time of day does this story take ...</td>\n",
       "      <td>Before the tree</td>\n",
       "      <td>...</td>\n",
       "      <td>multiple: What happened to Mr. Fish in the end?</td>\n",
       "      <td>He got put back in the bowl, but he was dead</td>\n",
       "      <td>He started swimming around in Elena's hand</td>\n",
       "      <td>He got put in a new bowl</td>\n",
       "      <td>He got put back in his bowl and started swimmi...</td>\n",
       "      <td>multiple: What was missing from the fish bowl?</td>\n",
       "      <td>the rocks</td>\n",
       "      <td>Mr. Fish</td>\n",
       "      <td>the water</td>\n",
       "      <td>the tiny castle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mc500.train.2</td>\n",
       "      <td>Author: 3165469218;Work Time(s): 1546;Qual. sc...</td>\n",
       "      <td>Billy was like a king on the school yard. A ki...</td>\n",
       "      <td>multiple: Billy was like a...</td>\n",
       "      <td>prince</td>\n",
       "      <td>dummy</td>\n",
       "      <td>queen</td>\n",
       "      <td>king</td>\n",
       "      <td>multiple: Who was Billy?</td>\n",
       "      <td>The skinny kid</td>\n",
       "      <td>...</td>\n",
       "      <td>one: What did the boy grab from his home?</td>\n",
       "      <td>a rock</td>\n",
       "      <td>a bench</td>\n",
       "      <td>a tree</td>\n",
       "      <td>Fishing line</td>\n",
       "      <td>one: What did the boy call Billy?</td>\n",
       "      <td>A dork</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>Mr.Stupid Kid</td>\n",
       "      <td>A bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mc500.train.3</td>\n",
       "      <td>Author: 3323630398;Work Time(s): 712;Qual. sco...</td>\n",
       "      <td>Billy went to the farm to buy some beef for hi...</td>\n",
       "      <td>one: What did Billy buy at the farm?</td>\n",
       "      <td>Beef</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>Cows</td>\n",
       "      <td>Fence</td>\n",
       "      <td>multiple: What color were the spots on the cows?</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>multiple: How many chickens were on the purple...</td>\n",
       "      <td>Ten</td>\n",
       "      <td>Six</td>\n",
       "      <td>Five</td>\n",
       "      <td>Four</td>\n",
       "      <td>one: How did Billy's brother feel after dinner?</td>\n",
       "      <td>Strange</td>\n",
       "      <td>Scared</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mc500.train.4</td>\n",
       "      <td>Author: 646501657;Work Time(s): 743;Qual. scor...</td>\n",
       "      <td>The road to Grandpa's house was long and windi...</td>\n",
       "      <td>multiple: Why did Grandpa answer the door?</td>\n",
       "      <td>Because he saw the insects</td>\n",
       "      <td>Because Jimmy was walking</td>\n",
       "      <td>Because Jimmy knocked</td>\n",
       "      <td>Because the trip took a long time</td>\n",
       "      <td>one: Where do Jimmy and his Grandpa sit?</td>\n",
       "      <td>On insects</td>\n",
       "      <td>...</td>\n",
       "      <td>multiple: What was Jimmy's favorite insect in ...</td>\n",
       "      <td>Beetle</td>\n",
       "      <td>Lady bug</td>\n",
       "      <td>Moth</td>\n",
       "      <td>Lightning bug</td>\n",
       "      <td>one: Why doesn't Jimmy collect more moths?</td>\n",
       "      <td>They're difficult to catch and they take up a ...</td>\n",
       "      <td>They're his favorite</td>\n",
       "      <td>He doesn't like them</td>\n",
       "      <td>Grandpa doesn't like them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1   \\\n",
       "0  mc500.train.0  Author: 2778399758;Work Time(s): 839;Qual. sco...   \n",
       "1  mc500.train.1  Author: 3208685851;Work Time(s): 836;Qual. sco...   \n",
       "2  mc500.train.2  Author: 3165469218;Work Time(s): 1546;Qual. sc...   \n",
       "3  mc500.train.3  Author: 3323630398;Work Time(s): 712;Qual. sco...   \n",
       "4  mc500.train.4  Author: 646501657;Work Time(s): 743;Qual. scor...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  Alyssa got to the beach after a long trip. She...   \n",
       "1  One morning, Elena woke up, much like she did ...   \n",
       "2  Billy was like a king on the school yard. A ki...   \n",
       "3  Billy went to the farm to buy some beef for hi...   \n",
       "4  The road to Grandpa's house was long and windi...   \n",
       "\n",
       "                                                  3   \\\n",
       "0                       one: What city is Alyssa in?   \n",
       "1  multiple: What is the very first thing Elena d...   \n",
       "2                      multiple: Billy was like a...   \n",
       "3               one: What did Billy buy at the farm?   \n",
       "4         multiple: Why did Grandpa answer the door?   \n",
       "\n",
       "                           4                                   5   \\\n",
       "0                        trip                               Miami   \n",
       "1  she says hello to the tree  she throws the covers on the floor   \n",
       "2                      prince                               dummy   \n",
       "3                        Beef                             Chicken   \n",
       "4  Because he saw the insects           Because Jimmy was walking   \n",
       "\n",
       "                          6                                  7   \\\n",
       "0                    Atlanta                              beach   \n",
       "1  she says hello to the sun                she gets out of bed   \n",
       "2                      queen                               king   \n",
       "3                       Cows                              Fence   \n",
       "4      Because Jimmy knocked  Because the trip took a long time   \n",
       "\n",
       "                                                  8                9   \\\n",
       "0                   one: Why did Alyssa go to Miami?             swim   \n",
       "1  one: At what time of day does this story take ...  Before the tree   \n",
       "2                           multiple: Who was Billy?   The skinny kid   \n",
       "3   multiple: What color were the spots on the cows?             Blue   \n",
       "4           one: Where do Jimmy and his Grandpa sit?       On insects   \n",
       "\n",
       "             ...              \\\n",
       "0            ...               \n",
       "1            ...               \n",
       "2            ...               \n",
       "3            ...               \n",
       "4            ...               \n",
       "\n",
       "                                                  13  \\\n",
       "0       multiple: How many friends does Alyssa have?   \n",
       "1    multiple: What happened to Mr. Fish in the end?   \n",
       "2          one: What did the boy grab from his home?   \n",
       "3  multiple: How many chickens were on the purple...   \n",
       "4  multiple: What was Jimmy's favorite insect in ...   \n",
       "\n",
       "                                             14  \\\n",
       "0                                             1   \n",
       "1  He got put back in the bowl, but he was dead   \n",
       "2                                        a rock   \n",
       "3                                           Ten   \n",
       "4                                        Beetle   \n",
       "\n",
       "                                           15                        16  \\\n",
       "0                                           2                         3   \n",
       "1  He started swimming around in Elena's hand  He got put in a new bowl   \n",
       "2                                     a bench                    a tree   \n",
       "3                                         Six                      Five   \n",
       "4                                    Lady bug                      Moth   \n",
       "\n",
       "                                                  17  \\\n",
       "0                                                  4   \n",
       "1  He got put back in his bowl and started swimmi...   \n",
       "2                                       Fishing line   \n",
       "3                                               Four   \n",
       "4                                      Lightning bug   \n",
       "\n",
       "                                                 18  \\\n",
       "0  multiple: What did Alyssa eat at the restaurant?   \n",
       "1    multiple: What was missing from the fish bowl?   \n",
       "2                 one: What did the boy call Billy?   \n",
       "3   one: How did Billy's brother feel after dinner?   \n",
       "4        one: Why doesn't Jimmy collect more moths?   \n",
       "\n",
       "                                                  19                    20  \\\n",
       "0                                              steak                  soup   \n",
       "1                                          the rocks              Mr. Fish   \n",
       "2                                             A dork                 Dummy   \n",
       "3                                            Strange                Scared   \n",
       "4  They're difficult to catch and they take up a ...  They're his favorite   \n",
       "\n",
       "                     21                         22  \n",
       "0                 salad                    catfish  \n",
       "1             the water            the tiny castle  \n",
       "2         Mr.Stupid Kid                    A bully  \n",
       "3                 Happy                        Sad  \n",
       "4  He doesn't like them  Grandpa doesn't like them  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    from nltk.tag import StanfordNERTagger \n",
    "result=[]\n",
    "for txt in df[2]:\n",
    "    result.extend(match_entities_with_dataset(txt,category_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach',\n",
       " 'beach',\n",
       " 'house',\n",
       " 'house',\n",
       " 'steak',\n",
       " 'house',\n",
       " 'bed',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'castle',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'face',\n",
       " 'bench',\n",
       " 'tree',\n",
       " 'line',\n",
       " 'line',\n",
       " 'tree',\n",
       " 'bench',\n",
       " 'bench',\n",
       " 'face',\n",
       " 'line',\n",
       " 'face',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'fence',\n",
       " 'fence',\n",
       " 'house',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'house',\n",
       " 'lightning',\n",
       " 'house',\n",
       " 'door',\n",
       " 'lightning',\n",
       " 'house',\n",
       " 'house',\n",
       " 'tree',\n",
       " 'television',\n",
       " 'television',\n",
       " 'telephone',\n",
       " 'lightning',\n",
       " 'rain',\n",
       " 'potato',\n",
       " 'bed',\n",
       " 'strawberry',\n",
       " 'spider',\n",
       " 'saw',\n",
       " 'spider',\n",
       " 'spider',\n",
       " 'spider',\n",
       " 'spider',\n",
       " 'spider',\n",
       " 'saw',\n",
       " 'horse',\n",
       " 'cow',\n",
       " 'horse',\n",
       " 'cow',\n",
       " 'dog',\n",
       " 'sandwich',\n",
       " 'fish',\n",
       " 'sandwich',\n",
       " 'horse',\n",
       " 'cow',\n",
       " 'onion',\n",
       " 'potato',\n",
       " 'horse',\n",
       " 'cow',\n",
       " 'dog',\n",
       " 'sandwich',\n",
       " 'fish',\n",
       " 'sandwich',\n",
       " 'house',\n",
       " 'face',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'bicycle',\n",
       " 'bicycle',\n",
       " 'river',\n",
       " 'house',\n",
       " 'bicycle',\n",
       " 'river',\n",
       " 'river',\n",
       " 'river',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'ladder',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'ladder',\n",
       " 'bucket',\n",
       " 'bucket',\n",
       " 'ladder',\n",
       " 'ladder',\n",
       " 'ladder',\n",
       " 'hammer',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'ladder',\n",
       " 'bucket',\n",
       " 'house',\n",
       " 'saw',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'saw',\n",
       " 'car',\n",
       " 'jacket',\n",
       " 'car',\n",
       " 'car',\n",
       " 'tree',\n",
       " 'saw',\n",
       " 'peanut',\n",
       " 'tree',\n",
       " 'bear',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'lightning',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'house',\n",
       " 'house',\n",
       " 'pizza',\n",
       " 'table',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cake',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'knee',\n",
       " 'knee',\n",
       " 'bandage',\n",
       " 'bed',\n",
       " 'car',\n",
       " 'pizza',\n",
       " 'car',\n",
       " 'house',\n",
       " 'bed',\n",
       " 'rabbit',\n",
       " 'bench',\n",
       " 'rabbit',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'pizza',\n",
       " 'rabbit',\n",
       " 'rabbit',\n",
       " 'rabbit',\n",
       " 'beach',\n",
       " 'car',\n",
       " 'car',\n",
       " 'car',\n",
       " 'car',\n",
       " 'face',\n",
       " 'ocean',\n",
       " 'ocean',\n",
       " 'bed',\n",
       " 'beach',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'dolphin',\n",
       " 'fish',\n",
       " 'shark',\n",
       " 'strawberry',\n",
       " 'blackberry',\n",
       " 'telephone',\n",
       " 'matches',\n",
       " 'saw',\n",
       " 'door',\n",
       " 'elephant',\n",
       " 'elephant',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'table',\n",
       " 'cat',\n",
       " 'table',\n",
       " 'cake',\n",
       " 'frog',\n",
       " 'pond',\n",
       " 'river',\n",
       " 'saw',\n",
       " 'frog',\n",
       " 'bed',\n",
       " 'bed',\n",
       " 'mouth',\n",
       " 'bed',\n",
       " 'house',\n",
       " 'house',\n",
       " 'table',\n",
       " 'table',\n",
       " 'table',\n",
       " 'crayon',\n",
       " 'crayon',\n",
       " 'house',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'bear',\n",
       " 'eye',\n",
       " 'bear',\n",
       " 'matches',\n",
       " 'strawberry',\n",
       " 'bear',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'lion',\n",
       " 'lion',\n",
       " 'lion',\n",
       " 'bed',\n",
       " 'lion',\n",
       " 'monkey',\n",
       " 'lion',\n",
       " 'monkey',\n",
       " 'lion',\n",
       " 'chair',\n",
       " 'basket',\n",
       " 'duck',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'duck',\n",
       " 'telephone',\n",
       " 'telephone',\n",
       " 'chair',\n",
       " 'truck',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'saw',\n",
       " 'arm',\n",
       " 'bandage',\n",
       " 'arm',\n",
       " 'truck',\n",
       " 'television',\n",
       " 'rain',\n",
       " 'house',\n",
       " 'rain',\n",
       " 'rain',\n",
       " 'rain',\n",
       " 'baseball',\n",
       " 'rain',\n",
       " 'car',\n",
       " 'door',\n",
       " 'rainbow',\n",
       " 'rain',\n",
       " 'book',\n",
       " 'train',\n",
       " 'car',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'tree',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'strawberry',\n",
       " 'chair',\n",
       " 'hand',\n",
       " 'hand',\n",
       " 'toilet',\n",
       " 'dog',\n",
       " 'van',\n",
       " 'hamburger',\n",
       " 'van',\n",
       " 'dog',\n",
       " 'pencil',\n",
       " 'house',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'flower',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'house',\n",
       " 'house',\n",
       " 'house',\n",
       " 'sun',\n",
       " 'house',\n",
       " 'saw',\n",
       " 'sandwich',\n",
       " 'pizza',\n",
       " 'pizza',\n",
       " 'car',\n",
       " 'oven',\n",
       " 'pizza',\n",
       " 'pizza',\n",
       " 'pizza',\n",
       " 'oven',\n",
       " 'pizza',\n",
       " 'bed',\n",
       " 'monkey',\n",
       " 'giraffe',\n",
       " 'pond',\n",
       " 'dog',\n",
       " 'monkey',\n",
       " 'monkey',\n",
       " 'monkey',\n",
       " 'bench',\n",
       " 'saw',\n",
       " 'monkey',\n",
       " 'monkey',\n",
       " 'monkey',\n",
       " 'monkey',\n",
       " 'saw',\n",
       " 'monkey',\n",
       " 'saw',\n",
       " 'rain',\n",
       " 'circle',\n",
       " 'face',\n",
       " 'house',\n",
       " 'sun',\n",
       " 'bird',\n",
       " 'saw',\n",
       " 'pool',\n",
       " 'blueberry',\n",
       " 'strawberry',\n",
       " 'blueberry',\n",
       " 'car',\n",
       " 'pig',\n",
       " 'rain',\n",
       " 'rain',\n",
       " 'hat',\n",
       " 'rain',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'hat',\n",
       " 'pig',\n",
       " 'bread',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'bread',\n",
       " 'pig',\n",
       " 'car',\n",
       " 'pig',\n",
       " 'car',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'pig',\n",
       " 'bread',\n",
       " 'telephone',\n",
       " 'house',\n",
       " 'television',\n",
       " 'river',\n",
       " 'river',\n",
       " 'pond',\n",
       " 'pond',\n",
       " 'pond',\n",
       " 'pond',\n",
       " 'pond',\n",
       " 'pond',\n",
       " 'pear',\n",
       " 'table',\n",
       " 'apple',\n",
       " 'grapes',\n",
       " 'basket',\n",
       " 'pear',\n",
       " 'mouth',\n",
       " 'bicycle',\n",
       " 'bicycle',\n",
       " 'bicycle',\n",
       " 'bicycle',\n",
       " 'bicycle',\n",
       " 'bicycle',\n",
       " 'grass',\n",
       " 'strawberry',\n",
       " 'apple',\n",
       " 'hand',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'star',\n",
       " 'airplane',\n",
       " 'house',\n",
       " 'ladder',\n",
       " 'door',\n",
       " 'door',\n",
       " 'duck',\n",
       " 'door',\n",
       " 'ladder',\n",
       " 'ladder',\n",
       " 'car',\n",
       " 'train',\n",
       " 'book',\n",
       " 'airplane',\n",
       " 'house',\n",
       " 'ladder',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'beach',\n",
       " 'bicycle',\n",
       " 'beach',\n",
       " 'castle',\n",
       " 'saw',\n",
       " 'bed',\n",
       " 'cup',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'hat',\n",
       " 'hat',\n",
       " 'flower',\n",
       " 'hat',\n",
       " 'dragon',\n",
       " 'face',\n",
       " 'dragon',\n",
       " 'castle',\n",
       " 'castle',\n",
       " 'dragon',\n",
       " 'castle',\n",
       " 'nose',\n",
       " 'dog',\n",
       " 'squirrel',\n",
       " 'bus',\n",
       " 'shoe',\n",
       " 'shoe',\n",
       " 'watermelon',\n",
       " 'dog',\n",
       " 'blueberry',\n",
       " 'grapes',\n",
       " 'strawberry',\n",
       " 'strawberry',\n",
       " 'wheel',\n",
       " 'strawberry',\n",
       " 'strawberry',\n",
       " 'baseball',\n",
       " 'basketball',\n",
       " 'baseball',\n",
       " 'car',\n",
       " 'cake',\n",
       " 'house',\n",
       " 'table',\n",
       " 'television',\n",
       " 'couch',\n",
       " 'dog',\n",
       " 'chair',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'ear',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'pencil',\n",
       " 'dog',\n",
       " 'toilet',\n",
       " 'frog',\n",
       " 'spoon',\n",
       " 'banana',\n",
       " 'cat',\n",
       " 'moon',\n",
       " 'face',\n",
       " 'beard',\n",
       " 'beard',\n",
       " 'tree',\n",
       " 'toe',\n",
       " 'saw',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'house',\n",
       " 'horse',\n",
       " 'basket',\n",
       " 'dog',\n",
       " 'table',\n",
       " 'face',\n",
       " 'sandwich',\n",
       " 'lion',\n",
       " 'lion',\n",
       " 'sun',\n",
       " 'strawberry',\n",
       " 'strawberry',\n",
       " 'saw',\n",
       " 'banana',\n",
       " 'strawberry',\n",
       " 'river',\n",
       " 'duck',\n",
       " 'strawberry',\n",
       " 'apple',\n",
       " 'strawberry',\n",
       " 'elephant',\n",
       " 'house',\n",
       " 'strawberry',\n",
       " 'steak',\n",
       " 'table',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'car',\n",
       " 'house',\n",
       " 'chair',\n",
       " 'table',\n",
       " 'book',\n",
       " 'chair',\n",
       " 'book',\n",
       " 'book',\n",
       " 'book',\n",
       " 'chair',\n",
       " 'angel',\n",
       " 'jacket',\n",
       " 'house',\n",
       " 'door',\n",
       " 'saw',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'door',\n",
       " 'house',\n",
       " 'house',\n",
       " 'saw',\n",
       " 'beach',\n",
       " 'bird',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'basket',\n",
       " 'house',\n",
       " 'basket',\n",
       " 'beach',\n",
       " 'dog',\n",
       " 'train',\n",
       " 'sun',\n",
       " 'train',\n",
       " 'train',\n",
       " 'house',\n",
       " 'train',\n",
       " 'train',\n",
       " 'car',\n",
       " 'train',\n",
       " 'train',\n",
       " 'dog',\n",
       " 'peanut',\n",
       " 'potato',\n",
       " 'dog',\n",
       " 'tree',\n",
       " 'dog',\n",
       " 'flower',\n",
       " 'flower',\n",
       " 'tree',\n",
       " 'hat',\n",
       " 'telephone',\n",
       " 'dog',\n",
       " 'house',\n",
       " 'saw',\n",
       " 'bear',\n",
       " 'bear',\n",
       " 'sandwich',\n",
       " 'sandwich',\n",
       " 'peanut',\n",
       " 'sandwich',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'tree',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'saw',\n",
       " 'dragon',\n",
       " 'bed',\n",
       " 'grass',\n",
       " 'dragon',\n",
       " 'bed',\n",
       " 'bed',\n",
       " 'saw',\n",
       " 'necklace',\n",
       " 'dragon',\n",
       " 'dragon',\n",
       " 'bed',\n",
       " 'bed',\n",
       " 'bed',\n",
       " 'car',\n",
       " 'saw',\n",
       " 'fish',\n",
       " 'lion',\n",
       " 'circle',\n",
       " 'grass',\n",
       " 'horse',\n",
       " 'squirrel',\n",
       " 'beach',\n",
       " 'lightning',\n",
       " 'squirrel',\n",
       " 'lightning',\n",
       " 'tree',\n",
       " 'car',\n",
       " 'car',\n",
       " 'tree',\n",
       " 'car',\n",
       " 'door',\n",
       " 'car',\n",
       " 'ear',\n",
       " 'telephone',\n",
       " 'telephone',\n",
       " 'telephone',\n",
       " 'garden',\n",
       " 'peas',\n",
       " 'broccoli',\n",
       " 'telephone',\n",
       " 'line',\n",
       " 'telephone',\n",
       " 'saw',\n",
       " 'house',\n",
       " 'basketball',\n",
       " 'star',\n",
       " 'baseball',\n",
       " 'cup',\n",
       " 'cup',\n",
       " 'cup',\n",
       " 'saw',\n",
       " 'cup',\n",
       " 'peanut',\n",
       " 'peanut',\n",
       " 'river',\n",
       " 'river',\n",
       " 'bridge',\n",
       " 'house',\n",
       " 'river',\n",
       " 'lion',\n",
       " 'tiger',\n",
       " 'bear',\n",
       " 'saw',\n",
       " 'raccoon',\n",
       " 'raccoon',\n",
       " 'river',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'peanut',\n",
       " 'sandwich',\n",
       " 'saw',\n",
       " 'fish',\n",
       " 'fish',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'basket',\n",
       " 'sun',\n",
       " 'house',\n",
       " 'tree',\n",
       " 'house',\n",
       " 'saw',\n",
       " 'house',\n",
       " 'door',\n",
       " 'saw',\n",
       " 'face',\n",
       " 'telephone',\n",
       " 'pizza',\n",
       " 'backpack',\n",
       " 'beach',\n",
       " 'house',\n",
       " 'beach',\n",
       " 'river',\n",
       " 'castle',\n",
       " 'bridge',\n",
       " 'river',\n",
       " 'castle',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'house',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'couch',\n",
       " 'octopus',\n",
       " 'ocean',\n",
       " 'ocean',\n",
       " 'fish',\n",
       " 'star',\n",
       " 'fish',\n",
       " 'octopus',\n",
       " 'mug',\n",
       " 'sandwich',\n",
       " 'bed',\n",
       " 'sandwich',\n",
       " 'book',\n",
       " 'sandwich',\n",
       " 'book',\n",
       " 'sandwich',\n",
       " 'saw',\n",
       " 'tree',\n",
       " 'snake',\n",
       " 'car',\n",
       " 'car',\n",
       " 'bus',\n",
       " 'radio',\n",
       " 'radio',\n",
       " 'snake',\n",
       " 'snake',\n",
       " 'snake',\n",
       " 'snake',\n",
       " 'bear',\n",
       " 'monkey',\n",
       " 'snake',\n",
       " 'snake',\n",
       " 'snake',\n",
       " 'saw',\n",
       " 'snake',\n",
       " 'rabbit',\n",
       " 'duck',\n",
       " 'bear',\n",
       " 'duck',\n",
       " 'bear',\n",
       " 'rabbit',\n",
       " 'saw',\n",
       " 'basket',\n",
       " 'clock',\n",
       " 'bed',\n",
       " 'face',\n",
       " 'bus',\n",
       " 'bus',\n",
       " 'bus',\n",
       " 'bus',\n",
       " 'sandwich',\n",
       " 'potato',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'bus',\n",
       " 'house',\n",
       " 'apple',\n",
       " 'house',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'saw',\n",
       " 'tiger',\n",
       " 'tiger',\n",
       " 'book',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'tiger',\n",
       " 'tiger',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'tiger',\n",
       " 'tiger',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'snake',\n",
       " 'bird',\n",
       " 'tiger',\n",
       " 'apple',\n",
       " 'apple',\n",
       " 'tree',\n",
       " 'saw',\n",
       " 'bread',\n",
       " 'car',\n",
       " 'car',\n",
       " 'house',\n",
       " 'dog',\n",
       " 'squirrel',\n",
       " 'dog',\n",
       " 'tiger',\n",
       " 'saw',\n",
       " 'tiger',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'tree',\n",
       " 'cat',\n",
       " 'tree',\n",
       " 'cat',\n",
       " 'tree',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'tree',\n",
       " 'cat',\n",
       " 'face',\n",
       " 'table',\n",
       " 'chair',\n",
       " 'lollipop',\n",
       " 'basket',\n",
       " 'shoe',\n",
       " 'cookie',\n",
       " 'hand',\n",
       " 'shoe',\n",
       " 'cookie',\n",
       " 'shoe',\n",
       " 'house',\n",
       " 'camera',\n",
       " 'house',\n",
       " 'shoe',\n",
       " 'shoe',\n",
       " 'camera',\n",
       " 'house',\n",
       " 'cookie',\n",
       " 'house',\n",
       " 'finger',\n",
       " 'finger',\n",
       " 'toilet',\n",
       " 'finger',\n",
       " 'pencil',\n",
       " 'saw',\n",
       " 'finger',\n",
       " 'toilet',\n",
       " 'basket',\n",
       " 'basket',\n",
       " 'basket',\n",
       " 'face',\n",
       " 'saw',\n",
       " 'mouse',\n",
       " 'house',\n",
       " 'dog',\n",
       " 'saw',\n",
       " 'dog',\n",
       " 'sheep',\n",
       " 'pig',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'barn',\n",
       " 'ladder',\n",
       " 'barn',\n",
       " 'house',\n",
       " 'table',\n",
       " 'barn',\n",
       " 'sheep',\n",
       " 'sheep',\n",
       " 'car',\n",
       " 'grass',\n",
       " 'leaf',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'house',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'house',\n",
       " 'house',\n",
       " 'cake',\n",
       " 'house',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'garden',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'cake',\n",
       " 'cake',\n",
       " 'mouth',\n",
       " 'cat',\n",
       " 'line',\n",
       " 'door',\n",
       " 'flower',\n",
       " 'star',\n",
       " 'rain',\n",
       " 'dog',\n",
       " 'mountain',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'cake',\n",
       " 'table',\n",
       " 'cake',\n",
       " 'saw',\n",
       " 'sink',\n",
       " 'toaster',\n",
       " 'cake',\n",
       " 'sink',\n",
       " 'arm',\n",
       " 'bed',\n",
       " 'wheel',\n",
       " 'sock',\n",
       " 'chair',\n",
       " 'door',\n",
       " 'door',\n",
       " 'saw',\n",
       " 'door',\n",
       " 'cat',\n",
       " 'house',\n",
       " 'ocean',\n",
       " 'grass',\n",
       " 'grass',\n",
       " 'saw',\n",
       " 'grass',\n",
       " 'bird',\n",
       " 'house',\n",
       " 'dog',\n",
       " 'face',\n",
       " 'pig',\n",
       " 'star',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'clock',\n",
       " 'bird',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'bird',\n",
       " 'pond',\n",
       " 'beach',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'pond',\n",
       " 'car',\n",
       " 'face',\n",
       " 'potato',\n",
       " 'ocean',\n",
       " 'beach',\n",
       " 'bed',\n",
       " 'ear',\n",
       " 'sun',\n",
       " 'van',\n",
       " 'beach',\n",
       " 'door',\n",
       " 'strawberry',\n",
       " 'beach',\n",
       " 'cat',\n",
       " 'house',\n",
       " 'cat',\n",
       " 'house',\n",
       " 'house',\n",
       " 'car',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'house',\n",
       " 'couch',\n",
       " 'car',\n",
       " 'house',\n",
       " 'house',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'house',\n",
       " 'truck',\n",
       " 'house',\n",
       " 'door',\n",
       " 'truck',\n",
       " 'radio',\n",
       " 'dog',\n",
       " 'saw',\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Final result after namming the named entities to category\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eliminating duplicates to check the number of categories identified\n",
    "result_final = list(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "163 categories are detected. We can train the NER and word2vec model to improve this detection rate. For instance the categories like \"school bus\" and others that have two consecutive words are not detected by our model. This can be improved by training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Demo</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_txt = \"The dog is near the Tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use nltk.tag.corenlp.CoreNLPPOSTagger or nltk.tag.corenlp.CoreNLPNERTagger instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "result.extend(match_entities_with_dataset(demo_txt,category_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final = list(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'tree']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a sample text from which the standford NER identifies the entities. We can then use the entities and do semantic matching with Google's pretrained word2vec model. Once we get the categories we can use the appropriate npy files as input to auto-encoder , do clustering, decode only the centroids and add it to the dictionary to be sent to the generate response module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Let's use auto-encoder to convert each npy image to latent space and then decode to get the original values.</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data_npy/full%2Fnumpy_bitmap%2F'+result_final[0]+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152159, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_size = 32\n",
    "\n",
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(input_image)\n",
    "x = MaxPooling2D((2, 2), padding='same', data_format='channels_last')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same', data_format='channels_last')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same', data_format='channels_last')(x)\n",
    "\n",
    "x = Flatten()(x)                                        # Squashing\n",
    "x = Dense(256, activation='relu')(x)                    # Squashing\n",
    "x = Dropout(0.2)(x)                                     # Squashing\n",
    "encoded = Dense(encoding_size, activation='relu')(x)    # Dense, encoded layer\n",
    "x = Dense(64*7*7, activation='relu')(encoded)           # Growing\n",
    "x = Dropout(0.2)(x)                                     # Growing\n",
    "x = Reshape((-1, 7, 7, 64)[1:])(x)                      # Growing\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(x)\n",
    "x = UpSampling2D((2, 2), data_format='channels_last')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(x)\n",
    "x = UpSampling2D((2, 2), data_format='channels_last')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', data_format='channels_last')(x)\n",
    "\n",
    "autoencoder = Model(input_image, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3136)              103488    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 32)          18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 299,105\n",
      "Trainable params: 299,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='binary_crossentropy', \n",
    "                    metrics=['mse'])\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let K value be 5 for clustering, thus returning 5 centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - ETA: 6:12:36 - loss: 0.6941 - mean_squared_error: 0.215 - ETA: 3:05:36 - loss: 0.6929 - mean_squared_error: 0.213 - ETA: 2:03:10 - loss: 0.6919 - mean_squared_error: 0.212 - ETA: 1:31:54 - loss: 0.6904 - mean_squared_error: 0.212 - ETA: 1:13:11 - loss: 0.6884 - mean_squared_error: 0.211 - ETA: 1:00:43 - loss: 0.6854 - mean_squared_error: 0.210 - ETA: 51:48 - loss: 0.6807 - mean_squared_error: 0.2085  - ETA: 45:05 - loss: 0.6741 - mean_squared_error: 0.205 - ETA: 39:50 - loss: 0.6642 - mean_squared_error: 0.200 - ETA: 35:38 - loss: 0.6521 - mean_squared_error: 0.194 - ETA: 32:12 - loss: 0.6441 - mean_squared_error: 0.189 - ETA: 29:19 - loss: 0.6363 - mean_squared_error: 0.184 - ETA: 26:53 - loss: 0.6301 - mean_squared_error: 0.181 - ETA: 24:48 - loss: 0.6225 - mean_squared_error: 0.177 - ETA: 22:59 - loss: 0.6147 - mean_squared_error: 0.174 - ETA: 21:24 - loss: 0.6090 - mean_squared_error: 0.171 - ETA: 20:00 - loss: 0.6027 - mean_squared_error: 0.169 - ETA: 18:44 - loss: 0.5952 - mean_squared_error: 0.166 - ETA: 17:37 - loss: 0.5875 - mean_squared_error: 0.162 - ETA: 16:37 - loss: 0.5819 - mean_squared_error: 0.160 - ETA: 15:42 - loss: 0.5763 - mean_squared_error: 0.157 - ETA: 14:52 - loss: 0.5721 - mean_squared_error: 0.155 - ETA: 14:07 - loss: 0.5664 - mean_squared_error: 0.153 - ETA: 13:25 - loss: 0.5612 - mean_squared_error: 0.151 - ETA: 12:46 - loss: 0.5565 - mean_squared_error: 0.149 - ETA: 12:11 - loss: 0.5512 - mean_squared_error: 0.147 - ETA: 11:38 - loss: 0.5477 - mean_squared_error: 0.146 - ETA: 11:07 - loss: 0.5429 - mean_squared_error: 0.144 - ETA: 10:39 - loss: 0.5388 - mean_squared_error: 0.142 - ETA: 10:12 - loss: 0.5343 - mean_squared_error: 0.141 - ETA: 9:48 - loss: 0.5299 - mean_squared_error: 0.139 - ETA: 9:24 - loss: 0.5274 - mean_squared_error: 0.13 - ETA: 9:02 - loss: 0.5244 - mean_squared_error: 0.13 - ETA: 8:41 - loss: 0.5205 - mean_squared_error: 0.13 - ETA: 8:22 - loss: 0.5171 - mean_squared_error: 0.13 - ETA: 8:03 - loss: 0.5138 - mean_squared_error: 0.13 - ETA: 7:46 - loss: 0.5108 - mean_squared_error: 0.13 - ETA: 7:29 - loss: 0.5076 - mean_squared_error: 0.13 - ETA: 7:13 - loss: 0.5044 - mean_squared_error: 0.13 - ETA: 6:58 - loss: 0.5015 - mean_squared_error: 0.12 - ETA: 6:44 - loss: 0.4991 - mean_squared_error: 0.12 - ETA: 6:31 - loss: 0.4965 - mean_squared_error: 0.12 - ETA: 6:17 - loss: 0.4945 - mean_squared_error: 0.12 - ETA: 6:05 - loss: 0.4917 - mean_squared_error: 0.12 - ETA: 5:53 - loss: 0.4891 - mean_squared_error: 0.12 - ETA: 5:42 - loss: 0.4869 - mean_squared_error: 0.12 - ETA: 5:31 - loss: 0.4848 - mean_squared_error: 0.12 - ETA: 5:20 - loss: 0.4831 - mean_squared_error: 0.12 - ETA: 5:10 - loss: 0.4808 - mean_squared_error: 0.12 - ETA: 5:01 - loss: 0.4785 - mean_squared_error: 0.12 - ETA: 4:51 - loss: 0.4764 - mean_squared_error: 0.12 - ETA: 4:42 - loss: 0.4746 - mean_squared_error: 0.12 - ETA: 4:34 - loss: 0.4726 - mean_squared_error: 0.11 - ETA: 4:25 - loss: 0.4715 - mean_squared_error: 0.11 - ETA: 4:17 - loss: 0.4699 - mean_squared_error: 0.11 - ETA: 4:09 - loss: 0.4680 - mean_squared_error: 0.11 - ETA: 4:02 - loss: 0.4664 - mean_squared_error: 0.11 - ETA: 3:55 - loss: 0.4648 - mean_squared_error: 0.11 - ETA: 3:48 - loss: 0.4634 - mean_squared_error: 0.11 - ETA: 3:41 - loss: 0.4618 - mean_squared_error: 0.11 - ETA: 3:34 - loss: 0.4602 - mean_squared_error: 0.11 - ETA: 3:28 - loss: 0.4586 - mean_squared_error: 0.11 - ETA: 3:22 - loss: 0.4574 - mean_squared_error: 0.11 - ETA: 3:16 - loss: 0.4556 - mean_squared_error: 0.11 - ETA: 3:10 - loss: 0.4541 - mean_squared_error: 0.11 - ETA: 3:04 - loss: 0.4525 - mean_squared_error: 0.11 - ETA: 2:59 - loss: 0.4512 - mean_squared_error: 0.11 - ETA: 2:53 - loss: 0.4496 - mean_squared_error: 0.11 - ETA: 2:48 - loss: 0.4482 - mean_squared_error: 0.11 - ETA: 2:43 - loss: 0.4469 - mean_squared_error: 0.11 - ETA: 2:38 - loss: 0.4457 - mean_squared_error: 0.11 - ETA: 2:33 - loss: 0.4446 - mean_squared_error: 0.11 - ETA: 2:28 - loss: 0.4437 - mean_squared_error: 0.11 - ETA: 2:24 - loss: 0.4427 - mean_squared_error: 0.11 - ETA: 2:19 - loss: 0.4415 - mean_squared_error: 0.11 - ETA: 2:15 - loss: 0.4401 - mean_squared_error: 0.10 - ETA: 2:11 - loss: 0.4389 - mean_squared_error: 0.10 - ETA: 2:07 - loss: 0.4380 - mean_squared_error: 0.10 - ETA: 2:03 - loss: 0.4369 - mean_squared_error: 0.10 - ETA: 1:59 - loss: 0.4360 - mean_squared_error: 0.10 - ETA: 1:55 - loss: 0.4351 - mean_squared_error: 0.10 - ETA: 1:51 - loss: 0.4341 - mean_squared_error: 0.10 - ETA: 1:47 - loss: 0.4330 - mean_squared_error: 0.10 - ETA: 1:44 - loss: 0.4321 - mean_squared_error: 0.10 - ETA: 1:40 - loss: 0.4311 - mean_squared_error: 0.10 - ETA: 1:37 - loss: 0.4299 - mean_squared_error: 0.10 - ETA: 1:33 - loss: 0.4289 - mean_squared_error: 0.10 - ETA: 1:30 - loss: 0.4278 - mean_squared_error: 0.10 - ETA: 1:26 - loss: 0.4267 - mean_squared_error: 0.10 - ETA: 1:23 - loss: 0.4259 - mean_squared_error: 0.10 - ETA: 1:20 - loss: 0.4250 - mean_squared_error: 0.10 - ETA: 1:17 - loss: 0.4245 - mean_squared_error: 0.10 - ETA: 1:14 - loss: 0.4236 - mean_squared_error: 0.10 - ETA: 1:11 - loss: 0.4229 - mean_squared_error: 0.10 - ETA: 1:08 - loss: 0.4224 - mean_squared_error: 0.10 - ETA: 1:05 - loss: 0.4218 - mean_squared_error: 0.10 - ETA: 1:02 - loss: 0.4209 - mean_squared_error: 0.10 - ETA: 1:00 - loss: 0.4200 - mean_squared_error: 0.10 - ETA: 57s - loss: 0.4195 - mean_squared_error: 0.1037 - ETA: 54s - loss: 0.4188 - mean_squared_error: 0.103 - ETA: 52s - loss: 0.4183 - mean_squared_error: 0.103 - ETA: 49s - loss: 0.4174 - mean_squared_error: 0.103 - ETA: 47s - loss: 0.4169 - mean_squared_error: 0.103 - ETA: 44s - loss: 0.4163 - mean_squared_error: 0.102 - ETA: 42s - loss: 0.4157 - mean_squared_error: 0.102 - ETA: 39s - loss: 0.4148 - mean_squared_error: 0.102 - ETA: 37s - loss: 0.4141 - mean_squared_error: 0.102 - ETA: 34s - loss: 0.4137 - mean_squared_error: 0.102 - ETA: 32s - loss: 0.4132 - mean_squared_error: 0.101 - ETA: 30s - loss: 0.4126 - mean_squared_error: 0.101 - ETA: 28s - loss: 0.4122 - mean_squared_error: 0.101 - ETA: 25s - loss: 0.4115 - mean_squared_error: 0.101 - ETA: 23s - loss: 0.4108 - mean_squared_error: 0.101 - ETA: 21s - loss: 0.4102 - mean_squared_error: 0.101 - ETA: 19s - loss: 0.4098 - mean_squared_error: 0.100 - ETA: 17s - loss: 0.4090 - mean_squared_error: 0.100 - ETA: 15s - loss: 0.4084 - mean_squared_error: 0.100 - ETA: 13s - loss: 0.4078 - mean_squared_error: 0.100 - ETA: 11s - loss: 0.4071 - mean_squared_error: 0.100 - ETA: 9s - loss: 0.4067 - mean_squared_error: 0.099 - ETA: 7s - loss: 0.4061 - mean_squared_error: 0.09 - ETA: 5s - loss: 0.4056 - mean_squared_error: 0.09 - ETA: 3s - loss: 0.4049 - mean_squared_error: 0.09 - ETA: 1s - loss: 0.4041 - mean_squared_error: 0.09 - 231s 58ms/step - loss: 0.4035 - mean_squared_error: 0.0990 - val_loss: 0.3316 - val_mean_squared_error: 0.0774\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 45s - loss: 0.3281 - mean_squared_error: 0.077 - ETA: 44s - loss: 0.3443 - mean_squared_error: 0.081 - ETA: 44s - loss: 0.3456 - mean_squared_error: 0.081 - ETA: 44s - loss: 0.3372 - mean_squared_error: 0.079 - ETA: 43s - loss: 0.3356 - mean_squared_error: 0.078 - ETA: 43s - loss: 0.3344 - mean_squared_error: 0.078 - ETA: 43s - loss: 0.3339 - mean_squared_error: 0.078 - ETA: 43s - loss: 0.3340 - mean_squared_error: 0.078 - ETA: 43s - loss: 0.3337 - mean_squared_error: 0.078 - ETA: 42s - loss: 0.3358 - mean_squared_error: 0.078 - ETA: 42s - loss: 0.3357 - mean_squared_error: 0.078 - ETA: 42s - loss: 0.3350 - mean_squared_error: 0.078 - ETA: 41s - loss: 0.3325 - mean_squared_error: 0.077 - ETA: 41s - loss: 0.3344 - mean_squared_error: 0.078 - ETA: 40s - loss: 0.3354 - mean_squared_error: 0.078 - ETA: 40s - loss: 0.3358 - mean_squared_error: 0.078 - ETA: 40s - loss: 0.3372 - mean_squared_error: 0.079 - ETA: 39s - loss: 0.3366 - mean_squared_error: 0.079 - ETA: 39s - loss: 0.3372 - mean_squared_error: 0.079 - ETA: 38s - loss: 0.3375 - mean_squared_error: 0.079 - ETA: 38s - loss: 0.3370 - mean_squared_error: 0.079 - ETA: 38s - loss: 0.3369 - mean_squared_error: 0.079 - ETA: 37s - loss: 0.3367 - mean_squared_error: 0.079 - ETA: 37s - loss: 0.3362 - mean_squared_error: 0.078 - ETA: 37s - loss: 0.3360 - mean_squared_error: 0.078 - ETA: 36s - loss: 0.3352 - mean_squared_error: 0.078 - ETA: 36s - loss: 0.3353 - mean_squared_error: 0.078 - ETA: 35s - loss: 0.3355 - mean_squared_error: 0.078 - ETA: 35s - loss: 0.3358 - mean_squared_error: 0.078 - ETA: 34s - loss: 0.3355 - mean_squared_error: 0.078 - ETA: 34s - loss: 0.3352 - mean_squared_error: 0.078 - ETA: 34s - loss: 0.3353 - mean_squared_error: 0.078 - ETA: 33s - loss: 0.3349 - mean_squared_error: 0.078 - ETA: 33s - loss: 0.3347 - mean_squared_error: 0.078 - ETA: 33s - loss: 0.3344 - mean_squared_error: 0.078 - ETA: 32s - loss: 0.3345 - mean_squared_error: 0.078 - ETA: 32s - loss: 0.3345 - mean_squared_error: 0.078 - ETA: 31s - loss: 0.3345 - mean_squared_error: 0.078 - ETA: 31s - loss: 0.3343 - mean_squared_error: 0.078 - ETA: 30s - loss: 0.3343 - mean_squared_error: 0.078 - ETA: 30s - loss: 0.3337 - mean_squared_error: 0.078 - ETA: 30s - loss: 0.3335 - mean_squared_error: 0.078 - ETA: 29s - loss: 0.3331 - mean_squared_error: 0.078 - ETA: 29s - loss: 0.3331 - mean_squared_error: 0.078 - ETA: 29s - loss: 0.3324 - mean_squared_error: 0.077 - ETA: 28s - loss: 0.3324 - mean_squared_error: 0.077 - ETA: 28s - loss: 0.3323 - mean_squared_error: 0.077 - ETA: 28s - loss: 0.3325 - mean_squared_error: 0.077 - ETA: 27s - loss: 0.3328 - mean_squared_error: 0.077 - ETA: 27s - loss: 0.3331 - mean_squared_error: 0.077 - ETA: 27s - loss: 0.3330 - mean_squared_error: 0.077 - ETA: 26s - loss: 0.3323 - mean_squared_error: 0.077 - ETA: 26s - loss: 0.3326 - mean_squared_error: 0.077 - ETA: 25s - loss: 0.3329 - mean_squared_error: 0.077 - ETA: 25s - loss: 0.3327 - mean_squared_error: 0.077 - ETA: 25s - loss: 0.3324 - mean_squared_error: 0.077 - ETA: 24s - loss: 0.3322 - mean_squared_error: 0.077 - ETA: 24s - loss: 0.3327 - mean_squared_error: 0.077 - ETA: 24s - loss: 0.3328 - mean_squared_error: 0.077 - ETA: 23s - loss: 0.3324 - mean_squared_error: 0.077 - ETA: 23s - loss: 0.3318 - mean_squared_error: 0.077 - ETA: 23s - loss: 0.3318 - mean_squared_error: 0.077 - ETA: 22s - loss: 0.3319 - mean_squared_error: 0.077 - ETA: 22s - loss: 0.3320 - mean_squared_error: 0.077 - ETA: 21s - loss: 0.3316 - mean_squared_error: 0.077 - ETA: 21s - loss: 0.3315 - mean_squared_error: 0.077 - ETA: 21s - loss: 0.3320 - mean_squared_error: 0.077 - ETA: 20s - loss: 0.3322 - mean_squared_error: 0.077 - ETA: 20s - loss: 0.3319 - mean_squared_error: 0.077 - ETA: 20s - loss: 0.3316 - mean_squared_error: 0.077 - ETA: 19s - loss: 0.3313 - mean_squared_error: 0.077 - ETA: 19s - loss: 0.3310 - mean_squared_error: 0.077 - ETA: 19s - loss: 0.3310 - mean_squared_error: 0.077 - ETA: 18s - loss: 0.3304 - mean_squared_error: 0.077 - ETA: 18s - loss: 0.3303 - mean_squared_error: 0.077 - ETA: 18s - loss: 0.3303 - mean_squared_error: 0.077 - ETA: 17s - loss: 0.3305 - mean_squared_error: 0.077 - ETA: 17s - loss: 0.3305 - mean_squared_error: 0.077 - ETA: 16s - loss: 0.3302 - mean_squared_error: 0.077 - ETA: 16s - loss: 0.3301 - mean_squared_error: 0.077 - ETA: 16s - loss: 0.3296 - mean_squared_error: 0.076 - ETA: 15s - loss: 0.3297 - mean_squared_error: 0.076 - ETA: 15s - loss: 0.3298 - mean_squared_error: 0.076 - ETA: 15s - loss: 0.3293 - mean_squared_error: 0.076 - ETA: 14s - loss: 0.3291 - mean_squared_error: 0.076 - ETA: 14s - loss: 0.3291 - mean_squared_error: 0.076 - ETA: 13s - loss: 0.3290 - mean_squared_error: 0.076 - ETA: 13s - loss: 0.3287 - mean_squared_error: 0.076 - ETA: 13s - loss: 0.3287 - mean_squared_error: 0.076 - ETA: 12s - loss: 0.3283 - mean_squared_error: 0.076 - ETA: 12s - loss: 0.3283 - mean_squared_error: 0.076 - ETA: 12s - loss: 0.3280 - mean_squared_error: 0.076 - ETA: 11s - loss: 0.3277 - mean_squared_error: 0.076 - ETA: 11s - loss: 0.3277 - mean_squared_error: 0.076 - ETA: 10s - loss: 0.3276 - mean_squared_error: 0.076 - ETA: 10s - loss: 0.3274 - mean_squared_error: 0.076 - ETA: 10s - loss: 0.3273 - mean_squared_error: 0.076 - ETA: 9s - loss: 0.3271 - mean_squared_error: 0.076 - ETA: 9s - loss: 0.3271 - mean_squared_error: 0.07 - ETA: 9s - loss: 0.3270 - mean_squared_error: 0.07 - ETA: 8s - loss: 0.3267 - mean_squared_error: 0.07 - ETA: 8s - loss: 0.3266 - mean_squared_error: 0.07 - ETA: 8s - loss: 0.3263 - mean_squared_error: 0.07 - ETA: 7s - loss: 0.3265 - mean_squared_error: 0.07 - ETA: 7s - loss: 0.3265 - mean_squared_error: 0.07 - ETA: 6s - loss: 0.3264 - mean_squared_error: 0.07 - ETA: 6s - loss: 0.3266 - mean_squared_error: 0.07 - ETA: 6s - loss: 0.3265 - mean_squared_error: 0.07 - ETA: 5s - loss: 0.3265 - mean_squared_error: 0.07 - ETA: 5s - loss: 0.3264 - mean_squared_error: 0.07 - ETA: 5s - loss: 0.3263 - mean_squared_error: 0.07 - ETA: 4s - loss: 0.3262 - mean_squared_error: 0.07 - ETA: 4s - loss: 0.3259 - mean_squared_error: 0.07 - ETA: 4s - loss: 0.3258 - mean_squared_error: 0.07 - ETA: 3s - loss: 0.3257 - mean_squared_error: 0.07 - ETA: 3s - loss: 0.3253 - mean_squared_error: 0.07 - ETA: 2s - loss: 0.3250 - mean_squared_error: 0.07 - ETA: 2s - loss: 0.3247 - mean_squared_error: 0.07 - ETA: 2s - loss: 0.3247 - mean_squared_error: 0.07 - ETA: 1s - loss: 0.3247 - mean_squared_error: 0.07 - ETA: 1s - loss: 0.3248 - mean_squared_error: 0.07 - ETA: 1s - loss: 0.3247 - mean_squared_error: 0.07 - ETA: 0s - loss: 0.3245 - mean_squared_error: 0.07 - ETA: 0s - loss: 0.3244 - mean_squared_error: 0.07 - 48s 12ms/step - loss: 0.3244 - mean_squared_error: 0.0754 - val_loss: 0.3036 - val_mean_squared_error: 0.0695\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 42s - loss: 0.3092 - mean_squared_error: 0.071 - ETA: 42s - loss: 0.3065 - mean_squared_error: 0.070 - ETA: 42s - loss: 0.3119 - mean_squared_error: 0.072 - ETA: 41s - loss: 0.3123 - mean_squared_error: 0.072 - ETA: 41s - loss: 0.3151 - mean_squared_error: 0.072 - ETA: 41s - loss: 0.3106 - mean_squared_error: 0.071 - ETA: 40s - loss: 0.3150 - mean_squared_error: 0.072 - ETA: 40s - loss: 0.3115 - mean_squared_error: 0.071 - ETA: 40s - loss: 0.3114 - mean_squared_error: 0.071 - ETA: 40s - loss: 0.3111 - mean_squared_error: 0.071 - ETA: 39s - loss: 0.3099 - mean_squared_error: 0.071 - ETA: 39s - loss: 0.3092 - mean_squared_error: 0.071 - ETA: 38s - loss: 0.3096 - mean_squared_error: 0.071 - ETA: 38s - loss: 0.3090 - mean_squared_error: 0.071 - ETA: 38s - loss: 0.3091 - mean_squared_error: 0.071 - ETA: 38s - loss: 0.3100 - mean_squared_error: 0.071 - ETA: 37s - loss: 0.3093 - mean_squared_error: 0.071 - ETA: 37s - loss: 0.3098 - mean_squared_error: 0.071 - ETA: 36s - loss: 0.3109 - mean_squared_error: 0.071 - ETA: 36s - loss: 0.3116 - mean_squared_error: 0.071 - ETA: 36s - loss: 0.3120 - mean_squared_error: 0.071 - ETA: 35s - loss: 0.3116 - mean_squared_error: 0.071 - ETA: 35s - loss: 0.3122 - mean_squared_error: 0.071 - ETA: 35s - loss: 0.3114 - mean_squared_error: 0.071 - ETA: 34s - loss: 0.3125 - mean_squared_error: 0.071 - ETA: 34s - loss: 0.3123 - mean_squared_error: 0.071 - ETA: 34s - loss: 0.3117 - mean_squared_error: 0.071 - ETA: 33s - loss: 0.3112 - mean_squared_error: 0.071 - ETA: 33s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 33s - loss: 0.3108 - mean_squared_error: 0.071 - ETA: 32s - loss: 0.3107 - mean_squared_error: 0.071 - ETA: 32s - loss: 0.3112 - mean_squared_error: 0.071 - ETA: 32s - loss: 0.3112 - mean_squared_error: 0.071 - ETA: 32s - loss: 0.3112 - mean_squared_error: 0.071 - ETA: 32s - loss: 0.3111 - mean_squared_error: 0.071 - ETA: 32s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 31s - loss: 0.3103 - mean_squared_error: 0.071 - ETA: 31s - loss: 0.3109 - mean_squared_error: 0.071 - ETA: 31s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 31s - loss: 0.3115 - mean_squared_error: 0.071 - ETA: 30s - loss: 0.3118 - mean_squared_error: 0.071 - ETA: 30s - loss: 0.3120 - mean_squared_error: 0.071 - ETA: 30s - loss: 0.3120 - mean_squared_error: 0.071 - ETA: 29s - loss: 0.3122 - mean_squared_error: 0.071 - ETA: 29s - loss: 0.3119 - mean_squared_error: 0.071 - ETA: 29s - loss: 0.3119 - mean_squared_error: 0.071 - ETA: 28s - loss: 0.3115 - mean_squared_error: 0.071 - ETA: 28s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 27s - loss: 0.3107 - mean_squared_error: 0.071 - ETA: 27s - loss: 0.3108 - mean_squared_error: 0.071 - ETA: 27s - loss: 0.3109 - mean_squared_error: 0.071 - ETA: 26s - loss: 0.3113 - mean_squared_error: 0.071 - ETA: 26s - loss: 0.3113 - mean_squared_error: 0.071 - ETA: 26s - loss: 0.3113 - mean_squared_error: 0.071 - ETA: 25s - loss: 0.3113 - mean_squared_error: 0.071 - ETA: 25s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 24s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 24s - loss: 0.3108 - mean_squared_error: 0.071 - ETA: 24s - loss: 0.3110 - mean_squared_error: 0.071 - ETA: 23s - loss: 0.3107 - mean_squared_error: 0.071 - ETA: 23s - loss: 0.3104 - mean_squared_error: 0.071 - ETA: 23s - loss: 0.3102 - mean_squared_error: 0.071 - ETA: 22s - loss: 0.3103 - mean_squared_error: 0.071 - ETA: 22s - loss: 0.3099 - mean_squared_error: 0.071 - ETA: 22s - loss: 0.3099 - mean_squared_error: 0.071 - ETA: 21s - loss: 0.3097 - mean_squared_error: 0.071 - ETA: 21s - loss: 0.3098 - mean_squared_error: 0.071 - ETA: 20s - loss: 0.3099 - mean_squared_error: 0.071 - ETA: 20s - loss: 0.3099 - mean_squared_error: 0.071 - ETA: 20s - loss: 0.3097 - mean_squared_error: 0.071 - ETA: 19s - loss: 0.3099 - mean_squared_error: 0.071 - ETA: 19s - loss: 0.3100 - mean_squared_error: 0.071 - ETA: 19s - loss: 0.3098 - mean_squared_error: 0.071 - ETA: 18s - loss: 0.3098 - mean_squared_error: 0.071 - ETA: 18s - loss: 0.3098 - mean_squared_error: 0.071 - ETA: 17s - loss: 0.3092 - mean_squared_error: 0.070 - ETA: 17s - loss: 0.3093 - mean_squared_error: 0.070 - ETA: 17s - loss: 0.3092 - mean_squared_error: 0.070 - ETA: 16s - loss: 0.3093 - mean_squared_error: 0.070 - ETA: 16s - loss: 0.3093 - mean_squared_error: 0.070 - ETA: 16s - loss: 0.3093 - mean_squared_error: 0.070 - ETA: 15s - loss: 0.3087 - mean_squared_error: 0.070 - ETA: 15s - loss: 0.3083 - mean_squared_error: 0.070 - ETA: 14s - loss: 0.3083 - mean_squared_error: 0.070 - ETA: 14s - loss: 0.3081 - mean_squared_error: 0.070 - ETA: 14s - loss: 0.3081 - mean_squared_error: 0.070 - ETA: 13s - loss: 0.3081 - mean_squared_error: 0.070 - ETA: 13s - loss: 0.3081 - mean_squared_error: 0.070 - ETA: 13s - loss: 0.3081 - mean_squared_error: 0.070 - ETA: 12s - loss: 0.3082 - mean_squared_error: 0.070 - ETA: 12s - loss: 0.3082 - mean_squared_error: 0.070 - ETA: 12s - loss: 0.3084 - mean_squared_error: 0.070 - ETA: 11s - loss: 0.3083 - mean_squared_error: 0.070 - ETA: 11s - loss: 0.3084 - mean_squared_error: 0.070 - ETA: 10s - loss: 0.3082 - mean_squared_error: 0.070 - ETA: 10s - loss: 0.3082 - mean_squared_error: 0.070 - ETA: 10s - loss: 0.3084 - mean_squared_error: 0.070 - ETA: 9s - loss: 0.3080 - mean_squared_error: 0.070 - ETA: 9s - loss: 0.3076 - mean_squared_error: 0.07 - ETA: 9s - loss: 0.3076 - mean_squared_error: 0.07 - ETA: 8s - loss: 0.3075 - mean_squared_error: 0.07 - ETA: 8s - loss: 0.3074 - mean_squared_error: 0.07 - ETA: 7s - loss: 0.3073 - mean_squared_error: 0.07 - ETA: 7s - loss: 0.3074 - mean_squared_error: 0.07 - ETA: 7s - loss: 0.3073 - mean_squared_error: 0.07 - ETA: 6s - loss: 0.3072 - mean_squared_error: 0.07 - ETA: 6s - loss: 0.3071 - mean_squared_error: 0.07 - ETA: 6s - loss: 0.3070 - mean_squared_error: 0.07 - ETA: 5s - loss: 0.3070 - mean_squared_error: 0.07 - ETA: 5s - loss: 0.3071 - mean_squared_error: 0.07 - ETA: 5s - loss: 0.3072 - mean_squared_error: 0.07 - ETA: 4s - loss: 0.3072 - mean_squared_error: 0.07 - ETA: 4s - loss: 0.3070 - mean_squared_error: 0.07 - ETA: 3s - loss: 0.3069 - mean_squared_error: 0.07 - ETA: 3s - loss: 0.3068 - mean_squared_error: 0.07 - ETA: 3s - loss: 0.3068 - mean_squared_error: 0.07 - ETA: 2s - loss: 0.3068 - mean_squared_error: 0.07 - ETA: 2s - loss: 0.3069 - mean_squared_error: 0.07 - ETA: 2s - loss: 0.3068 - mean_squared_error: 0.07 - ETA: 1s - loss: 0.3067 - mean_squared_error: 0.07 - ETA: 1s - loss: 0.3067 - mean_squared_error: 0.07 - ETA: 1s - loss: 0.3067 - mean_squared_error: 0.07 - ETA: 0s - loss: 0.3068 - mean_squared_error: 0.07 - ETA: 0s - loss: 0.3068 - mean_squared_error: 0.07 - 48s 12ms/step - loss: 0.3068 - mean_squared_error: 0.0701 - val_loss: 0.2931 - val_mean_squared_error: 0.0658\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 44s - loss: 0.2886 - mean_squared_error: 0.065 - ETA: 44s - loss: 0.2999 - mean_squared_error: 0.067 - ETA: 43s - loss: 0.2965 - mean_squared_error: 0.066 - ETA: 43s - loss: 0.2917 - mean_squared_error: 0.066 - ETA: 43s - loss: 0.2951 - mean_squared_error: 0.066 - ETA: 43s - loss: 0.2944 - mean_squared_error: 0.066 - ETA: 42s - loss: 0.2945 - mean_squared_error: 0.066 - ETA: 42s - loss: 0.2948 - mean_squared_error: 0.066 - ETA: 41s - loss: 0.2957 - mean_squared_error: 0.066 - ETA: 41s - loss: 0.2953 - mean_squared_error: 0.066 - ETA: 41s - loss: 0.2966 - mean_squared_error: 0.067 - ETA: 40s - loss: 0.2973 - mean_squared_error: 0.067 - ETA: 40s - loss: 0.2986 - mean_squared_error: 0.067 - ETA: 40s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 39s - loss: 0.3003 - mean_squared_error: 0.067 - ETA: 39s - loss: 0.3005 - mean_squared_error: 0.067 - ETA: 39s - loss: 0.3005 - mean_squared_error: 0.067 - ETA: 38s - loss: 0.3007 - mean_squared_error: 0.067 - ETA: 38s - loss: 0.3004 - mean_squared_error: 0.067 - ETA: 38s - loss: 0.3005 - mean_squared_error: 0.067 - ETA: 37s - loss: 0.3007 - mean_squared_error: 0.067 - ETA: 37s - loss: 0.3007 - mean_squared_error: 0.067 - ETA: 37s - loss: 0.3002 - mean_squared_error: 0.067 - ETA: 36s - loss: 0.3012 - mean_squared_error: 0.068 - ETA: 36s - loss: 0.3010 - mean_squared_error: 0.068 - ETA: 36s - loss: 0.3001 - mean_squared_error: 0.067 - ETA: 35s - loss: 0.2997 - mean_squared_error: 0.067 - ETA: 35s - loss: 0.3001 - mean_squared_error: 0.067 - ETA: 34s - loss: 0.2999 - mean_squared_error: 0.067 - ETA: 34s - loss: 0.2997 - mean_squared_error: 0.067 - ETA: 33s - loss: 0.3003 - mean_squared_error: 0.067 - ETA: 33s - loss: 0.3004 - mean_squared_error: 0.067 - ETA: 33s - loss: 0.3004 - mean_squared_error: 0.067 - ETA: 32s - loss: 0.3004 - mean_squared_error: 0.067 - ETA: 32s - loss: 0.2999 - mean_squared_error: 0.067 - ETA: 31s - loss: 0.3001 - mean_squared_error: 0.067 - ETA: 31s - loss: 0.2998 - mean_squared_error: 0.067 - ETA: 31s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 30s - loss: 0.2995 - mean_squared_error: 0.067 - ETA: 30s - loss: 0.2996 - mean_squared_error: 0.067 - ETA: 29s - loss: 0.2992 - mean_squared_error: 0.067 - ETA: 29s - loss: 0.2990 - mean_squared_error: 0.067 - ETA: 29s - loss: 0.2988 - mean_squared_error: 0.067 - ETA: 28s - loss: 0.2987 - mean_squared_error: 0.067 - ETA: 28s - loss: 0.2987 - mean_squared_error: 0.067 - ETA: 28s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 27s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 27s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 27s - loss: 0.2989 - mean_squared_error: 0.067 - ETA: 26s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 26s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 26s - loss: 0.2989 - mean_squared_error: 0.067 - ETA: 26s - loss: 0.2995 - mean_squared_error: 0.067 - ETA: 25s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 25s - loss: 0.2992 - mean_squared_error: 0.067 - ETA: 25s - loss: 0.2995 - mean_squared_error: 0.067 - ETA: 24s - loss: 0.2997 - mean_squared_error: 0.067 - ETA: 24s - loss: 0.2996 - mean_squared_error: 0.067 - ETA: 23s - loss: 0.2995 - mean_squared_error: 0.067 - ETA: 23s - loss: 0.2995 - mean_squared_error: 0.067 - ETA: 23s - loss: 0.2995 - mean_squared_error: 0.067 - ETA: 22s - loss: 0.2990 - mean_squared_error: 0.067 - ETA: 22s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 22s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 21s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 21s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 20s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 20s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 20s - loss: 0.2992 - mean_squared_error: 0.067 - ETA: 19s - loss: 0.2996 - mean_squared_error: 0.067 - ETA: 19s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 19s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 18s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 18s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 17s - loss: 0.2992 - mean_squared_error: 0.067 - ETA: 17s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 17s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 16s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 16s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 16s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 15s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 15s - loss: 0.2994 - mean_squared_error: 0.067 - ETA: 15s - loss: 0.2993 - mean_squared_error: 0.067 - ETA: 14s - loss: 0.2991 - mean_squared_error: 0.067 - ETA: 14s - loss: 0.2989 - mean_squared_error: 0.067 - ETA: 13s - loss: 0.2989 - mean_squared_error: 0.067 - ETA: 13s - loss: 0.2985 - mean_squared_error: 0.067 - ETA: 13s - loss: 0.2988 - mean_squared_error: 0.067 - ETA: 12s - loss: 0.2988 - mean_squared_error: 0.067 - ETA: 12s - loss: 0.2989 - mean_squared_error: 0.067 - ETA: 12s - loss: 0.2987 - mean_squared_error: 0.067 - ETA: 11s - loss: 0.2986 - mean_squared_error: 0.067 - ETA: 11s - loss: 0.2985 - mean_squared_error: 0.067 - ETA: 11s - loss: 0.2982 - mean_squared_error: 0.067 - ETA: 10s - loss: 0.2981 - mean_squared_error: 0.067 - ETA: 10s - loss: 0.2978 - mean_squared_error: 0.066 - ETA: 10s - loss: 0.2977 - mean_squared_error: 0.066 - ETA: 9s - loss: 0.2979 - mean_squared_error: 0.066 - ETA: 9s - loss: 0.2979 - mean_squared_error: 0.06 - ETA: 9s - loss: 0.2976 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2974 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2974 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2974 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2972 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2971 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2970 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2970 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2968 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2966 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2966 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2967 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2967 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2968 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2969 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2970 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2972 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2973 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2971 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2971 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2970 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2970 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2968 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2968 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2968 - mean_squared_error: 0.06 - 48s 12ms/step - loss: 0.2966 - mean_squared_error: 0.0665 - val_loss: 0.2836 - val_mean_squared_error: 0.0622\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 46s - loss: 0.2608 - mean_squared_error: 0.057 - ETA: 46s - loss: 0.2694 - mean_squared_error: 0.059 - ETA: 45s - loss: 0.2694 - mean_squared_error: 0.059 - ETA: 44s - loss: 0.2731 - mean_squared_error: 0.059 - ETA: 43s - loss: 0.2733 - mean_squared_error: 0.060 - ETA: 43s - loss: 0.2796 - mean_squared_error: 0.061 - ETA: 42s - loss: 0.2838 - mean_squared_error: 0.062 - ETA: 42s - loss: 0.2861 - mean_squared_error: 0.063 - ETA: 41s - loss: 0.2848 - mean_squared_error: 0.062 - ETA: 41s - loss: 0.2852 - mean_squared_error: 0.063 - ETA: 40s - loss: 0.2856 - mean_squared_error: 0.063 - ETA: 40s - loss: 0.2878 - mean_squared_error: 0.063 - ETA: 40s - loss: 0.2876 - mean_squared_error: 0.063 - ETA: 40s - loss: 0.2877 - mean_squared_error: 0.063 - ETA: 40s - loss: 0.2866 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2870 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2880 - mean_squared_error: 0.063 - ETA: 38s - loss: 0.2889 - mean_squared_error: 0.064 - ETA: 38s - loss: 0.2896 - mean_squared_error: 0.064 - ETA: 38s - loss: 0.2884 - mean_squared_error: 0.063 - ETA: 37s - loss: 0.2884 - mean_squared_error: 0.063 - ETA: 37s - loss: 0.2883 - mean_squared_error: 0.063 - ETA: 36s - loss: 0.2877 - mean_squared_error: 0.063 - ETA: 36s - loss: 0.2875 - mean_squared_error: 0.063 - ETA: 35s - loss: 0.2879 - mean_squared_error: 0.063 - ETA: 35s - loss: 0.2884 - mean_squared_error: 0.063 - ETA: 35s - loss: 0.2881 - mean_squared_error: 0.063 - ETA: 34s - loss: 0.2882 - mean_squared_error: 0.063 - ETA: 34s - loss: 0.2883 - mean_squared_error: 0.063 - ETA: 33s - loss: 0.2884 - mean_squared_error: 0.064 - ETA: 33s - loss: 0.2879 - mean_squared_error: 0.063 - ETA: 33s - loss: 0.2883 - mean_squared_error: 0.063 - ETA: 32s - loss: 0.2882 - mean_squared_error: 0.063 - ETA: 32s - loss: 0.2881 - mean_squared_error: 0.063 - ETA: 32s - loss: 0.2888 - mean_squared_error: 0.064 - ETA: 32s - loss: 0.2891 - mean_squared_error: 0.064 - ETA: 31s - loss: 0.2890 - mean_squared_error: 0.064 - ETA: 31s - loss: 0.2884 - mean_squared_error: 0.063 - ETA: 30s - loss: 0.2888 - mean_squared_error: 0.064 - ETA: 30s - loss: 0.2889 - mean_squared_error: 0.064 - ETA: 30s - loss: 0.2890 - mean_squared_error: 0.064 - ETA: 29s - loss: 0.2891 - mean_squared_error: 0.064 - ETA: 29s - loss: 0.2891 - mean_squared_error: 0.064 - ETA: 28s - loss: 0.2886 - mean_squared_error: 0.063 - ETA: 28s - loss: 0.2882 - mean_squared_error: 0.063 - ETA: 28s - loss: 0.2884 - mean_squared_error: 0.063 - ETA: 27s - loss: 0.2889 - mean_squared_error: 0.064 - ETA: 27s - loss: 0.2888 - mean_squared_error: 0.063 - ETA: 27s - loss: 0.2893 - mean_squared_error: 0.064 - ETA: 26s - loss: 0.2900 - mean_squared_error: 0.064 - ETA: 26s - loss: 0.2898 - mean_squared_error: 0.064 - ETA: 26s - loss: 0.2896 - mean_squared_error: 0.064 - ETA: 25s - loss: 0.2895 - mean_squared_error: 0.064 - ETA: 25s - loss: 0.2896 - mean_squared_error: 0.064 - ETA: 25s - loss: 0.2901 - mean_squared_error: 0.064 - ETA: 24s - loss: 0.2897 - mean_squared_error: 0.064 - ETA: 24s - loss: 0.2894 - mean_squared_error: 0.064 - ETA: 24s - loss: 0.2891 - mean_squared_error: 0.064 - ETA: 23s - loss: 0.2891 - mean_squared_error: 0.064 - ETA: 23s - loss: 0.2895 - mean_squared_error: 0.064 - ETA: 23s - loss: 0.2896 - mean_squared_error: 0.064 - ETA: 22s - loss: 0.2894 - mean_squared_error: 0.064 - ETA: 22s - loss: 0.2893 - mean_squared_error: 0.064 - ETA: 22s - loss: 0.2894 - mean_squared_error: 0.064 - ETA: 21s - loss: 0.2898 - mean_squared_error: 0.064 - ETA: 21s - loss: 0.2905 - mean_squared_error: 0.064 - ETA: 20s - loss: 0.2902 - mean_squared_error: 0.064 - ETA: 20s - loss: 0.2903 - mean_squared_error: 0.064 - ETA: 20s - loss: 0.2904 - mean_squared_error: 0.064 - ETA: 19s - loss: 0.2902 - mean_squared_error: 0.064 - ETA: 19s - loss: 0.2902 - mean_squared_error: 0.064 - ETA: 19s - loss: 0.2901 - mean_squared_error: 0.064 - ETA: 18s - loss: 0.2902 - mean_squared_error: 0.064 - ETA: 18s - loss: 0.2906 - mean_squared_error: 0.064 - ETA: 17s - loss: 0.2906 - mean_squared_error: 0.064 - ETA: 17s - loss: 0.2904 - mean_squared_error: 0.064 - ETA: 17s - loss: 0.2905 - mean_squared_error: 0.064 - ETA: 16s - loss: 0.2903 - mean_squared_error: 0.064 - ETA: 16s - loss: 0.2902 - mean_squared_error: 0.064 - ETA: 16s - loss: 0.2900 - mean_squared_error: 0.064 - ETA: 15s - loss: 0.2898 - mean_squared_error: 0.064 - ETA: 15s - loss: 0.2897 - mean_squared_error: 0.064 - ETA: 14s - loss: 0.2896 - mean_squared_error: 0.064 - ETA: 14s - loss: 0.2896 - mean_squared_error: 0.064 - ETA: 14s - loss: 0.2895 - mean_squared_error: 0.064 - ETA: 13s - loss: 0.2895 - mean_squared_error: 0.064 - ETA: 13s - loss: 0.2894 - mean_squared_error: 0.064 - ETA: 13s - loss: 0.2892 - mean_squared_error: 0.063 - ETA: 12s - loss: 0.2892 - mean_squared_error: 0.063 - ETA: 12s - loss: 0.2893 - mean_squared_error: 0.064 - ETA: 12s - loss: 0.2892 - mean_squared_error: 0.063 - ETA: 11s - loss: 0.2890 - mean_squared_error: 0.063 - ETA: 11s - loss: 0.2892 - mean_squared_error: 0.063 - ETA: 11s - loss: 0.2892 - mean_squared_error: 0.063 - ETA: 10s - loss: 0.2891 - mean_squared_error: 0.063 - ETA: 10s - loss: 0.2890 - mean_squared_error: 0.063 - ETA: 9s - loss: 0.2891 - mean_squared_error: 0.063 - ETA: 9s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 9s - loss: 0.2887 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2888 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2888 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2888 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2887 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2890 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2891 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2892 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2893 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2894 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2893 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2891 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2890 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2888 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2891 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2890 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2889 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2888 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2888 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2888 - mean_squared_error: 0.06 - 47s 12ms/step - loss: 0.2888 - mean_squared_error: 0.0637 - val_loss: 0.2733 - val_mean_squared_error: 0.0587\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 48s - loss: 0.2983 - mean_squared_error: 0.065 - ETA: 45s - loss: 0.2978 - mean_squared_error: 0.064 - ETA: 46s - loss: 0.2962 - mean_squared_error: 0.064 - ETA: 44s - loss: 0.2959 - mean_squared_error: 0.065 - ETA: 42s - loss: 0.2931 - mean_squared_error: 0.064 - ETA: 41s - loss: 0.2925 - mean_squared_error: 0.064 - ETA: 41s - loss: 0.2929 - mean_squared_error: 0.064 - ETA: 40s - loss: 0.2921 - mean_squared_error: 0.064 - ETA: 40s - loss: 0.2912 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2899 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2910 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2901 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2893 - mean_squared_error: 0.063 - ETA: 39s - loss: 0.2888 - mean_squared_error: 0.063 - ETA: 38s - loss: 0.2880 - mean_squared_error: 0.063 - ETA: 38s - loss: 0.2878 - mean_squared_error: 0.063 - ETA: 37s - loss: 0.2875 - mean_squared_error: 0.063 - ETA: 37s - loss: 0.2871 - mean_squared_error: 0.062 - ETA: 36s - loss: 0.2875 - mean_squared_error: 0.062 - ETA: 36s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 36s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 35s - loss: 0.2875 - mean_squared_error: 0.062 - ETA: 35s - loss: 0.2880 - mean_squared_error: 0.063 - ETA: 34s - loss: 0.2870 - mean_squared_error: 0.062 - ETA: 34s - loss: 0.2871 - mean_squared_error: 0.062 - ETA: 34s - loss: 0.2876 - mean_squared_error: 0.063 - ETA: 33s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 33s - loss: 0.2875 - mean_squared_error: 0.062 - ETA: 33s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 32s - loss: 0.2877 - mean_squared_error: 0.062 - ETA: 32s - loss: 0.2878 - mean_squared_error: 0.063 - ETA: 32s - loss: 0.2871 - mean_squared_error: 0.062 - ETA: 31s - loss: 0.2873 - mean_squared_error: 0.062 - ETA: 31s - loss: 0.2870 - mean_squared_error: 0.062 - ETA: 31s - loss: 0.2876 - mean_squared_error: 0.063 - ETA: 30s - loss: 0.2879 - mean_squared_error: 0.063 - ETA: 30s - loss: 0.2876 - mean_squared_error: 0.063 - ETA: 30s - loss: 0.2875 - mean_squared_error: 0.062 - ETA: 29s - loss: 0.2876 - mean_squared_error: 0.062 - ETA: 29s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 29s - loss: 0.2873 - mean_squared_error: 0.062 - ETA: 28s - loss: 0.2880 - mean_squared_error: 0.063 - ETA: 28s - loss: 0.2882 - mean_squared_error: 0.063 - ETA: 27s - loss: 0.2879 - mean_squared_error: 0.063 - ETA: 27s - loss: 0.2875 - mean_squared_error: 0.062 - ETA: 27s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 26s - loss: 0.2873 - mean_squared_error: 0.062 - ETA: 26s - loss: 0.2876 - mean_squared_error: 0.062 - ETA: 26s - loss: 0.2876 - mean_squared_error: 0.062 - ETA: 25s - loss: 0.2875 - mean_squared_error: 0.062 - ETA: 25s - loss: 0.2871 - mean_squared_error: 0.062 - ETA: 25s - loss: 0.2870 - mean_squared_error: 0.062 - ETA: 24s - loss: 0.2867 - mean_squared_error: 0.062 - ETA: 24s - loss: 0.2866 - mean_squared_error: 0.062 - ETA: 24s - loss: 0.2865 - mean_squared_error: 0.062 - ETA: 23s - loss: 0.2863 - mean_squared_error: 0.062 - ETA: 23s - loss: 0.2864 - mean_squared_error: 0.062 - ETA: 22s - loss: 0.2863 - mean_squared_error: 0.062 - ETA: 22s - loss: 0.2865 - mean_squared_error: 0.062 - ETA: 22s - loss: 0.2862 - mean_squared_error: 0.062 - ETA: 21s - loss: 0.2859 - mean_squared_error: 0.062 - ETA: 21s - loss: 0.2858 - mean_squared_error: 0.062 - ETA: 21s - loss: 0.2855 - mean_squared_error: 0.062 - ETA: 20s - loss: 0.2857 - mean_squared_error: 0.062 - ETA: 20s - loss: 0.2856 - mean_squared_error: 0.062 - ETA: 20s - loss: 0.2856 - mean_squared_error: 0.062 - ETA: 19s - loss: 0.2853 - mean_squared_error: 0.062 - ETA: 19s - loss: 0.2850 - mean_squared_error: 0.062 - ETA: 19s - loss: 0.2849 - mean_squared_error: 0.062 - ETA: 18s - loss: 0.2848 - mean_squared_error: 0.062 - ETA: 18s - loss: 0.2848 - mean_squared_error: 0.062 - ETA: 18s - loss: 0.2848 - mean_squared_error: 0.062 - ETA: 17s - loss: 0.2852 - mean_squared_error: 0.062 - ETA: 17s - loss: 0.2852 - mean_squared_error: 0.062 - ETA: 16s - loss: 0.2853 - mean_squared_error: 0.062 - ETA: 16s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 16s - loss: 0.2852 - mean_squared_error: 0.062 - ETA: 15s - loss: 0.2850 - mean_squared_error: 0.062 - ETA: 15s - loss: 0.2850 - mean_squared_error: 0.062 - ETA: 15s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 14s - loss: 0.2852 - mean_squared_error: 0.062 - ETA: 14s - loss: 0.2850 - mean_squared_error: 0.062 - ETA: 14s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 13s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 13s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 13s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 12s - loss: 0.2851 - mean_squared_error: 0.062 - ETA: 12s - loss: 0.2852 - mean_squared_error: 0.062 - ETA: 12s - loss: 0.2854 - mean_squared_error: 0.062 - ETA: 11s - loss: 0.2853 - mean_squared_error: 0.062 - ETA: 11s - loss: 0.2849 - mean_squared_error: 0.062 - ETA: 11s - loss: 0.2850 - mean_squared_error: 0.062 - ETA: 10s - loss: 0.2847 - mean_squared_error: 0.062 - ETA: 10s - loss: 0.2845 - mean_squared_error: 0.062 - ETA: 10s - loss: 0.2846 - mean_squared_error: 0.062 - ETA: 9s - loss: 0.2848 - mean_squared_error: 0.062 - ETA: 9s - loss: 0.2848 - mean_squared_error: 0.06 - ETA: 9s - loss: 0.2848 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2846 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2845 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2846 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2845 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2845 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2844 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2843 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2842 - mean_squared_error: 0.06 - ETA: 6s - loss: 0.2841 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2839 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2841 - mean_squared_error: 0.06 - ETA: 5s - loss: 0.2840 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2839 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2838 - mean_squared_error: 0.06 - ETA: 4s - loss: 0.2837 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2838 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2837 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2835 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2835 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2836 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2835 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2834 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2835 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2833 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2831 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2831 - mean_squared_error: 0.06 - 45s 11ms/step - loss: 0.2830 - mean_squared_error: 0.0616 - val_loss: 0.2664 - val_mean_squared_error: 0.0562\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 43s - loss: 0.2804 - mean_squared_error: 0.059 - ETA: 43s - loss: 0.2712 - mean_squared_error: 0.057 - ETA: 44s - loss: 0.2734 - mean_squared_error: 0.058 - ETA: 44s - loss: 0.2777 - mean_squared_error: 0.059 - ETA: 44s - loss: 0.2787 - mean_squared_error: 0.059 - ETA: 44s - loss: 0.2796 - mean_squared_error: 0.060 - ETA: 43s - loss: 0.2810 - mean_squared_error: 0.060 - ETA: 43s - loss: 0.2797 - mean_squared_error: 0.060 - ETA: 43s - loss: 0.2800 - mean_squared_error: 0.060 - ETA: 42s - loss: 0.2794 - mean_squared_error: 0.060 - ETA: 42s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 41s - loss: 0.2795 - mean_squared_error: 0.060 - ETA: 41s - loss: 0.2797 - mean_squared_error: 0.060 - ETA: 40s - loss: 0.2803 - mean_squared_error: 0.060 - ETA: 40s - loss: 0.2791 - mean_squared_error: 0.060 - ETA: 39s - loss: 0.2779 - mean_squared_error: 0.059 - ETA: 39s - loss: 0.2787 - mean_squared_error: 0.059 - ETA: 39s - loss: 0.2774 - mean_squared_error: 0.059 - ETA: 38s - loss: 0.2775 - mean_squared_error: 0.059 - ETA: 38s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 37s - loss: 0.2781 - mean_squared_error: 0.060 - ETA: 37s - loss: 0.2772 - mean_squared_error: 0.059 - ETA: 36s - loss: 0.2777 - mean_squared_error: 0.059 - ETA: 36s - loss: 0.2776 - mean_squared_error: 0.059 - ETA: 35s - loss: 0.2774 - mean_squared_error: 0.059 - ETA: 35s - loss: 0.2775 - mean_squared_error: 0.059 - ETA: 34s - loss: 0.2775 - mean_squared_error: 0.059 - ETA: 34s - loss: 0.2766 - mean_squared_error: 0.059 - ETA: 33s - loss: 0.2783 - mean_squared_error: 0.060 - ETA: 33s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 33s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 32s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 32s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 31s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 31s - loss: 0.2791 - mean_squared_error: 0.060 - ETA: 31s - loss: 0.2793 - mean_squared_error: 0.060 - ETA: 30s - loss: 0.2792 - mean_squared_error: 0.060 - ETA: 30s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 29s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 29s - loss: 0.2789 - mean_squared_error: 0.060 - ETA: 29s - loss: 0.2791 - mean_squared_error: 0.060 - ETA: 28s - loss: 0.2789 - mean_squared_error: 0.060 - ETA: 28s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 28s - loss: 0.2788 - mean_squared_error: 0.060 - ETA: 27s - loss: 0.2784 - mean_squared_error: 0.060 - ETA: 27s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 27s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 26s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 26s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 26s - loss: 0.2793 - mean_squared_error: 0.060 - ETA: 25s - loss: 0.2793 - mean_squared_error: 0.060 - ETA: 25s - loss: 0.2793 - mean_squared_error: 0.060 - ETA: 24s - loss: 0.2803 - mean_squared_error: 0.060 - ETA: 24s - loss: 0.2800 - mean_squared_error: 0.060 - ETA: 24s - loss: 0.2796 - mean_squared_error: 0.060 - ETA: 23s - loss: 0.2795 - mean_squared_error: 0.060 - ETA: 23s - loss: 0.2794 - mean_squared_error: 0.060 - ETA: 23s - loss: 0.2794 - mean_squared_error: 0.060 - ETA: 22s - loss: 0.2792 - mean_squared_error: 0.060 - ETA: 22s - loss: 0.2791 - mean_squared_error: 0.060 - ETA: 22s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 21s - loss: 0.2789 - mean_squared_error: 0.060 - ETA: 21s - loss: 0.2789 - mean_squared_error: 0.060 - ETA: 21s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 20s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 20s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 20s - loss: 0.2782 - mean_squared_error: 0.060 - ETA: 19s - loss: 0.2782 - mean_squared_error: 0.060 - ETA: 19s - loss: 0.2781 - mean_squared_error: 0.060 - ETA: 19s - loss: 0.2782 - mean_squared_error: 0.060 - ETA: 18s - loss: 0.2781 - mean_squared_error: 0.060 - ETA: 18s - loss: 0.2783 - mean_squared_error: 0.060 - ETA: 18s - loss: 0.2782 - mean_squared_error: 0.060 - ETA: 17s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 17s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 17s - loss: 0.2788 - mean_squared_error: 0.060 - ETA: 16s - loss: 0.2788 - mean_squared_error: 0.060 - ETA: 16s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 15s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 15s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 15s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 14s - loss: 0.2787 - mean_squared_error: 0.060 - ETA: 14s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 14s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 13s - loss: 0.2784 - mean_squared_error: 0.060 - ETA: 13s - loss: 0.2784 - mean_squared_error: 0.060 - ETA: 13s - loss: 0.2783 - mean_squared_error: 0.060 - ETA: 12s - loss: 0.2783 - mean_squared_error: 0.059 - ETA: 12s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 12s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 11s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 11s - loss: 0.2786 - mean_squared_error: 0.060 - ETA: 11s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 10s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 10s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 10s - loss: 0.2784 - mean_squared_error: 0.060 - ETA: 9s - loss: 0.2785 - mean_squared_error: 0.060 - ETA: 9s - loss: 0.2785 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2784 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2786 - mean_squared_error: 0.06 - ETA: 8s - loss: 0.2785 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2783 - mean_squared_error: 0.06 - ETA: 7s - loss: 0.2782 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2781 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2781 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2781 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2782 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2783 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2783 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2783 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2782 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2783 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2784 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2786 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2786 - mean_squared_error: 0.06 - ETA: 3s - loss: 0.2785 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2786 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2787 - mean_squared_error: 0.06 - ETA: 2s - loss: 0.2789 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2790 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2790 - mean_squared_error: 0.06 - ETA: 1s - loss: 0.2790 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2791 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.2791 - mean_squared_error: 0.06 - 46s 11ms/step - loss: 0.2790 - mean_squared_error: 0.0601 - val_loss: 0.2624 - val_mean_squared_error: 0.0548\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 38s - loss: 0.2839 - mean_squared_error: 0.060 - ETA: 40s - loss: 0.2733 - mean_squared_error: 0.057 - ETA: 39s - loss: 0.2808 - mean_squared_error: 0.059 - ETA: 39s - loss: 0.2785 - mean_squared_error: 0.059 - ETA: 39s - loss: 0.2731 - mean_squared_error: 0.058 - ETA: 39s - loss: 0.2759 - mean_squared_error: 0.059 - ETA: 38s - loss: 0.2773 - mean_squared_error: 0.059 - ETA: 38s - loss: 0.2790 - mean_squared_error: 0.060 - ETA: 38s - loss: 0.2781 - mean_squared_error: 0.059 - ETA: 38s - loss: 0.2785 - mean_squared_error: 0.059 - ETA: 37s - loss: 0.2793 - mean_squared_error: 0.060 - ETA: 37s - loss: 0.2782 - mean_squared_error: 0.059 - ETA: 37s - loss: 0.2777 - mean_squared_error: 0.059 - ETA: 37s - loss: 0.2788 - mean_squared_error: 0.059 - ETA: 36s - loss: 0.2786 - mean_squared_error: 0.059 - ETA: 36s - loss: 0.2792 - mean_squared_error: 0.060 - ETA: 36s - loss: 0.2789 - mean_squared_error: 0.059 - ETA: 36s - loss: 0.2785 - mean_squared_error: 0.059 - ETA: 35s - loss: 0.2766 - mean_squared_error: 0.059 - ETA: 35s - loss: 0.2774 - mean_squared_error: 0.059 - ETA: 35s - loss: 0.2765 - mean_squared_error: 0.059 - ETA: 35s - loss: 0.2764 - mean_squared_error: 0.059 - ETA: 34s - loss: 0.2763 - mean_squared_error: 0.059 - ETA: 34s - loss: 0.2761 - mean_squared_error: 0.059 - ETA: 34s - loss: 0.2761 - mean_squared_error: 0.059 - ETA: 34s - loss: 0.2756 - mean_squared_error: 0.058 - ETA: 33s - loss: 0.2765 - mean_squared_error: 0.059 - ETA: 33s - loss: 0.2769 - mean_squared_error: 0.059 - ETA: 33s - loss: 0.2769 - mean_squared_error: 0.059 - ETA: 33s - loss: 0.2772 - mean_squared_error: 0.059 - ETA: 32s - loss: 0.2766 - mean_squared_error: 0.059 - ETA: 32s - loss: 0.2765 - mean_squared_error: 0.059 - ETA: 32s - loss: 0.2758 - mean_squared_error: 0.059 - ETA: 31s - loss: 0.2763 - mean_squared_error: 0.059 - ETA: 31s - loss: 0.2767 - mean_squared_error: 0.059 - ETA: 31s - loss: 0.2764 - mean_squared_error: 0.059 - ETA: 30s - loss: 0.2768 - mean_squared_error: 0.059 - ETA: 30s - loss: 0.2774 - mean_squared_error: 0.059 - ETA: 30s - loss: 0.2773 - mean_squared_error: 0.059 - ETA: 29s - loss: 0.2772 - mean_squared_error: 0.059 - ETA: 29s - loss: 0.2773 - mean_squared_error: 0.059 - ETA: 29s - loss: 0.2774 - mean_squared_error: 0.059 - ETA: 28s - loss: 0.2776 - mean_squared_error: 0.059 - ETA: 28s - loss: 0.2772 - mean_squared_error: 0.059 - ETA: 28s - loss: 0.2771 - mean_squared_error: 0.059 - ETA: 27s - loss: 0.2771 - mean_squared_error: 0.059 - ETA: 27s - loss: 0.2772 - mean_squared_error: 0.059 - ETA: 27s - loss: 0.2768 - mean_squared_error: 0.059 - ETA: 26s - loss: 0.2762 - mean_squared_error: 0.059 - ETA: 26s - loss: 0.2766 - mean_squared_error: 0.059 - ETA: 26s - loss: 0.2762 - mean_squared_error: 0.059 - ETA: 25s - loss: 0.2763 - mean_squared_error: 0.059 - ETA: 25s - loss: 0.2768 - mean_squared_error: 0.059 - ETA: 24s - loss: 0.2767 - mean_squared_error: 0.059 - ETA: 24s - loss: 0.2765 - mean_squared_error: 0.059 - ETA: 24s - loss: 0.2762 - mean_squared_error: 0.059 - ETA: 23s - loss: 0.2765 - mean_squared_error: 0.059 - ETA: 23s - loss: 0.2764 - mean_squared_error: 0.059 - ETA: 23s - loss: 0.2761 - mean_squared_error: 0.059 - ETA: 22s - loss: 0.2757 - mean_squared_error: 0.058 - ETA: 22s - loss: 0.2755 - mean_squared_error: 0.058 - ETA: 22s - loss: 0.2754 - mean_squared_error: 0.058 - ETA: 21s - loss: 0.2752 - mean_squared_error: 0.058 - ETA: 21s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 21s - loss: 0.2748 - mean_squared_error: 0.058 - ETA: 20s - loss: 0.2749 - mean_squared_error: 0.058 - ETA: 20s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 20s - loss: 0.2748 - mean_squared_error: 0.058 - ETA: 19s - loss: 0.2748 - mean_squared_error: 0.058 - ETA: 19s - loss: 0.2745 - mean_squared_error: 0.058 - ETA: 19s - loss: 0.2746 - mean_squared_error: 0.058 - ETA: 18s - loss: 0.2747 - mean_squared_error: 0.058 - ETA: 18s - loss: 0.2748 - mean_squared_error: 0.058 - ETA: 17s - loss: 0.2748 - mean_squared_error: 0.058 - ETA: 17s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 17s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 16s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 16s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 16s - loss: 0.2748 - mean_squared_error: 0.058 - ETA: 15s - loss: 0.2751 - mean_squared_error: 0.058 - ETA: 15s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 15s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 14s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 14s - loss: 0.2749 - mean_squared_error: 0.058 - ETA: 14s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 13s - loss: 0.2750 - mean_squared_error: 0.058 - ETA: 13s - loss: 0.2751 - mean_squared_error: 0.058 - ETA: 13s - loss: 0.2752 - mean_squared_error: 0.058 - ETA: 12s - loss: 0.2752 - mean_squared_error: 0.058 - ETA: 12s - loss: 0.2752 - mean_squared_error: 0.058 - ETA: 12s - loss: 0.2751 - mean_squared_error: 0.058 - ETA: 11s - loss: 0.2753 - mean_squared_error: 0.058 - ETA: 11s - loss: 0.2754 - mean_squared_error: 0.058 - ETA: 11s - loss: 0.2754 - mean_squared_error: 0.058 - ETA: 10s - loss: 0.2755 - mean_squared_error: 0.058 - ETA: 10s - loss: 0.2757 - mean_squared_error: 0.058 - ETA: 9s - loss: 0.2760 - mean_squared_error: 0.058 - ETA: 9s - loss: 0.2760 - mean_squared_error: 0.05 - ETA: 9s - loss: 0.2759 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2758 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2761 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2759 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2757 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2759 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2755 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2755 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2755 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2755 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2753 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2753 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2753 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2752 - mean_squared_error: 0.05 - 48s 12ms/step - loss: 0.2752 - mean_squared_error: 0.0587 - val_loss: 0.2596 - val_mean_squared_error: 0.0536\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 47s - loss: 0.2821 - mean_squared_error: 0.061 - ETA: 47s - loss: 0.2810 - mean_squared_error: 0.060 - ETA: 47s - loss: 0.2710 - mean_squared_error: 0.057 - ETA: 46s - loss: 0.2690 - mean_squared_error: 0.057 - ETA: 45s - loss: 0.2684 - mean_squared_error: 0.056 - ETA: 44s - loss: 0.2692 - mean_squared_error: 0.057 - ETA: 45s - loss: 0.2694 - mean_squared_error: 0.057 - ETA: 44s - loss: 0.2692 - mean_squared_error: 0.057 - ETA: 44s - loss: 0.2679 - mean_squared_error: 0.056 - ETA: 44s - loss: 0.2674 - mean_squared_error: 0.056 - ETA: 43s - loss: 0.2686 - mean_squared_error: 0.056 - ETA: 43s - loss: 0.2703 - mean_squared_error: 0.057 - ETA: 43s - loss: 0.2696 - mean_squared_error: 0.057 - ETA: 42s - loss: 0.2695 - mean_squared_error: 0.057 - ETA: 41s - loss: 0.2704 - mean_squared_error: 0.057 - ETA: 41s - loss: 0.2698 - mean_squared_error: 0.057 - ETA: 40s - loss: 0.2695 - mean_squared_error: 0.057 - ETA: 39s - loss: 0.2687 - mean_squared_error: 0.056 - ETA: 39s - loss: 0.2680 - mean_squared_error: 0.056 - ETA: 38s - loss: 0.2689 - mean_squared_error: 0.057 - ETA: 38s - loss: 0.2693 - mean_squared_error: 0.057 - ETA: 37s - loss: 0.2689 - mean_squared_error: 0.057 - ETA: 36s - loss: 0.2691 - mean_squared_error: 0.057 - ETA: 36s - loss: 0.2704 - mean_squared_error: 0.057 - ETA: 35s - loss: 0.2704 - mean_squared_error: 0.057 - ETA: 35s - loss: 0.2697 - mean_squared_error: 0.057 - ETA: 35s - loss: 0.2701 - mean_squared_error: 0.057 - ETA: 34s - loss: 0.2703 - mean_squared_error: 0.057 - ETA: 34s - loss: 0.2699 - mean_squared_error: 0.057 - ETA: 34s - loss: 0.2697 - mean_squared_error: 0.057 - ETA: 33s - loss: 0.2691 - mean_squared_error: 0.057 - ETA: 33s - loss: 0.2689 - mean_squared_error: 0.057 - ETA: 33s - loss: 0.2692 - mean_squared_error: 0.057 - ETA: 33s - loss: 0.2689 - mean_squared_error: 0.056 - ETA: 32s - loss: 0.2698 - mean_squared_error: 0.057 - ETA: 32s - loss: 0.2702 - mean_squared_error: 0.057 - ETA: 32s - loss: 0.2703 - mean_squared_error: 0.057 - ETA: 32s - loss: 0.2702 - mean_squared_error: 0.057 - ETA: 31s - loss: 0.2702 - mean_squared_error: 0.057 - ETA: 31s - loss: 0.2701 - mean_squared_error: 0.057 - ETA: 30s - loss: 0.2703 - mean_squared_error: 0.057 - ETA: 30s - loss: 0.2703 - mean_squared_error: 0.057 - ETA: 30s - loss: 0.2707 - mean_squared_error: 0.057 - ETA: 29s - loss: 0.2705 - mean_squared_error: 0.057 - ETA: 29s - loss: 0.2704 - mean_squared_error: 0.057 - ETA: 28s - loss: 0.2696 - mean_squared_error: 0.057 - ETA: 28s - loss: 0.2697 - mean_squared_error: 0.057 - ETA: 28s - loss: 0.2701 - mean_squared_error: 0.057 - ETA: 27s - loss: 0.2707 - mean_squared_error: 0.057 - ETA: 27s - loss: 0.2709 - mean_squared_error: 0.057 - ETA: 26s - loss: 0.2708 - mean_squared_error: 0.057 - ETA: 26s - loss: 0.2709 - mean_squared_error: 0.057 - ETA: 26s - loss: 0.2707 - mean_squared_error: 0.057 - ETA: 25s - loss: 0.2711 - mean_squared_error: 0.057 - ETA: 25s - loss: 0.2712 - mean_squared_error: 0.057 - ETA: 24s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 24s - loss: 0.2714 - mean_squared_error: 0.057 - ETA: 24s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 23s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 23s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 22s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 22s - loss: 0.2713 - mean_squared_error: 0.057 - ETA: 22s - loss: 0.2712 - mean_squared_error: 0.057 - ETA: 21s - loss: 0.2712 - mean_squared_error: 0.057 - ETA: 21s - loss: 0.2710 - mean_squared_error: 0.057 - ETA: 21s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 20s - loss: 0.2718 - mean_squared_error: 0.057 - ETA: 20s - loss: 0.2717 - mean_squared_error: 0.057 - ETA: 19s - loss: 0.2718 - mean_squared_error: 0.057 - ETA: 19s - loss: 0.2718 - mean_squared_error: 0.057 - ETA: 19s - loss: 0.2716 - mean_squared_error: 0.057 - ETA: 18s - loss: 0.2715 - mean_squared_error: 0.057 - ETA: 18s - loss: 0.2718 - mean_squared_error: 0.057 - ETA: 18s - loss: 0.2719 - mean_squared_error: 0.057 - ETA: 17s - loss: 0.2720 - mean_squared_error: 0.057 - ETA: 17s - loss: 0.2720 - mean_squared_error: 0.057 - ETA: 17s - loss: 0.2723 - mean_squared_error: 0.057 - ETA: 16s - loss: 0.2724 - mean_squared_error: 0.057 - ETA: 16s - loss: 0.2728 - mean_squared_error: 0.057 - ETA: 15s - loss: 0.2730 - mean_squared_error: 0.057 - ETA: 15s - loss: 0.2728 - mean_squared_error: 0.057 - ETA: 15s - loss: 0.2727 - mean_squared_error: 0.057 - ETA: 14s - loss: 0.2728 - mean_squared_error: 0.057 - ETA: 14s - loss: 0.2728 - mean_squared_error: 0.057 - ETA: 14s - loss: 0.2727 - mean_squared_error: 0.057 - ETA: 13s - loss: 0.2727 - mean_squared_error: 0.057 - ETA: 13s - loss: 0.2726 - mean_squared_error: 0.057 - ETA: 13s - loss: 0.2726 - mean_squared_error: 0.057 - ETA: 12s - loss: 0.2727 - mean_squared_error: 0.057 - ETA: 12s - loss: 0.2725 - mean_squared_error: 0.057 - ETA: 12s - loss: 0.2727 - mean_squared_error: 0.057 - ETA: 11s - loss: 0.2728 - mean_squared_error: 0.057 - ETA: 11s - loss: 0.2726 - mean_squared_error: 0.057 - ETA: 11s - loss: 0.2727 - mean_squared_error: 0.057 - ETA: 10s - loss: 0.2726 - mean_squared_error: 0.057 - ETA: 10s - loss: 0.2726 - mean_squared_error: 0.057 - ETA: 9s - loss: 0.2725 - mean_squared_error: 0.057 - ETA: 9s - loss: 0.2722 - mean_squared_error: 0.05 - ETA: 9s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2721 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2725 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2723 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2723 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2725 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2724 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2727 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2726 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2728 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2727 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2727 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2728 - mean_squared_error: 0.05 - 46s 12ms/step - loss: 0.2728 - mean_squared_error: 0.0578 - val_loss: 0.2584 - val_mean_squared_error: 0.0529\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 45s - loss: 0.2700 - mean_squared_error: 0.057 - ETA: 45s - loss: 0.2604 - mean_squared_error: 0.054 - ETA: 46s - loss: 0.2600 - mean_squared_error: 0.054 - ETA: 46s - loss: 0.2650 - mean_squared_error: 0.055 - ETA: 46s - loss: 0.2654 - mean_squared_error: 0.056 - ETA: 46s - loss: 0.2638 - mean_squared_error: 0.055 - ETA: 45s - loss: 0.2645 - mean_squared_error: 0.055 - ETA: 44s - loss: 0.2653 - mean_squared_error: 0.055 - ETA: 44s - loss: 0.2650 - mean_squared_error: 0.055 - ETA: 43s - loss: 0.2646 - mean_squared_error: 0.055 - ETA: 43s - loss: 0.2648 - mean_squared_error: 0.055 - ETA: 42s - loss: 0.2673 - mean_squared_error: 0.056 - ETA: 42s - loss: 0.2672 - mean_squared_error: 0.056 - ETA: 42s - loss: 0.2680 - mean_squared_error: 0.056 - ETA: 41s - loss: 0.2688 - mean_squared_error: 0.056 - ETA: 41s - loss: 0.2690 - mean_squared_error: 0.056 - ETA: 41s - loss: 0.2707 - mean_squared_error: 0.057 - ETA: 40s - loss: 0.2711 - mean_squared_error: 0.057 - ETA: 40s - loss: 0.2711 - mean_squared_error: 0.057 - ETA: 39s - loss: 0.2712 - mean_squared_error: 0.057 - ETA: 39s - loss: 0.2711 - mean_squared_error: 0.057 - ETA: 38s - loss: 0.2712 - mean_squared_error: 0.057 - ETA: 38s - loss: 0.2711 - mean_squared_error: 0.057 - ETA: 37s - loss: 0.2718 - mean_squared_error: 0.057 - ETA: 37s - loss: 0.2716 - mean_squared_error: 0.057 - ETA: 37s - loss: 0.2714 - mean_squared_error: 0.057 - ETA: 36s - loss: 0.2706 - mean_squared_error: 0.057 - ETA: 36s - loss: 0.2707 - mean_squared_error: 0.057 - ETA: 35s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 35s - loss: 0.2701 - mean_squared_error: 0.056 - ETA: 34s - loss: 0.2703 - mean_squared_error: 0.056 - ETA: 34s - loss: 0.2703 - mean_squared_error: 0.056 - ETA: 34s - loss: 0.2698 - mean_squared_error: 0.056 - ETA: 33s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 33s - loss: 0.2701 - mean_squared_error: 0.056 - ETA: 32s - loss: 0.2696 - mean_squared_error: 0.056 - ETA: 32s - loss: 0.2696 - mean_squared_error: 0.056 - ETA: 32s - loss: 0.2694 - mean_squared_error: 0.056 - ETA: 31s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 31s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 30s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 30s - loss: 0.2698 - mean_squared_error: 0.056 - ETA: 29s - loss: 0.2696 - mean_squared_error: 0.056 - ETA: 29s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 29s - loss: 0.2693 - mean_squared_error: 0.056 - ETA: 28s - loss: 0.2698 - mean_squared_error: 0.056 - ETA: 28s - loss: 0.2702 - mean_squared_error: 0.056 - ETA: 28s - loss: 0.2704 - mean_squared_error: 0.056 - ETA: 27s - loss: 0.2701 - mean_squared_error: 0.056 - ETA: 27s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 26s - loss: 0.2696 - mean_squared_error: 0.056 - ETA: 26s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 26s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 25s - loss: 0.2691 - mean_squared_error: 0.056 - ETA: 25s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 24s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 24s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 24s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 23s - loss: 0.2694 - mean_squared_error: 0.056 - ETA: 23s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 23s - loss: 0.2693 - mean_squared_error: 0.056 - ETA: 22s - loss: 0.2695 - mean_squared_error: 0.056 - ETA: 22s - loss: 0.2693 - mean_squared_error: 0.056 - ETA: 22s - loss: 0.2691 - mean_squared_error: 0.056 - ETA: 21s - loss: 0.2691 - mean_squared_error: 0.056 - ETA: 21s - loss: 0.2689 - mean_squared_error: 0.056 - ETA: 20s - loss: 0.2689 - mean_squared_error: 0.056 - ETA: 20s - loss: 0.2691 - mean_squared_error: 0.056 - ETA: 20s - loss: 0.2690 - mean_squared_error: 0.056 - ETA: 19s - loss: 0.2691 - mean_squared_error: 0.056 - ETA: 19s - loss: 0.2693 - mean_squared_error: 0.056 - ETA: 19s - loss: 0.2694 - mean_squared_error: 0.056 - ETA: 18s - loss: 0.2694 - mean_squared_error: 0.056 - ETA: 18s - loss: 0.2694 - mean_squared_error: 0.056 - ETA: 18s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 17s - loss: 0.2698 - mean_squared_error: 0.056 - ETA: 17s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 16s - loss: 0.2702 - mean_squared_error: 0.056 - ETA: 16s - loss: 0.2703 - mean_squared_error: 0.056 - ETA: 16s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 15s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 15s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 15s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 14s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 14s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 14s - loss: 0.2698 - mean_squared_error: 0.056 - ETA: 13s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 13s - loss: 0.2698 - mean_squared_error: 0.056 - ETA: 12s - loss: 0.2697 - mean_squared_error: 0.056 - ETA: 12s - loss: 0.2699 - mean_squared_error: 0.056 - ETA: 12s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 11s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 11s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 11s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 10s - loss: 0.2702 - mean_squared_error: 0.056 - ETA: 10s - loss: 0.2701 - mean_squared_error: 0.056 - ETA: 10s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 9s - loss: 0.2700 - mean_squared_error: 0.056 - ETA: 9s - loss: 0.2701 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2702 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2703 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2701 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2702 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2703 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2705 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2706 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2706 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2703 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2704 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2703 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2704 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2703 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2705 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2706 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2706 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2707 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2707 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2709 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2709 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2708 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2708 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2708 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2707 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2706 - mean_squared_error: 0.05 - 48s 12ms/step - loss: 0.2705 - mean_squared_error: 0.0569 - val_loss: 0.2540 - val_mean_squared_error: 0.0515\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 53s - loss: 0.3188 - mean_squared_error: 0.074 - ETA: 56s - loss: 0.3127 - mean_squared_error: 0.070 - ETA: 53s - loss: 0.3062 - mean_squared_error: 0.069 - ETA: 52s - loss: 0.3064 - mean_squared_error: 0.068 - ETA: 52s - loss: 0.3061 - mean_squared_error: 0.068 - ETA: 51s - loss: 0.3028 - mean_squared_error: 0.067 - ETA: 51s - loss: 0.2998 - mean_squared_error: 0.066 - ETA: 49s - loss: 0.2993 - mean_squared_error: 0.066 - ETA: 48s - loss: 0.2973 - mean_squared_error: 0.066 - ETA: 47s - loss: 0.2963 - mean_squared_error: 0.065 - ETA: 46s - loss: 0.2970 - mean_squared_error: 0.065 - ETA: 47s - loss: 0.2964 - mean_squared_error: 0.065 - ETA: 46s - loss: 0.2972 - mean_squared_error: 0.065 - ETA: 46s - loss: 0.2975 - mean_squared_error: 0.065 - ETA: 45s - loss: 0.2970 - mean_squared_error: 0.065 - ETA: 44s - loss: 0.2969 - mean_squared_error: 0.065 - ETA: 43s - loss: 0.2970 - mean_squared_error: 0.065 - ETA: 43s - loss: 0.2961 - mean_squared_error: 0.065 - ETA: 42s - loss: 0.2954 - mean_squared_error: 0.065 - ETA: 41s - loss: 0.2952 - mean_squared_error: 0.065 - ETA: 41s - loss: 0.2946 - mean_squared_error: 0.065 - ETA: 40s - loss: 0.2948 - mean_squared_error: 0.065 - ETA: 40s - loss: 0.2940 - mean_squared_error: 0.064 - ETA: 39s - loss: 0.2933 - mean_squared_error: 0.064 - ETA: 39s - loss: 0.2931 - mean_squared_error: 0.064 - ETA: 38s - loss: 0.2927 - mean_squared_error: 0.064 - ETA: 38s - loss: 0.2922 - mean_squared_error: 0.064 - ETA: 37s - loss: 0.2919 - mean_squared_error: 0.064 - ETA: 37s - loss: 0.2912 - mean_squared_error: 0.063 - ETA: 36s - loss: 0.2907 - mean_squared_error: 0.063 - ETA: 36s - loss: 0.2901 - mean_squared_error: 0.063 - ETA: 35s - loss: 0.2900 - mean_squared_error: 0.063 - ETA: 35s - loss: 0.2892 - mean_squared_error: 0.063 - ETA: 34s - loss: 0.2891 - mean_squared_error: 0.063 - ETA: 34s - loss: 0.2885 - mean_squared_error: 0.063 - ETA: 33s - loss: 0.2874 - mean_squared_error: 0.062 - ETA: 33s - loss: 0.2870 - mean_squared_error: 0.062 - ETA: 33s - loss: 0.2863 - mean_squared_error: 0.062 - ETA: 32s - loss: 0.2864 - mean_squared_error: 0.062 - ETA: 32s - loss: 0.2862 - mean_squared_error: 0.062 - ETA: 31s - loss: 0.2861 - mean_squared_error: 0.062 - ETA: 31s - loss: 0.2860 - mean_squared_error: 0.062 - ETA: 30s - loss: 0.2858 - mean_squared_error: 0.062 - ETA: 30s - loss: 0.2857 - mean_squared_error: 0.062 - ETA: 30s - loss: 0.2855 - mean_squared_error: 0.062 - ETA: 29s - loss: 0.2854 - mean_squared_error: 0.062 - ETA: 29s - loss: 0.2848 - mean_squared_error: 0.061 - ETA: 28s - loss: 0.2846 - mean_squared_error: 0.061 - ETA: 28s - loss: 0.2848 - mean_squared_error: 0.061 - ETA: 28s - loss: 0.2843 - mean_squared_error: 0.061 - ETA: 27s - loss: 0.2842 - mean_squared_error: 0.061 - ETA: 27s - loss: 0.2839 - mean_squared_error: 0.061 - ETA: 26s - loss: 0.2838 - mean_squared_error: 0.061 - ETA: 26s - loss: 0.2837 - mean_squared_error: 0.061 - ETA: 26s - loss: 0.2835 - mean_squared_error: 0.061 - ETA: 25s - loss: 0.2831 - mean_squared_error: 0.061 - ETA: 25s - loss: 0.2826 - mean_squared_error: 0.061 - ETA: 24s - loss: 0.2827 - mean_squared_error: 0.061 - ETA: 24s - loss: 0.2826 - mean_squared_error: 0.061 - ETA: 24s - loss: 0.2822 - mean_squared_error: 0.061 - ETA: 23s - loss: 0.2822 - mean_squared_error: 0.061 - ETA: 23s - loss: 0.2822 - mean_squared_error: 0.061 - ETA: 23s - loss: 0.2820 - mean_squared_error: 0.061 - ETA: 22s - loss: 0.2818 - mean_squared_error: 0.060 - ETA: 22s - loss: 0.2816 - mean_squared_error: 0.060 - ETA: 21s - loss: 0.2813 - mean_squared_error: 0.060 - ETA: 21s - loss: 0.2811 - mean_squared_error: 0.060 - ETA: 21s - loss: 0.2812 - mean_squared_error: 0.060 - ETA: 20s - loss: 0.2810 - mean_squared_error: 0.060 - ETA: 20s - loss: 0.2809 - mean_squared_error: 0.060 - ETA: 19s - loss: 0.2809 - mean_squared_error: 0.060 - ETA: 19s - loss: 0.2808 - mean_squared_error: 0.060 - ETA: 19s - loss: 0.2807 - mean_squared_error: 0.060 - ETA: 18s - loss: 0.2806 - mean_squared_error: 0.060 - ETA: 18s - loss: 0.2804 - mean_squared_error: 0.060 - ETA: 18s - loss: 0.2801 - mean_squared_error: 0.060 - ETA: 17s - loss: 0.2802 - mean_squared_error: 0.060 - ETA: 17s - loss: 0.2800 - mean_squared_error: 0.060 - ETA: 17s - loss: 0.2797 - mean_squared_error: 0.060 - ETA: 16s - loss: 0.2796 - mean_squared_error: 0.060 - ETA: 16s - loss: 0.2794 - mean_squared_error: 0.060 - ETA: 15s - loss: 0.2792 - mean_squared_error: 0.060 - ETA: 15s - loss: 0.2790 - mean_squared_error: 0.059 - ETA: 15s - loss: 0.2791 - mean_squared_error: 0.059 - ETA: 14s - loss: 0.2787 - mean_squared_error: 0.059 - ETA: 14s - loss: 0.2785 - mean_squared_error: 0.059 - ETA: 14s - loss: 0.2783 - mean_squared_error: 0.059 - ETA: 13s - loss: 0.2781 - mean_squared_error: 0.059 - ETA: 13s - loss: 0.2779 - mean_squared_error: 0.059 - ETA: 12s - loss: 0.2779 - mean_squared_error: 0.059 - ETA: 12s - loss: 0.2778 - mean_squared_error: 0.059 - ETA: 12s - loss: 0.2775 - mean_squared_error: 0.059 - ETA: 11s - loss: 0.2774 - mean_squared_error: 0.059 - ETA: 11s - loss: 0.2771 - mean_squared_error: 0.059 - ETA: 11s - loss: 0.2769 - mean_squared_error: 0.059 - ETA: 10s - loss: 0.2768 - mean_squared_error: 0.059 - ETA: 10s - loss: 0.2766 - mean_squared_error: 0.059 - ETA: 9s - loss: 0.2763 - mean_squared_error: 0.058 - ETA: 9s - loss: 0.2763 - mean_squared_error: 0.05 - ETA: 9s - loss: 0.2762 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2759 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2757 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2757 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2756 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2754 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2753 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2753 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2752 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2751 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2750 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2748 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2747 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2746 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2744 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2743 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2741 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2739 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2739 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2738 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2736 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2735 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2733 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2732 - mean_squared_error: 0.05 - 48s 12ms/step - loss: 0.2732 - mean_squared_error: 0.0578 - val_loss: 0.2461 - val_mean_squared_error: 0.0480\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 44s - loss: 0.2742 - mean_squared_error: 0.057 - ETA: 44s - loss: 0.2675 - mean_squared_error: 0.054 - ETA: 44s - loss: 0.2651 - mean_squared_error: 0.054 - ETA: 43s - loss: 0.2627 - mean_squared_error: 0.053 - ETA: 43s - loss: 0.2624 - mean_squared_error: 0.053 - ETA: 42s - loss: 0.2595 - mean_squared_error: 0.053 - ETA: 42s - loss: 0.2626 - mean_squared_error: 0.053 - ETA: 42s - loss: 0.2607 - mean_squared_error: 0.053 - ETA: 42s - loss: 0.2603 - mean_squared_error: 0.053 - ETA: 41s - loss: 0.2599 - mean_squared_error: 0.052 - ETA: 41s - loss: 0.2589 - mean_squared_error: 0.052 - ETA: 40s - loss: 0.2584 - mean_squared_error: 0.052 - ETA: 40s - loss: 0.2572 - mean_squared_error: 0.052 - ETA: 40s - loss: 0.2567 - mean_squared_error: 0.052 - ETA: 40s - loss: 0.2562 - mean_squared_error: 0.051 - ETA: 39s - loss: 0.2563 - mean_squared_error: 0.051 - ETA: 39s - loss: 0.2570 - mean_squared_error: 0.052 - ETA: 38s - loss: 0.2573 - mean_squared_error: 0.052 - ETA: 38s - loss: 0.2567 - mean_squared_error: 0.051 - ETA: 38s - loss: 0.2576 - mean_squared_error: 0.052 - ETA: 37s - loss: 0.2574 - mean_squared_error: 0.052 - ETA: 37s - loss: 0.2568 - mean_squared_error: 0.051 - ETA: 37s - loss: 0.2567 - mean_squared_error: 0.052 - ETA: 36s - loss: 0.2570 - mean_squared_error: 0.052 - ETA: 36s - loss: 0.2578 - mean_squared_error: 0.052 - ETA: 36s - loss: 0.2580 - mean_squared_error: 0.052 - ETA: 35s - loss: 0.2578 - mean_squared_error: 0.052 - ETA: 35s - loss: 0.2581 - mean_squared_error: 0.052 - ETA: 34s - loss: 0.2582 - mean_squared_error: 0.052 - ETA: 34s - loss: 0.2579 - mean_squared_error: 0.052 - ETA: 33s - loss: 0.2584 - mean_squared_error: 0.052 - ETA: 33s - loss: 0.2582 - mean_squared_error: 0.052 - ETA: 33s - loss: 0.2584 - mean_squared_error: 0.052 - ETA: 32s - loss: 0.2587 - mean_squared_error: 0.052 - ETA: 32s - loss: 0.2586 - mean_squared_error: 0.052 - ETA: 31s - loss: 0.2585 - mean_squared_error: 0.052 - ETA: 31s - loss: 0.2584 - mean_squared_error: 0.052 - ETA: 31s - loss: 0.2583 - mean_squared_error: 0.052 - ETA: 30s - loss: 0.2584 - mean_squared_error: 0.052 - ETA: 30s - loss: 0.2580 - mean_squared_error: 0.052 - ETA: 30s - loss: 0.2579 - mean_squared_error: 0.052 - ETA: 29s - loss: 0.2577 - mean_squared_error: 0.052 - ETA: 29s - loss: 0.2578 - mean_squared_error: 0.052 - ETA: 28s - loss: 0.2577 - mean_squared_error: 0.052 - ETA: 28s - loss: 0.2575 - mean_squared_error: 0.052 - ETA: 28s - loss: 0.2575 - mean_squared_error: 0.052 - ETA: 27s - loss: 0.2576 - mean_squared_error: 0.052 - ETA: 27s - loss: 0.2574 - mean_squared_error: 0.052 - ETA: 26s - loss: 0.2575 - mean_squared_error: 0.052 - ETA: 26s - loss: 0.2574 - mean_squared_error: 0.051 - ETA: 26s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 25s - loss: 0.2574 - mean_squared_error: 0.052 - ETA: 25s - loss: 0.2577 - mean_squared_error: 0.052 - ETA: 25s - loss: 0.2577 - mean_squared_error: 0.052 - ETA: 24s - loss: 0.2574 - mean_squared_error: 0.052 - ETA: 24s - loss: 0.2578 - mean_squared_error: 0.052 - ETA: 24s - loss: 0.2580 - mean_squared_error: 0.052 - ETA: 23s - loss: 0.2577 - mean_squared_error: 0.052 - ETA: 23s - loss: 0.2577 - mean_squared_error: 0.052 - ETA: 22s - loss: 0.2575 - mean_squared_error: 0.052 - ETA: 22s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 22s - loss: 0.2572 - mean_squared_error: 0.051 - ETA: 21s - loss: 0.2571 - mean_squared_error: 0.051 - ETA: 21s - loss: 0.2574 - mean_squared_error: 0.051 - ETA: 21s - loss: 0.2574 - mean_squared_error: 0.051 - ETA: 20s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 20s - loss: 0.2571 - mean_squared_error: 0.051 - ETA: 20s - loss: 0.2571 - mean_squared_error: 0.051 - ETA: 19s - loss: 0.2572 - mean_squared_error: 0.051 - ETA: 19s - loss: 0.2572 - mean_squared_error: 0.051 - ETA: 19s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 18s - loss: 0.2571 - mean_squared_error: 0.051 - ETA: 18s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 17s - loss: 0.2571 - mean_squared_error: 0.051 - ETA: 17s - loss: 0.2571 - mean_squared_error: 0.051 - ETA: 17s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 16s - loss: 0.2573 - mean_squared_error: 0.051 - ETA: 16s - loss: 0.2572 - mean_squared_error: 0.051 - ETA: 16s - loss: 0.2569 - mean_squared_error: 0.051 - ETA: 15s - loss: 0.2570 - mean_squared_error: 0.051 - ETA: 15s - loss: 0.2569 - mean_squared_error: 0.051 - ETA: 15s - loss: 0.2570 - mean_squared_error: 0.051 - ETA: 14s - loss: 0.2570 - mean_squared_error: 0.051 - ETA: 14s - loss: 0.2569 - mean_squared_error: 0.051 - ETA: 14s - loss: 0.2566 - mean_squared_error: 0.051 - ETA: 13s - loss: 0.2567 - mean_squared_error: 0.051 - ETA: 13s - loss: 0.2566 - mean_squared_error: 0.051 - ETA: 13s - loss: 0.2568 - mean_squared_error: 0.051 - ETA: 12s - loss: 0.2566 - mean_squared_error: 0.051 - ETA: 12s - loss: 0.2566 - mean_squared_error: 0.051 - ETA: 11s - loss: 0.2563 - mean_squared_error: 0.051 - ETA: 11s - loss: 0.2564 - mean_squared_error: 0.051 - ETA: 11s - loss: 0.2564 - mean_squared_error: 0.051 - ETA: 10s - loss: 0.2563 - mean_squared_error: 0.051 - ETA: 10s - loss: 0.2562 - mean_squared_error: 0.051 - ETA: 10s - loss: 0.2563 - mean_squared_error: 0.051 - ETA: 9s - loss: 0.2563 - mean_squared_error: 0.051 - ETA: 9s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 9s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2566 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 8s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2563 - mean_squared_error: 0.05 - ETA: 7s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2563 - mean_squared_error: 0.05 - ETA: 6s - loss: 0.2563 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 5s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2566 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 4s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2567 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2566 - mean_squared_error: 0.05 - ETA: 3s - loss: 0.2567 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2566 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 2s - loss: 0.2564 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 1s - loss: 0.2565 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2567 - mean_squared_error: 0.05 - ETA: 0s - loss: 0.2567 - mean_squared_error: 0.05 - 47s 12ms/step - loss: 0.2568 - mean_squared_error: 0.0516 - val_loss: 0.2371 - val_mean_squared_error: 0.0447\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 42s - loss: 0.2529 - mean_squared_error: 0.050 - ETA: 45s - loss: 0.2499 - mean_squared_error: 0.049 - ETA: 44s - loss: 0.2474 - mean_squared_error: 0.048 - ETA: 44s - loss: 0.2484 - mean_squared_error: 0.049 - ETA: 43s - loss: 0.2490 - mean_squared_error: 0.049 - ETA: 42s - loss: 0.2496 - mean_squared_error: 0.049 - ETA: 42s - loss: 0.2500 - mean_squared_error: 0.049 - ETA: 41s - loss: 0.2505 - mean_squared_error: 0.049 - ETA: 41s - loss: 0.2520 - mean_squared_error: 0.049 - ETA: 40s - loss: 0.2524 - mean_squared_error: 0.049 - ETA: 40s - loss: 0.2530 - mean_squared_error: 0.050 - ETA: 40s - loss: 0.2517 - mean_squared_error: 0.049 - ETA: 39s - loss: 0.2525 - mean_squared_error: 0.049 - ETA: 39s - loss: 0.2530 - mean_squared_error: 0.049 - ETA: 39s - loss: 0.2529 - mean_squared_error: 0.049 - ETA: 38s - loss: 0.2532 - mean_squared_error: 0.050 - ETA: 38s - loss: 0.2530 - mean_squared_error: 0.050 - ETA: 37s - loss: 0.2535 - mean_squared_error: 0.050 - ETA: 37s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 37s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 36s - loss: 0.2535 - mean_squared_error: 0.050 - ETA: 36s - loss: 0.2536 - mean_squared_error: 0.050 - ETA: 36s - loss: 0.2539 - mean_squared_error: 0.050 - ETA: 35s - loss: 0.2536 - mean_squared_error: 0.050 - ETA: 35s - loss: 0.2533 - mean_squared_error: 0.050 - ETA: 35s - loss: 0.2536 - mean_squared_error: 0.050 - ETA: 34s - loss: 0.2541 - mean_squared_error: 0.050 - ETA: 34s - loss: 0.2537 - mean_squared_error: 0.050 - ETA: 33s - loss: 0.2540 - mean_squared_error: 0.050 - ETA: 33s - loss: 0.2541 - mean_squared_error: 0.050 - ETA: 33s - loss: 0.2542 - mean_squared_error: 0.050 - ETA: 32s - loss: 0.2545 - mean_squared_error: 0.050 - ETA: 32s - loss: 0.2544 - mean_squared_error: 0.050 - ETA: 32s - loss: 0.2542 - mean_squared_error: 0.050 - ETA: 31s - loss: 0.2543 - mean_squared_error: 0.050 - ETA: 31s - loss: 0.2541 - mean_squared_error: 0.050 - ETA: 31s - loss: 0.2543 - mean_squared_error: 0.050 - ETA: 31s - loss: 0.2545 - mean_squared_error: 0.050 - ETA: 31s - loss: 0.2543 - mean_squared_error: 0.050 - ETA: 30s - loss: 0.2545 - mean_squared_error: 0.050 - ETA: 30s - loss: 0.2546 - mean_squared_error: 0.050 - ETA: 30s - loss: 0.2547 - mean_squared_error: 0.050 - ETA: 29s - loss: 0.2544 - mean_squared_error: 0.050 - ETA: 29s - loss: 0.2546 - mean_squared_error: 0.050 - ETA: 29s - loss: 0.2545 - mean_squared_error: 0.050 - ETA: 28s - loss: 0.2545 - mean_squared_error: 0.050 - ETA: 28s - loss: 0.2548 - mean_squared_error: 0.050 - ETA: 28s - loss: 0.2544 - mean_squared_error: 0.050 - ETA: 27s - loss: 0.2540 - mean_squared_error: 0.050 - ETA: 27s - loss: 0.2540 - mean_squared_error: 0.050 - ETA: 27s - loss: 0.2539 - mean_squared_error: 0.050 - ETA: 26s - loss: 0.2539 - mean_squared_error: 0.050 - ETA: 26s - loss: 0.2540 - mean_squared_error: 0.050 - ETA: 25s - loss: 0.2538 - mean_squared_error: 0.050 - ETA: 25s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 25s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 24s - loss: 0.2531 - mean_squared_error: 0.050 - ETA: 24s - loss: 0.2531 - mean_squared_error: 0.050 - ETA: 24s - loss: 0.2530 - mean_squared_error: 0.050 - ETA: 23s - loss: 0.2533 - mean_squared_error: 0.050 - ETA: 23s - loss: 0.2532 - mean_squared_error: 0.050 - ETA: 22s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 22s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 22s - loss: 0.2534 - mean_squared_error: 0.050 - ETA: 21s - loss: 0.2532 - mean_squared_error: 0.050 - ETA: 21s - loss: 0.2530 - mean_squared_error: 0.050 - ETA: 21s - loss: 0.2528 - mean_squared_error: 0.050 - ETA: 20s - loss: 0.2529 - mean_squared_error: 0.050 - ETA: 20s - loss: 0.2528 - mean_squared_error: 0.050 - ETA: 20s - loss: 0.2527 - mean_squared_error: 0.050 - ETA: 19s - loss: 0.2527 - mean_squared_error: 0.050 - ETA: 19s - loss: 0.2526 - mean_squared_error: 0.050 - ETA: 18s - loss: 0.2528 - mean_squared_error: 0.050 - ETA: 18s - loss: 0.2525 - mean_squared_error: 0.050 - ETA: 18s - loss: 0.2525 - mean_squared_error: 0.050 - ETA: 17s - loss: 0.2527 - mean_squared_error: 0.050 - ETA: 17s - loss: 0.2528 - mean_squared_error: 0.050 - ETA: 17s - loss: 0.2526 - mean_squared_error: 0.050 - ETA: 16s - loss: 0.2526 - mean_squared_error: 0.050 - ETA: 16s - loss: 0.2525 - mean_squared_error: 0.050 - ETA: 15s - loss: 0.2524 - mean_squared_error: 0.049 - ETA: 15s - loss: 0.2523 - mean_squared_error: 0.049 - ETA: 15s - loss: 0.2523 - mean_squared_error: 0.049 - ETA: 14s - loss: 0.2522 - mean_squared_error: 0.049 - ETA: 14s - loss: 0.2522 - mean_squared_error: 0.049 - ETA: 14s - loss: 0.2522 - mean_squared_error: 0.049 - ETA: 13s - loss: 0.2520 - mean_squared_error: 0.049 - ETA: 13s - loss: 0.2519 - mean_squared_error: 0.049 - ETA: 13s - loss: 0.2519 - mean_squared_error: 0.049 - ETA: 12s - loss: 0.2516 - mean_squared_error: 0.049 - ETA: 12s - loss: 0.2517 - mean_squared_error: 0.049 - ETA: 11s - loss: 0.2517 - mean_squared_error: 0.049 - ETA: 11s - loss: 0.2517 - mean_squared_error: 0.049 - ETA: 11s - loss: 0.2515 - mean_squared_error: 0.049 - ETA: 10s - loss: 0.2516 - mean_squared_error: 0.049 - ETA: 10s - loss: 0.2513 - mean_squared_error: 0.049 - ETA: 10s - loss: 0.2513 - mean_squared_error: 0.049 - ETA: 9s - loss: 0.2511 - mean_squared_error: 0.049 - ETA: 9s - loss: 0.2510 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2510 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2511 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2512 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2511 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2511 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2512 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2512 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2512 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2511 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2511 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2511 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2509 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2510 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2509 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2510 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2509 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2509 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2509 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2508 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2507 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2506 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2506 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2506 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2506 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2506 - mean_squared_error: 0.04 - 49s 12ms/step - loss: 0.2505 - mean_squared_error: 0.0494 - val_loss: 0.2339 - val_mean_squared_error: 0.0435\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 44s - loss: 0.2498 - mean_squared_error: 0.049 - ETA: 46s - loss: 0.2554 - mean_squared_error: 0.051 - ETA: 47s - loss: 0.2484 - mean_squared_error: 0.048 - ETA: 47s - loss: 0.2461 - mean_squared_error: 0.048 - ETA: 47s - loss: 0.2435 - mean_squared_error: 0.047 - ETA: 46s - loss: 0.2461 - mean_squared_error: 0.048 - ETA: 45s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 45s - loss: 0.2456 - mean_squared_error: 0.047 - ETA: 45s - loss: 0.2457 - mean_squared_error: 0.047 - ETA: 44s - loss: 0.2459 - mean_squared_error: 0.048 - ETA: 44s - loss: 0.2458 - mean_squared_error: 0.048 - ETA: 43s - loss: 0.2457 - mean_squared_error: 0.048 - ETA: 43s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 43s - loss: 0.2449 - mean_squared_error: 0.047 - ETA: 42s - loss: 0.2452 - mean_squared_error: 0.047 - ETA: 42s - loss: 0.2455 - mean_squared_error: 0.047 - ETA: 41s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 41s - loss: 0.2444 - mean_squared_error: 0.047 - ETA: 40s - loss: 0.2440 - mean_squared_error: 0.047 - ETA: 40s - loss: 0.2437 - mean_squared_error: 0.047 - ETA: 39s - loss: 0.2435 - mean_squared_error: 0.047 - ETA: 39s - loss: 0.2448 - mean_squared_error: 0.047 - ETA: 38s - loss: 0.2442 - mean_squared_error: 0.047 - ETA: 38s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 38s - loss: 0.2454 - mean_squared_error: 0.047 - ETA: 37s - loss: 0.2457 - mean_squared_error: 0.047 - ETA: 37s - loss: 0.2456 - mean_squared_error: 0.047 - ETA: 36s - loss: 0.2457 - mean_squared_error: 0.047 - ETA: 36s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 35s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 35s - loss: 0.2456 - mean_squared_error: 0.047 - ETA: 35s - loss: 0.2455 - mean_squared_error: 0.047 - ETA: 34s - loss: 0.2455 - mean_squared_error: 0.047 - ETA: 34s - loss: 0.2452 - mean_squared_error: 0.047 - ETA: 33s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 33s - loss: 0.2448 - mean_squared_error: 0.047 - ETA: 32s - loss: 0.2452 - mean_squared_error: 0.047 - ETA: 32s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 32s - loss: 0.2450 - mean_squared_error: 0.047 - ETA: 31s - loss: 0.2454 - mean_squared_error: 0.047 - ETA: 31s - loss: 0.2456 - mean_squared_error: 0.047 - ETA: 31s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 30s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 30s - loss: 0.2452 - mean_squared_error: 0.047 - ETA: 29s - loss: 0.2450 - mean_squared_error: 0.047 - ETA: 29s - loss: 0.2445 - mean_squared_error: 0.047 - ETA: 28s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 28s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 28s - loss: 0.2446 - mean_squared_error: 0.047 - ETA: 27s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 27s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 27s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 26s - loss: 0.2448 - mean_squared_error: 0.047 - ETA: 26s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 25s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 25s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 25s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 24s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 24s - loss: 0.2456 - mean_squared_error: 0.047 - ETA: 23s - loss: 0.2460 - mean_squared_error: 0.047 - ETA: 23s - loss: 0.2459 - mean_squared_error: 0.047 - ETA: 23s - loss: 0.2459 - mean_squared_error: 0.047 - ETA: 22s - loss: 0.2460 - mean_squared_error: 0.047 - ETA: 22s - loss: 0.2461 - mean_squared_error: 0.047 - ETA: 22s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 21s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 21s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 20s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 20s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 20s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 19s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 19s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 19s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 18s - loss: 0.2461 - mean_squared_error: 0.047 - ETA: 18s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 17s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 17s - loss: 0.2465 - mean_squared_error: 0.047 - ETA: 17s - loss: 0.2465 - mean_squared_error: 0.047 - ETA: 16s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 16s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 16s - loss: 0.2465 - mean_squared_error: 0.047 - ETA: 15s - loss: 0.2465 - mean_squared_error: 0.047 - ETA: 15s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 14s - loss: 0.2465 - mean_squared_error: 0.047 - ETA: 14s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 14s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 13s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 13s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 13s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 12s - loss: 0.2461 - mean_squared_error: 0.047 - ETA: 12s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 12s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 11s - loss: 0.2462 - mean_squared_error: 0.047 - ETA: 11s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 10s - loss: 0.2466 - mean_squared_error: 0.047 - ETA: 10s - loss: 0.2465 - mean_squared_error: 0.047 - ETA: 10s - loss: 0.2464 - mean_squared_error: 0.047 - ETA: 9s - loss: 0.2463 - mean_squared_error: 0.047 - ETA: 9s - loss: 0.2464 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2463 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2463 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2464 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2464 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2464 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2466 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2466 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2466 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2468 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2467 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2468 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2467 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2466 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2466 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2465 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2463 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2464 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2463 - mean_squared_error: 0.04 - 48s 12ms/step - loss: 0.2463 - mean_squared_error: 0.0479 - val_loss: 0.2287 - val_mean_squared_error: 0.0416\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 45s - loss: 0.2438 - mean_squared_error: 0.046 - ETA: 45s - loss: 0.2380 - mean_squared_error: 0.045 - ETA: 44s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 44s - loss: 0.2388 - mean_squared_error: 0.045 - ETA: 43s - loss: 0.2398 - mean_squared_error: 0.045 - ETA: 43s - loss: 0.2388 - mean_squared_error: 0.045 - ETA: 43s - loss: 0.2410 - mean_squared_error: 0.046 - ETA: 42s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 42s - loss: 0.2425 - mean_squared_error: 0.046 - ETA: 42s - loss: 0.2423 - mean_squared_error: 0.046 - ETA: 41s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 40s - loss: 0.2420 - mean_squared_error: 0.046 - ETA: 40s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 40s - loss: 0.2423 - mean_squared_error: 0.046 - ETA: 39s - loss: 0.2426 - mean_squared_error: 0.046 - ETA: 39s - loss: 0.2429 - mean_squared_error: 0.046 - ETA: 39s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 38s - loss: 0.2437 - mean_squared_error: 0.046 - ETA: 38s - loss: 0.2436 - mean_squared_error: 0.046 - ETA: 38s - loss: 0.2436 - mean_squared_error: 0.046 - ETA: 37s - loss: 0.2438 - mean_squared_error: 0.046 - ETA: 37s - loss: 0.2440 - mean_squared_error: 0.046 - ETA: 36s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 36s - loss: 0.2452 - mean_squared_error: 0.047 - ETA: 36s - loss: 0.2454 - mean_squared_error: 0.047 - ETA: 35s - loss: 0.2449 - mean_squared_error: 0.047 - ETA: 35s - loss: 0.2450 - mean_squared_error: 0.047 - ETA: 35s - loss: 0.2451 - mean_squared_error: 0.047 - ETA: 34s - loss: 0.2457 - mean_squared_error: 0.047 - ETA: 34s - loss: 0.2455 - mean_squared_error: 0.047 - ETA: 33s - loss: 0.2450 - mean_squared_error: 0.047 - ETA: 33s - loss: 0.2454 - mean_squared_error: 0.047 - ETA: 33s - loss: 0.2453 - mean_squared_error: 0.047 - ETA: 32s - loss: 0.2449 - mean_squared_error: 0.047 - ETA: 32s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 31s - loss: 0.2445 - mean_squared_error: 0.047 - ETA: 31s - loss: 0.2442 - mean_squared_error: 0.046 - ETA: 31s - loss: 0.2447 - mean_squared_error: 0.047 - ETA: 30s - loss: 0.2446 - mean_squared_error: 0.047 - ETA: 30s - loss: 0.2442 - mean_squared_error: 0.046 - ETA: 30s - loss: 0.2440 - mean_squared_error: 0.046 - ETA: 29s - loss: 0.2438 - mean_squared_error: 0.046 - ETA: 29s - loss: 0.2436 - mean_squared_error: 0.046 - ETA: 28s - loss: 0.2438 - mean_squared_error: 0.046 - ETA: 28s - loss: 0.2437 - mean_squared_error: 0.046 - ETA: 28s - loss: 0.2444 - mean_squared_error: 0.047 - ETA: 27s - loss: 0.2443 - mean_squared_error: 0.047 - ETA: 27s - loss: 0.2441 - mean_squared_error: 0.046 - ETA: 27s - loss: 0.2442 - mean_squared_error: 0.046 - ETA: 26s - loss: 0.2439 - mean_squared_error: 0.046 - ETA: 26s - loss: 0.2440 - mean_squared_error: 0.046 - ETA: 25s - loss: 0.2440 - mean_squared_error: 0.046 - ETA: 25s - loss: 0.2440 - mean_squared_error: 0.046 - ETA: 25s - loss: 0.2438 - mean_squared_error: 0.046 - ETA: 24s - loss: 0.2437 - mean_squared_error: 0.046 - ETA: 24s - loss: 0.2435 - mean_squared_error: 0.046 - ETA: 24s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 23s - loss: 0.2433 - mean_squared_error: 0.046 - ETA: 23s - loss: 0.2435 - mean_squared_error: 0.046 - ETA: 22s - loss: 0.2434 - mean_squared_error: 0.046 - ETA: 22s - loss: 0.2434 - mean_squared_error: 0.046 - ETA: 22s - loss: 0.2434 - mean_squared_error: 0.046 - ETA: 21s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 21s - loss: 0.2434 - mean_squared_error: 0.046 - ETA: 21s - loss: 0.2436 - mean_squared_error: 0.046 - ETA: 20s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 20s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 20s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 19s - loss: 0.2433 - mean_squared_error: 0.046 - ETA: 19s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 19s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 18s - loss: 0.2428 - mean_squared_error: 0.046 - ETA: 18s - loss: 0.2429 - mean_squared_error: 0.046 - ETA: 17s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 17s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 17s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 16s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 16s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 16s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 15s - loss: 0.2429 - mean_squared_error: 0.046 - ETA: 15s - loss: 0.2428 - mean_squared_error: 0.046 - ETA: 15s - loss: 0.2427 - mean_squared_error: 0.046 - ETA: 14s - loss: 0.2428 - mean_squared_error: 0.046 - ETA: 14s - loss: 0.2428 - mean_squared_error: 0.046 - ETA: 14s - loss: 0.2429 - mean_squared_error: 0.046 - ETA: 13s - loss: 0.2428 - mean_squared_error: 0.046 - ETA: 13s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 13s - loss: 0.2429 - mean_squared_error: 0.046 - ETA: 12s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 12s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 12s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 11s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 11s - loss: 0.2431 - mean_squared_error: 0.046 - ETA: 11s - loss: 0.2429 - mean_squared_error: 0.046 - ETA: 10s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 10s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 10s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 9s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 9s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2430 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2427 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2428 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2428 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2428 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2428 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2427 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2429 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2430 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2431 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2431 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2431 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2431 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2433 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2432 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2433 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2434 - mean_squared_error: 0.04 - 48s 12ms/step - loss: 0.2433 - mean_squared_error: 0.0467 - val_loss: 0.2267 - val_mean_squared_error: 0.0409\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 44s - loss: 0.2298 - mean_squared_error: 0.043 - ETA: 45s - loss: 0.2349 - mean_squared_error: 0.044 - ETA: 46s - loss: 0.2346 - mean_squared_error: 0.044 - ETA: 46s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 46s - loss: 0.2360 - mean_squared_error: 0.044 - ETA: 45s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 45s - loss: 0.2378 - mean_squared_error: 0.045 - ETA: 45s - loss: 0.2387 - mean_squared_error: 0.045 - ETA: 44s - loss: 0.2385 - mean_squared_error: 0.045 - ETA: 44s - loss: 0.2393 - mean_squared_error: 0.045 - ETA: 43s - loss: 0.2393 - mean_squared_error: 0.045 - ETA: 43s - loss: 0.2404 - mean_squared_error: 0.045 - ETA: 43s - loss: 0.2404 - mean_squared_error: 0.045 - ETA: 42s - loss: 0.2401 - mean_squared_error: 0.045 - ETA: 42s - loss: 0.2401 - mean_squared_error: 0.045 - ETA: 42s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 41s - loss: 0.2408 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2407 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2406 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2407 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2411 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2411 - mean_squared_error: 0.045 - ETA: 38s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 38s - loss: 0.2421 - mean_squared_error: 0.046 - ETA: 38s - loss: 0.2422 - mean_squared_error: 0.046 - ETA: 37s - loss: 0.2422 - mean_squared_error: 0.046 - ETA: 37s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 36s - loss: 0.2428 - mean_squared_error: 0.046 - ETA: 36s - loss: 0.2433 - mean_squared_error: 0.046 - ETA: 35s - loss: 0.2434 - mean_squared_error: 0.046 - ETA: 35s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 34s - loss: 0.2430 - mean_squared_error: 0.046 - ETA: 34s - loss: 0.2435 - mean_squared_error: 0.046 - ETA: 33s - loss: 0.2432 - mean_squared_error: 0.046 - ETA: 33s - loss: 0.2427 - mean_squared_error: 0.046 - ETA: 32s - loss: 0.2423 - mean_squared_error: 0.046 - ETA: 32s - loss: 0.2422 - mean_squared_error: 0.046 - ETA: 32s - loss: 0.2421 - mean_squared_error: 0.046 - ETA: 31s - loss: 0.2424 - mean_squared_error: 0.046 - ETA: 31s - loss: 0.2424 - mean_squared_error: 0.046 - ETA: 30s - loss: 0.2425 - mean_squared_error: 0.046 - ETA: 30s - loss: 0.2424 - mean_squared_error: 0.046 - ETA: 30s - loss: 0.2421 - mean_squared_error: 0.046 - ETA: 29s - loss: 0.2419 - mean_squared_error: 0.046 - ETA: 29s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 28s - loss: 0.2413 - mean_squared_error: 0.046 - ETA: 28s - loss: 0.2413 - mean_squared_error: 0.046 - ETA: 28s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 27s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 27s - loss: 0.2409 - mean_squared_error: 0.045 - ETA: 26s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 26s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 26s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 25s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 25s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 25s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 24s - loss: 0.2413 - mean_squared_error: 0.046 - ETA: 24s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 23s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 23s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 23s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 22s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 22s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 22s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 21s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 21s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 20s - loss: 0.2411 - mean_squared_error: 0.046 - ETA: 20s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 20s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 19s - loss: 0.2412 - mean_squared_error: 0.046 - ETA: 19s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 19s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 18s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 18s - loss: 0.2413 - mean_squared_error: 0.046 - ETA: 17s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 17s - loss: 0.2417 - mean_squared_error: 0.046 - ETA: 17s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 16s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 16s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 16s - loss: 0.2417 - mean_squared_error: 0.046 - ETA: 15s - loss: 0.2417 - mean_squared_error: 0.046 - ETA: 15s - loss: 0.2417 - mean_squared_error: 0.046 - ETA: 15s - loss: 0.2418 - mean_squared_error: 0.046 - ETA: 14s - loss: 0.2418 - mean_squared_error: 0.046 - ETA: 14s - loss: 0.2418 - mean_squared_error: 0.046 - ETA: 13s - loss: 0.2417 - mean_squared_error: 0.046 - ETA: 13s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 13s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 12s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 12s - loss: 0.2416 - mean_squared_error: 0.046 - ETA: 12s - loss: 0.2415 - mean_squared_error: 0.046 - ETA: 11s - loss: 0.2414 - mean_squared_error: 0.046 - ETA: 11s - loss: 0.2412 - mean_squared_error: 0.045 - ETA: 11s - loss: 0.2411 - mean_squared_error: 0.045 - ETA: 10s - loss: 0.2409 - mean_squared_error: 0.045 - ETA: 10s - loss: 0.2409 - mean_squared_error: 0.045 - ETA: 9s - loss: 0.2410 - mean_squared_error: 0.045 - ETA: 9s - loss: 0.2410 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2411 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2409 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2409 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2410 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2408 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2406 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2406 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2406 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2405 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2405 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2404 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2404 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2403 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2402 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2403 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2403 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2404 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2404 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2405 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2405 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2406 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2406 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2405 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2406 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2407 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2408 - mean_squared_error: 0.04 - 47s 12ms/step - loss: 0.2407 - mean_squared_error: 0.0458 - val_loss: 0.2257 - val_mean_squared_error: 0.0403\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 45s - loss: 0.2310 - mean_squared_error: 0.043 - ETA: 43s - loss: 0.2282 - mean_squared_error: 0.042 - ETA: 43s - loss: 0.2304 - mean_squared_error: 0.042 - ETA: 43s - loss: 0.2341 - mean_squared_error: 0.043 - ETA: 43s - loss: 0.2389 - mean_squared_error: 0.045 - ETA: 42s - loss: 0.2398 - mean_squared_error: 0.045 - ETA: 42s - loss: 0.2391 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2402 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2408 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2407 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2409 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2411 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2408 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2418 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2416 - mean_squared_error: 0.045 - ETA: 38s - loss: 0.2423 - mean_squared_error: 0.046 - ETA: 38s - loss: 0.2413 - mean_squared_error: 0.045 - ETA: 37s - loss: 0.2408 - mean_squared_error: 0.045 - ETA: 37s - loss: 0.2414 - mean_squared_error: 0.045 - ETA: 37s - loss: 0.2408 - mean_squared_error: 0.045 - ETA: 36s - loss: 0.2402 - mean_squared_error: 0.045 - ETA: 36s - loss: 0.2408 - mean_squared_error: 0.045 - ETA: 36s - loss: 0.2409 - mean_squared_error: 0.045 - ETA: 35s - loss: 0.2404 - mean_squared_error: 0.045 - ETA: 35s - loss: 0.2401 - mean_squared_error: 0.045 - ETA: 35s - loss: 0.2401 - mean_squared_error: 0.045 - ETA: 34s - loss: 0.2395 - mean_squared_error: 0.045 - ETA: 34s - loss: 0.2389 - mean_squared_error: 0.045 - ETA: 33s - loss: 0.2386 - mean_squared_error: 0.045 - ETA: 33s - loss: 0.2388 - mean_squared_error: 0.045 - ETA: 33s - loss: 0.2388 - mean_squared_error: 0.045 - ETA: 32s - loss: 0.2389 - mean_squared_error: 0.045 - ETA: 32s - loss: 0.2383 - mean_squared_error: 0.045 - ETA: 32s - loss: 0.2386 - mean_squared_error: 0.045 - ETA: 31s - loss: 0.2383 - mean_squared_error: 0.045 - ETA: 31s - loss: 0.2387 - mean_squared_error: 0.045 - ETA: 31s - loss: 0.2385 - mean_squared_error: 0.045 - ETA: 30s - loss: 0.2384 - mean_squared_error: 0.045 - ETA: 30s - loss: 0.2379 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2381 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2381 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2375 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2376 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2380 - mean_squared_error: 0.045 - ETA: 24s - loss: 0.2381 - mean_squared_error: 0.045 - ETA: 24s - loss: 0.2381 - mean_squared_error: 0.045 - ETA: 24s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2379 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 22s - loss: 0.2380 - mean_squared_error: 0.045 - ETA: 22s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2376 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2375 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2375 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 19s - loss: 0.2377 - mean_squared_error: 0.044 - ETA: 19s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 19s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 18s - loss: 0.2381 - mean_squared_error: 0.045 - ETA: 18s - loss: 0.2381 - mean_squared_error: 0.045 - ETA: 18s - loss: 0.2383 - mean_squared_error: 0.045 - ETA: 17s - loss: 0.2382 - mean_squared_error: 0.045 - ETA: 17s - loss: 0.2383 - mean_squared_error: 0.045 - ETA: 16s - loss: 0.2383 - mean_squared_error: 0.045 - ETA: 16s - loss: 0.2382 - mean_squared_error: 0.045 - ETA: 16s - loss: 0.2381 - mean_squared_error: 0.044 - ETA: 15s - loss: 0.2381 - mean_squared_error: 0.044 - ETA: 15s - loss: 0.2379 - mean_squared_error: 0.044 - ETA: 15s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 14s - loss: 0.2382 - mean_squared_error: 0.045 - ETA: 14s - loss: 0.2382 - mean_squared_error: 0.045 - ETA: 14s - loss: 0.2383 - mean_squared_error: 0.045 - ETA: 13s - loss: 0.2384 - mean_squared_error: 0.045 - ETA: 13s - loss: 0.2385 - mean_squared_error: 0.045 - ETA: 13s - loss: 0.2386 - mean_squared_error: 0.045 - ETA: 12s - loss: 0.2385 - mean_squared_error: 0.045 - ETA: 12s - loss: 0.2384 - mean_squared_error: 0.045 - ETA: 12s - loss: 0.2386 - mean_squared_error: 0.045 - ETA: 11s - loss: 0.2387 - mean_squared_error: 0.045 - ETA: 11s - loss: 0.2388 - mean_squared_error: 0.045 - ETA: 10s - loss: 0.2387 - mean_squared_error: 0.045 - ETA: 10s - loss: 0.2387 - mean_squared_error: 0.045 - ETA: 10s - loss: 0.2388 - mean_squared_error: 0.045 - ETA: 9s - loss: 0.2387 - mean_squared_error: 0.045 - ETA: 9s - loss: 0.2387 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2386 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2386 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2386 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2385 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2385 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2384 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2385 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2385 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2384 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2383 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2383 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2382 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2382 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2382 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2381 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2382 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2382 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2383 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2385 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2384 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2386 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2388 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2387 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2386 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2385 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2385 - mean_squared_error: 0.04 - 47s 12ms/step - loss: 0.2386 - mean_squared_error: 0.0450 - val_loss: 0.2230 - val_mean_squared_error: 0.0394\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 44s - loss: 0.2408 - mean_squared_error: 0.044 - ETA: 44s - loss: 0.2397 - mean_squared_error: 0.044 - ETA: 43s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 42s - loss: 0.2378 - mean_squared_error: 0.044 - ETA: 42s - loss: 0.2436 - mean_squared_error: 0.045 - ETA: 42s - loss: 0.2437 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2425 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2440 - mean_squared_error: 0.046 - ETA: 41s - loss: 0.2417 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2407 - mean_squared_error: 0.045 - ETA: 41s - loss: 0.2406 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2414 - mean_squared_error: 0.045 - ETA: 40s - loss: 0.2426 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2421 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2416 - mean_squared_error: 0.045 - ETA: 39s - loss: 0.2413 - mean_squared_error: 0.045 - ETA: 38s - loss: 0.2409 - mean_squared_error: 0.045 - ETA: 38s - loss: 0.2407 - mean_squared_error: 0.045 - ETA: 38s - loss: 0.2401 - mean_squared_error: 0.045 - ETA: 37s - loss: 0.2403 - mean_squared_error: 0.045 - ETA: 37s - loss: 0.2401 - mean_squared_error: 0.045 - ETA: 37s - loss: 0.2399 - mean_squared_error: 0.045 - ETA: 36s - loss: 0.2391 - mean_squared_error: 0.044 - ETA: 36s - loss: 0.2388 - mean_squared_error: 0.044 - ETA: 36s - loss: 0.2383 - mean_squared_error: 0.044 - ETA: 35s - loss: 0.2386 - mean_squared_error: 0.044 - ETA: 35s - loss: 0.2382 - mean_squared_error: 0.044 - ETA: 34s - loss: 0.2380 - mean_squared_error: 0.044 - ETA: 34s - loss: 0.2376 - mean_squared_error: 0.044 - ETA: 34s - loss: 0.2379 - mean_squared_error: 0.044 - ETA: 33s - loss: 0.2376 - mean_squared_error: 0.044 - ETA: 33s - loss: 0.2379 - mean_squared_error: 0.044 - ETA: 32s - loss: 0.2375 - mean_squared_error: 0.044 - ETA: 32s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 32s - loss: 0.2370 - mean_squared_error: 0.044 - ETA: 31s - loss: 0.2370 - mean_squared_error: 0.044 - ETA: 31s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 30s - loss: 0.2372 - mean_squared_error: 0.044 - ETA: 30s - loss: 0.2374 - mean_squared_error: 0.044 - ETA: 30s - loss: 0.2373 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2374 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2370 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2361 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2362 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2360 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2361 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2357 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2358 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2360 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 24s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 24s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 24s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 22s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 22s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 22s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2370 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2370 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 19s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 19s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 19s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 18s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 18s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 18s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 17s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 17s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 17s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 16s - loss: 0.2369 - mean_squared_error: 0.044 - ETA: 16s - loss: 0.2369 - mean_squared_error: 0.044 - ETA: 16s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 15s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 15s - loss: 0.2372 - mean_squared_error: 0.044 - ETA: 15s - loss: 0.2371 - mean_squared_error: 0.044 - ETA: 14s - loss: 0.2370 - mean_squared_error: 0.044 - ETA: 14s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 13s - loss: 0.2369 - mean_squared_error: 0.044 - ETA: 13s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 13s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 12s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 12s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 12s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 11s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 11s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 11s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 10s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 10s - loss: 0.2369 - mean_squared_error: 0.044 - ETA: 10s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 9s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 9s - loss: 0.2369 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2370 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2369 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2370 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2370 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2367 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2367 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2364 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2365 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2367 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2367 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2367 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2369 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2370 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2369 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2369 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2367 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2368 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2369 - mean_squared_error: 0.04 - 46s 12ms/step - loss: 0.2370 - mean_squared_error: 0.0445 - val_loss: 0.2202 - val_mean_squared_error: 0.0387\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 46s - loss: 0.2419 - mean_squared_error: 0.045 - ETA: 45s - loss: 0.2382 - mean_squared_error: 0.044 - ETA: 45s - loss: 0.2358 - mean_squared_error: 0.044 - ETA: 44s - loss: 0.2317 - mean_squared_error: 0.042 - ETA: 44s - loss: 0.2313 - mean_squared_error: 0.042 - ETA: 43s - loss: 0.2307 - mean_squared_error: 0.042 - ETA: 43s - loss: 0.2281 - mean_squared_error: 0.041 - ETA: 42s - loss: 0.2292 - mean_squared_error: 0.042 - ETA: 42s - loss: 0.2303 - mean_squared_error: 0.042 - ETA: 41s - loss: 0.2299 - mean_squared_error: 0.042 - ETA: 41s - loss: 0.2313 - mean_squared_error: 0.042 - ETA: 40s - loss: 0.2323 - mean_squared_error: 0.043 - ETA: 40s - loss: 0.2323 - mean_squared_error: 0.043 - ETA: 40s - loss: 0.2315 - mean_squared_error: 0.042 - ETA: 39s - loss: 0.2314 - mean_squared_error: 0.042 - ETA: 39s - loss: 0.2310 - mean_squared_error: 0.042 - ETA: 39s - loss: 0.2313 - mean_squared_error: 0.042 - ETA: 38s - loss: 0.2313 - mean_squared_error: 0.042 - ETA: 38s - loss: 0.2309 - mean_squared_error: 0.042 - ETA: 37s - loss: 0.2309 - mean_squared_error: 0.042 - ETA: 37s - loss: 0.2309 - mean_squared_error: 0.042 - ETA: 37s - loss: 0.2306 - mean_squared_error: 0.042 - ETA: 36s - loss: 0.2307 - mean_squared_error: 0.042 - ETA: 36s - loss: 0.2313 - mean_squared_error: 0.042 - ETA: 36s - loss: 0.2314 - mean_squared_error: 0.042 - ETA: 35s - loss: 0.2325 - mean_squared_error: 0.043 - ETA: 35s - loss: 0.2329 - mean_squared_error: 0.043 - ETA: 35s - loss: 0.2331 - mean_squared_error: 0.043 - ETA: 34s - loss: 0.2335 - mean_squared_error: 0.043 - ETA: 34s - loss: 0.2336 - mean_squared_error: 0.043 - ETA: 33s - loss: 0.2335 - mean_squared_error: 0.043 - ETA: 33s - loss: 0.2336 - mean_squared_error: 0.043 - ETA: 32s - loss: 0.2338 - mean_squared_error: 0.043 - ETA: 32s - loss: 0.2338 - mean_squared_error: 0.043 - ETA: 32s - loss: 0.2337 - mean_squared_error: 0.043 - ETA: 31s - loss: 0.2338 - mean_squared_error: 0.043 - ETA: 31s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 30s - loss: 0.2338 - mean_squared_error: 0.043 - ETA: 30s - loss: 0.2340 - mean_squared_error: 0.043 - ETA: 30s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 29s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 29s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 29s - loss: 0.2336 - mean_squared_error: 0.043 - ETA: 28s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 28s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 28s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 27s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 27s - loss: 0.2343 - mean_squared_error: 0.043 - ETA: 26s - loss: 0.2345 - mean_squared_error: 0.043 - ETA: 26s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 26s - loss: 0.2341 - mean_squared_error: 0.043 - ETA: 25s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 25s - loss: 0.2341 - mean_squared_error: 0.043 - ETA: 25s - loss: 0.2340 - mean_squared_error: 0.043 - ETA: 24s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 24s - loss: 0.2340 - mean_squared_error: 0.043 - ETA: 23s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 23s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 23s - loss: 0.2341 - mean_squared_error: 0.043 - ETA: 22s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 22s - loss: 0.2338 - mean_squared_error: 0.043 - ETA: 22s - loss: 0.2340 - mean_squared_error: 0.043 - ETA: 21s - loss: 0.2337 - mean_squared_error: 0.043 - ETA: 21s - loss: 0.2338 - mean_squared_error: 0.043 - ETA: 20s - loss: 0.2340 - mean_squared_error: 0.043 - ETA: 20s - loss: 0.2340 - mean_squared_error: 0.043 - ETA: 20s - loss: 0.2341 - mean_squared_error: 0.043 - ETA: 19s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 19s - loss: 0.2342 - mean_squared_error: 0.043 - ETA: 19s - loss: 0.2343 - mean_squared_error: 0.043 - ETA: 18s - loss: 0.2343 - mean_squared_error: 0.043 - ETA: 18s - loss: 0.2343 - mean_squared_error: 0.043 - ETA: 18s - loss: 0.2345 - mean_squared_error: 0.043 - ETA: 17s - loss: 0.2344 - mean_squared_error: 0.043 - ETA: 17s - loss: 0.2345 - mean_squared_error: 0.043 - ETA: 17s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 16s - loss: 0.2344 - mean_squared_error: 0.043 - ETA: 16s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 16s - loss: 0.2345 - mean_squared_error: 0.043 - ETA: 15s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 15s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 14s - loss: 0.2347 - mean_squared_error: 0.043 - ETA: 14s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 14s - loss: 0.2345 - mean_squared_error: 0.043 - ETA: 13s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 13s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 13s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 12s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 12s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 12s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 11s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 11s - loss: 0.2349 - mean_squared_error: 0.043 - ETA: 11s - loss: 0.2351 - mean_squared_error: 0.043 - ETA: 10s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 10s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 10s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 9s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 9s - loss: 0.2349 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2348 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2348 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2346 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2348 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2347 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2347 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2347 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2347 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2347 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2348 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2349 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2350 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2352 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2352 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2353 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2353 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2353 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2352 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2352 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2353 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2351 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2351 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2351 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2350 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2350 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2349 - mean_squared_error: 0.04 - 48s 12ms/step - loss: 0.2349 - mean_squared_error: 0.0438 - val_loss: 0.2181 - val_mean_squared_error: 0.0376\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 47s - loss: 0.2354 - mean_squared_error: 0.044 - ETA: 49s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 49s - loss: 0.2337 - mean_squared_error: 0.043 - ETA: 48s - loss: 0.2358 - mean_squared_error: 0.044 - ETA: 48s - loss: 0.2358 - mean_squared_error: 0.044 - ETA: 47s - loss: 0.2339 - mean_squared_error: 0.043 - ETA: 48s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 47s - loss: 0.2360 - mean_squared_error: 0.044 - ETA: 47s - loss: 0.2358 - mean_squared_error: 0.044 - ETA: 46s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 46s - loss: 0.2362 - mean_squared_error: 0.044 - ETA: 45s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 45s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 44s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 44s - loss: 0.2359 - mean_squared_error: 0.044 - ETA: 43s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 43s - loss: 0.2369 - mean_squared_error: 0.044 - ETA: 43s - loss: 0.2368 - mean_squared_error: 0.044 - ETA: 42s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 42s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 41s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 41s - loss: 0.2367 - mean_squared_error: 0.044 - ETA: 41s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 40s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 40s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 39s - loss: 0.2355 - mean_squared_error: 0.043 - ETA: 39s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 38s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 38s - loss: 0.2361 - mean_squared_error: 0.043 - ETA: 38s - loss: 0.2356 - mean_squared_error: 0.043 - ETA: 37s - loss: 0.2359 - mean_squared_error: 0.043 - ETA: 37s - loss: 0.2354 - mean_squared_error: 0.043 - ETA: 37s - loss: 0.2351 - mean_squared_error: 0.043 - ETA: 36s - loss: 0.2353 - mean_squared_error: 0.043 - ETA: 36s - loss: 0.2357 - mean_squared_error: 0.043 - ETA: 35s - loss: 0.2359 - mean_squared_error: 0.043 - ETA: 35s - loss: 0.2360 - mean_squared_error: 0.043 - ETA: 35s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 34s - loss: 0.2361 - mean_squared_error: 0.044 - ETA: 34s - loss: 0.2360 - mean_squared_error: 0.043 - ETA: 33s - loss: 0.2362 - mean_squared_error: 0.044 - ETA: 33s - loss: 0.2361 - mean_squared_error: 0.043 - ETA: 32s - loss: 0.2360 - mean_squared_error: 0.043 - ETA: 32s - loss: 0.2359 - mean_squared_error: 0.043 - ETA: 31s - loss: 0.2360 - mean_squared_error: 0.043 - ETA: 31s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 31s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 30s - loss: 0.2362 - mean_squared_error: 0.044 - ETA: 30s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 29s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 28s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 27s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 26s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2362 - mean_squared_error: 0.044 - ETA: 25s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 24s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 24s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 24s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 23s - loss: 0.2365 - mean_squared_error: 0.044 - ETA: 22s - loss: 0.2364 - mean_squared_error: 0.044 - ETA: 22s - loss: 0.2366 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2363 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2362 - mean_squared_error: 0.044 - ETA: 21s - loss: 0.2360 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2361 - mean_squared_error: 0.044 - ETA: 20s - loss: 0.2359 - mean_squared_error: 0.043 - ETA: 19s - loss: 0.2356 - mean_squared_error: 0.043 - ETA: 19s - loss: 0.2356 - mean_squared_error: 0.043 - ETA: 19s - loss: 0.2355 - mean_squared_error: 0.043 - ETA: 18s - loss: 0.2353 - mean_squared_error: 0.043 - ETA: 18s - loss: 0.2353 - mean_squared_error: 0.043 - ETA: 17s - loss: 0.2352 - mean_squared_error: 0.043 - ETA: 17s - loss: 0.2353 - mean_squared_error: 0.043 - ETA: 17s - loss: 0.2352 - mean_squared_error: 0.043 - ETA: 16s - loss: 0.2351 - mean_squared_error: 0.043 - ETA: 16s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 15s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 15s - loss: 0.2349 - mean_squared_error: 0.043 - ETA: 15s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 14s - loss: 0.2349 - mean_squared_error: 0.043 - ETA: 14s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 13s - loss: 0.2349 - mean_squared_error: 0.043 - ETA: 13s - loss: 0.2350 - mean_squared_error: 0.043 - ETA: 13s - loss: 0.2349 - mean_squared_error: 0.043 - ETA: 12s - loss: 0.2349 - mean_squared_error: 0.043 - ETA: 12s - loss: 0.2348 - mean_squared_error: 0.043 - ETA: 11s - loss: 0.2347 - mean_squared_error: 0.043 - ETA: 11s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 11s - loss: 0.2346 - mean_squared_error: 0.043 - ETA: 10s - loss: 0.2345 - mean_squared_error: 0.043 - ETA: 10s - loss: 0.2344 - mean_squared_error: 0.043 - ETA: 9s - loss: 0.2344 - mean_squared_error: 0.043 - ETA: 9s - loss: 0.2344 - mean_squared_error: 0.04 - ETA: 9s - loss: 0.2344 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2344 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2344 - mean_squared_error: 0.04 - ETA: 8s - loss: 0.2344 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2343 - mean_squared_error: 0.04 - ETA: 7s - loss: 0.2344 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2343 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 6s - loss: 0.2341 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2340 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2341 - mean_squared_error: 0.04 - ETA: 5s - loss: 0.2340 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2340 - mean_squared_error: 0.04 - ETA: 4s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 3s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 2s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2343 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2343 - mean_squared_error: 0.04 - ETA: 1s - loss: 0.2342 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2341 - mean_squared_error: 0.04 - ETA: 0s - loss: 0.2341 - mean_squared_error: 0.04 - 52s 13ms/step - loss: 0.2341 - mean_squared_error: 0.0434 - val_loss: 0.2189 - val_mean_squared_error: 0.0380\n"
     ]
    }
   ],
   "source": [
    "for entity in result_final:\n",
    "    data=np.load('data_npy/full%2Fnumpy_bitmap%2F'+entity+'.npy')\n",
    "    data = data.reshape(-1, 28, 28, 1) / 255.0\n",
    "    X = data[:5000]\n",
    "    autoencoder.fit(X, X, \n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                epochs=10)\n",
    "    input_image = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last',\n",
    "           weights=autoencoder.layers[1].get_weights())(input_image)\n",
    "    x = MaxPooling2D((2, 2), padding='same', data_format='channels_last')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last',\n",
    "           weights=autoencoder.layers[4].get_weights())(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', data_format='channels_last')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last',\n",
    "           weights=autoencoder.layers[7].get_weights())(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', data_format='channels_last')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu',\n",
    "          weights=autoencoder.layers[10].get_weights())(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    encoded = Dense(encoding_size, activation='relu',\n",
    "          weights=autoencoder.layers[12].get_weights())(x)\n",
    "\n",
    "    encoder = Model(input_image, encoded)\n",
    "    latent_images = data.reshape(-1, 28, 28, 1)\n",
    "    Z= encoder.predict(latent_images)\n",
    "    ##Apply Kmeans\n",
    "    # Number of clusters\n",
    "    kmeans = KMeans(n_clusters=5)\n",
    "    # Fitting the input data\n",
    "    kmeans = kmeans.fit(Z)\n",
    "    # Getting the cluster labels\n",
    "    labels = kmeans.predict(Z)\n",
    "    # Centroid values\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    ##Decode\n",
    "    latent_vector = Input(shape=(32,))\n",
    "    y = Dense(64*7*7, activation='relu', \n",
    "          weights=autoencoder.layers[13].get_weights())(latent_vector)\n",
    "    y = Reshape((-1, 7, 7, 64)[1:])(y)\n",
    "    y = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "           weights=autoencoder.layers[16].get_weights())(y)\n",
    "    y = UpSampling2D((2, 2), data_format='channels_last')(y)\n",
    "    y = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "          weights=autoencoder.layers[18].get_weights())(y)\n",
    "    y = UpSampling2D((2, 2), data_format='channels_last')(y)\n",
    "    y = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "           weights=autoencoder.layers[20].get_weights())(y)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', data_format='channels_last', \n",
    "                 weights=autoencoder.layers[21].get_weights())(y)\n",
    "\n",
    "    decoder = Model(latent_vector, decoded)\n",
    "    strokes_decoded=decoder.predict(centroids)\n",
    "    lib_dict[entity] = strokes_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': array([[[[2.04363384e-11],\n",
       "          [1.27295525e-14],\n",
       "          [2.55106657e-16],\n",
       "          ...,\n",
       "          [6.03020292e-13],\n",
       "          [1.75641876e-10],\n",
       "          [4.01530578e-08]],\n",
       " \n",
       "         [[5.02509770e-11],\n",
       "          [3.46778487e-13],\n",
       "          [9.05178032e-14],\n",
       "          ...,\n",
       "          [1.38650766e-11],\n",
       "          [1.96561059e-10],\n",
       "          [2.32744490e-10]],\n",
       " \n",
       "         [[1.00888568e-11],\n",
       "          [5.77577959e-12],\n",
       "          [3.07689789e-12],\n",
       "          ...,\n",
       "          [1.76104117e-10],\n",
       "          [1.75823633e-09],\n",
       "          [2.06891587e-10]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.49486212e-09],\n",
       "          [5.72577610e-11],\n",
       "          [1.90213505e-11],\n",
       "          ...,\n",
       "          [8.74880238e-11],\n",
       "          [2.93954666e-10],\n",
       "          [4.00965199e-11]],\n",
       " \n",
       "         [[2.58472461e-08],\n",
       "          [1.42448178e-10],\n",
       "          [1.49440738e-11],\n",
       "          ...,\n",
       "          [2.40458931e-10],\n",
       "          [2.22951435e-09],\n",
       "          [2.91783508e-09]],\n",
       " \n",
       "         [[2.68023814e-06],\n",
       "          [1.67387249e-09],\n",
       "          [2.10293484e-11],\n",
       "          ...,\n",
       "          [3.36412287e-11],\n",
       "          [6.15269058e-10],\n",
       "          [1.52582995e-08]]],\n",
       " \n",
       " \n",
       "        [[[6.24005634e-06],\n",
       "          [1.52579275e-06],\n",
       "          [1.10566964e-06],\n",
       "          ...,\n",
       "          [4.40791791e-06],\n",
       "          [3.62216015e-05],\n",
       "          [2.57507549e-04]],\n",
       " \n",
       "         [[2.96800317e-06],\n",
       "          [9.32301282e-06],\n",
       "          [1.54306290e-05],\n",
       "          ...,\n",
       "          [1.00353252e-04],\n",
       "          [1.03817081e-04],\n",
       "          [1.81445903e-05]],\n",
       " \n",
       "         [[4.32772907e-07],\n",
       "          [2.12323775e-05],\n",
       "          [7.85547381e-05],\n",
       "          ...,\n",
       "          [1.11905253e-03],\n",
       "          [3.36226629e-04],\n",
       "          [1.02046215e-05]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.93382912e-05],\n",
       "          [1.66429909e-05],\n",
       "          [7.80382179e-05],\n",
       "          ...,\n",
       "          [1.33122012e-04],\n",
       "          [3.67088251e-05],\n",
       "          [4.18186914e-07]],\n",
       " \n",
       "         [[1.17540432e-04],\n",
       "          [2.38231769e-05],\n",
       "          [4.00417703e-05],\n",
       "          ...,\n",
       "          [5.87269096e-05],\n",
       "          [3.68017791e-05],\n",
       "          [3.23174936e-06]],\n",
       " \n",
       "         [[1.49563886e-03],\n",
       "          [7.33606794e-05],\n",
       "          [2.14357678e-05],\n",
       "          ...,\n",
       "          [6.44780675e-06],\n",
       "          [8.20063815e-06],\n",
       "          [1.06710986e-05]]],\n",
       " \n",
       " \n",
       "        [[[5.59841951e-08],\n",
       "          [2.84749402e-09],\n",
       "          [7.49944051e-10],\n",
       "          ...,\n",
       "          [1.76537535e-11],\n",
       "          [2.90214430e-09],\n",
       "          [2.79248979e-07]],\n",
       " \n",
       "         [[5.66526523e-08],\n",
       "          [8.41355714e-08],\n",
       "          [7.25035321e-08],\n",
       "          ...,\n",
       "          [7.41168307e-11],\n",
       "          [1.19347998e-09],\n",
       "          [1.72696735e-09]],\n",
       " \n",
       "         [[2.22039152e-08],\n",
       "          [7.30935710e-07],\n",
       "          [1.33218418e-06],\n",
       "          ...,\n",
       "          [3.03502778e-10],\n",
       "          [3.35052519e-09],\n",
       "          [5.22229815e-10]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.26659117e-07],\n",
       "          [3.44641613e-08],\n",
       "          [2.94830347e-08],\n",
       "          ...,\n",
       "          [1.26446812e-05],\n",
       "          [8.78244464e-06],\n",
       "          [3.33504403e-07]],\n",
       " \n",
       "         [[1.81068128e-06],\n",
       "          [7.78394025e-08],\n",
       "          [2.75028142e-08],\n",
       "          ...,\n",
       "          [3.45877856e-06],\n",
       "          [4.99590851e-06],\n",
       "          [1.65881045e-06]],\n",
       " \n",
       "         [[7.30907195e-05],\n",
       "          [5.27739076e-07],\n",
       "          [2.70046812e-08],\n",
       "          ...,\n",
       "          [2.92645126e-07],\n",
       "          [8.64651440e-07],\n",
       "          [3.28989404e-06]]],\n",
       " \n",
       " \n",
       "        [[[4.28861702e-09],\n",
       "          [1.17891070e-11],\n",
       "          [5.89620095e-13],\n",
       "          ...,\n",
       "          [6.13070572e-09],\n",
       "          [2.17810395e-07],\n",
       "          [9.54256120e-06]],\n",
       " \n",
       "         [[9.36289624e-09],\n",
       "          [1.45549198e-10],\n",
       "          [4.64197153e-11],\n",
       "          ...,\n",
       "          [6.32365868e-07],\n",
       "          [1.28126146e-06],\n",
       "          [5.33531306e-07]],\n",
       " \n",
       "         [[1.92380267e-09],\n",
       "          [1.06764531e-09],\n",
       "          [7.25320914e-10],\n",
       "          ...,\n",
       "          [1.12043899e-05],\n",
       "          [1.24640310e-05],\n",
       "          [7.52574010e-07]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.24269309e-06],\n",
       "          [3.51739914e-07],\n",
       "          [1.10229735e-06],\n",
       "          ...,\n",
       "          [2.83614954e-09],\n",
       "          [6.13340756e-09],\n",
       "          [7.22938431e-10]],\n",
       " \n",
       "         [[3.13124110e-06],\n",
       "          [1.62983653e-07],\n",
       "          [1.18227391e-07],\n",
       "          ...,\n",
       "          [7.08397696e-09],\n",
       "          [4.60557317e-08],\n",
       "          [3.84346457e-08]],\n",
       " \n",
       "         [[5.29300669e-05],\n",
       "          [2.76819407e-07],\n",
       "          [2.16306457e-08],\n",
       "          ...,\n",
       "          [1.04174236e-09],\n",
       "          [1.12519656e-08],\n",
       "          [1.64478436e-07]]],\n",
       " \n",
       " \n",
       "        [[[9.55700866e-11],\n",
       "          [4.95070619e-13],\n",
       "          [5.62746871e-14],\n",
       "          ...,\n",
       "          [2.62301794e-14],\n",
       "          [1.55880916e-11],\n",
       "          [1.23343193e-08]],\n",
       " \n",
       "         [[6.60873092e-11],\n",
       "          [8.62700363e-12],\n",
       "          [6.78879435e-12],\n",
       "          ...,\n",
       "          [7.80668846e-12],\n",
       "          [7.60825639e-11],\n",
       "          [9.75385328e-11]],\n",
       " \n",
       "         [[1.02220229e-11],\n",
       "          [1.24752736e-10],\n",
       "          [1.84575244e-10],\n",
       "          ...,\n",
       "          [3.87024524e-10],\n",
       "          [1.52649293e-09],\n",
       "          [1.48443396e-10]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.60411471e-08],\n",
       "          [1.21354460e-09],\n",
       "          [1.15267051e-09],\n",
       "          ...,\n",
       "          [1.41948930e-09],\n",
       "          [2.60148014e-09],\n",
       "          [1.38381084e-10]],\n",
       " \n",
       "         [[1.07595639e-07],\n",
       "          [1.11232901e-09],\n",
       "          [2.97387365e-10],\n",
       "          ...,\n",
       "          [4.93734220e-10],\n",
       "          [3.44616469e-09],\n",
       "          [2.78347434e-09]],\n",
       " \n",
       "         [[5.68530277e-06],\n",
       "          [4.68232964e-09],\n",
       "          [1.13039682e-10],\n",
       "          ...,\n",
       "          [3.54125999e-11],\n",
       "          [4.74761619e-10],\n",
       "          [9.32845712e-09]]]], dtype=float32),\n",
       " 'tree': array([[[[1.71729719e-09],\n",
       "          [7.48089299e-11],\n",
       "          [8.32307313e-12],\n",
       "          ...,\n",
       "          [9.04680150e-12],\n",
       "          [4.74702534e-11],\n",
       "          [1.46332425e-07]],\n",
       " \n",
       "         [[1.36726644e-10],\n",
       "          [2.68368522e-10],\n",
       "          [2.34751635e-10],\n",
       "          ...,\n",
       "          [5.64527203e-10],\n",
       "          [5.55639368e-10],\n",
       "          [1.61560398e-09]],\n",
       " \n",
       "         [[1.27150536e-12],\n",
       "          [2.31827377e-10],\n",
       "          [1.46914547e-09],\n",
       "          ...,\n",
       "          [8.32708658e-09],\n",
       "          [4.86112983e-10],\n",
       "          [3.39323347e-10]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.73876503e-11],\n",
       "          [1.82397841e-09],\n",
       "          [2.39571851e-09],\n",
       "          ...,\n",
       "          [1.28762041e-08],\n",
       "          [3.30272920e-09],\n",
       "          [8.28861335e-09]],\n",
       " \n",
       "         [[3.22754296e-10],\n",
       "          [1.16402274e-08],\n",
       "          [1.42796512e-08],\n",
       "          ...,\n",
       "          [4.37312941e-08],\n",
       "          [2.19610143e-08],\n",
       "          [2.74244286e-07]],\n",
       " \n",
       "         [[1.32516277e-07],\n",
       "          [3.00441272e-08],\n",
       "          [1.17419559e-08],\n",
       "          ...,\n",
       "          [2.67999845e-09],\n",
       "          [1.23216159e-09],\n",
       "          [2.97691276e-08]]],\n",
       " \n",
       " \n",
       "        [[[7.22950091e-08],\n",
       "          [3.15602144e-09],\n",
       "          [1.48678583e-10],\n",
       "          ...,\n",
       "          [3.63357846e-12],\n",
       "          [5.44957551e-11],\n",
       "          [6.47072568e-07]],\n",
       " \n",
       "         [[2.63780606e-08],\n",
       "          [3.35552812e-08],\n",
       "          [1.12381322e-08],\n",
       "          ...,\n",
       "          [3.55289853e-10],\n",
       "          [8.85587048e-10],\n",
       "          [4.35475869e-08]],\n",
       " \n",
       "         [[1.23897772e-08],\n",
       "          [2.34443633e-07],\n",
       "          [2.19323695e-07],\n",
       "          ...,\n",
       "          [5.21390087e-09],\n",
       "          [3.46312534e-09],\n",
       "          [6.93956039e-08]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.73608894e-05],\n",
       "          [1.29742621e-04],\n",
       "          [1.35968381e-04],\n",
       "          ...,\n",
       "          [1.89276034e-05],\n",
       "          [1.81542473e-05],\n",
       "          [3.82895705e-05]],\n",
       " \n",
       "         [[2.45482788e-05],\n",
       "          [7.27306397e-05],\n",
       "          [1.02445309e-04],\n",
       "          ...,\n",
       "          [1.69365903e-05],\n",
       "          [2.10276266e-05],\n",
       "          [1.03110076e-04]],\n",
       " \n",
       "         [[1.21799450e-04],\n",
       "          [2.62747726e-05],\n",
       "          [1.49580401e-05],\n",
       "          ...,\n",
       "          [5.95606537e-07],\n",
       "          [8.95145149e-07],\n",
       "          [1.16310775e-05]]],\n",
       " \n",
       " \n",
       "        [[[1.76365820e-08],\n",
       "          [9.61152602e-10],\n",
       "          [1.07446801e-10],\n",
       "          ...,\n",
       "          [1.40837758e-10],\n",
       "          [6.78173462e-10],\n",
       "          [8.74436694e-07]],\n",
       " \n",
       "         [[1.91068183e-09],\n",
       "          [2.17712004e-09],\n",
       "          [1.37665623e-09],\n",
       "          ...,\n",
       "          [2.76237189e-09],\n",
       "          [2.36282238e-09],\n",
       "          [7.28164284e-09]],\n",
       " \n",
       "         [[1.85013636e-11],\n",
       "          [1.01876985e-09],\n",
       "          [5.35077538e-09],\n",
       "          ...,\n",
       "          [1.86248865e-08],\n",
       "          [1.45384726e-09],\n",
       "          [1.06379949e-09]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.00655705e-08],\n",
       "          [7.34913920e-06],\n",
       "          [5.69714393e-05],\n",
       "          ...,\n",
       "          [4.86655044e-05],\n",
       "          [1.20814102e-05],\n",
       "          [3.45258513e-07]],\n",
       " \n",
       "         [[6.38871924e-08],\n",
       "          [4.34247750e-06],\n",
       "          [5.53416467e-05],\n",
       "          ...,\n",
       "          [3.29218055e-05],\n",
       "          [1.19240440e-05],\n",
       "          [2.02714705e-06]],\n",
       " \n",
       "         [[4.28358589e-06],\n",
       "          [1.89222658e-06],\n",
       "          [2.30288151e-06],\n",
       "          ...,\n",
       "          [8.31707268e-07],\n",
       "          [5.24044822e-07],\n",
       "          [1.06268658e-06]]],\n",
       " \n",
       " \n",
       "        [[[1.06417382e-07],\n",
       "          [8.04577471e-09],\n",
       "          [1.03147102e-09],\n",
       "          ...,\n",
       "          [3.91078905e-11],\n",
       "          [2.39327835e-10],\n",
       "          [8.55825874e-07]],\n",
       " \n",
       "         [[1.61862754e-08],\n",
       "          [4.33517648e-08],\n",
       "          [4.37172858e-08],\n",
       "          ...,\n",
       "          [6.28501562e-09],\n",
       "          [6.56338939e-09],\n",
       "          [2.72069816e-08]],\n",
       " \n",
       "         [[7.73361708e-10],\n",
       "          [7.93248489e-08],\n",
       "          [3.18062206e-07],\n",
       "          ...,\n",
       "          [2.65133508e-07],\n",
       "          [2.12296776e-08],\n",
       "          [2.23534897e-08]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[9.66385088e-08],\n",
       "          [5.90770333e-06],\n",
       "          [4.75727320e-05],\n",
       "          ...,\n",
       "          [8.16741252e-09],\n",
       "          [4.59927696e-09],\n",
       "          [6.22132887e-08]],\n",
       " \n",
       "         [[4.49692095e-07],\n",
       "          [5.04231411e-06],\n",
       "          [5.47029813e-05],\n",
       "          ...,\n",
       "          [1.61468670e-08],\n",
       "          [1.96463041e-08],\n",
       "          [5.72672889e-07]],\n",
       " \n",
       "         [[3.01078326e-05],\n",
       "          [8.43793077e-06],\n",
       "          [8.82878339e-06],\n",
       "          ...,\n",
       "          [2.20857527e-10],\n",
       "          [2.72049328e-10],\n",
       "          [1.36592284e-08]]],\n",
       " \n",
       " \n",
       "        [[[5.60996341e-07],\n",
       "          [6.32237516e-08],\n",
       "          [8.23809909e-09],\n",
       "          ...,\n",
       "          [2.14074802e-09],\n",
       "          [1.04371782e-08],\n",
       "          [9.40515201e-06]],\n",
       " \n",
       "         [[1.24622346e-07],\n",
       "          [7.43740998e-07],\n",
       "          [8.98840653e-07],\n",
       "          ...,\n",
       "          [2.04047097e-07],\n",
       "          [1.89088851e-07],\n",
       "          [5.94534015e-07]],\n",
       " \n",
       "         [[1.50526027e-08],\n",
       "          [2.36418646e-06],\n",
       "          [8.33909417e-06],\n",
       "          ...,\n",
       "          [1.22622914e-05],\n",
       "          [1.53983183e-06],\n",
       "          [1.23759810e-06]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.20992797e-06],\n",
       "          [4.23544370e-05],\n",
       "          [1.73933440e-04],\n",
       "          ...,\n",
       "          [8.02053983e-05],\n",
       "          [1.90279025e-05],\n",
       "          [8.07691958e-06]],\n",
       " \n",
       "         [[2.67655219e-06],\n",
       "          [3.16114820e-05],\n",
       "          [1.48512554e-04],\n",
       "          ...,\n",
       "          [7.47767408e-05],\n",
       "          [3.78297154e-05],\n",
       "          [5.16867040e-05]],\n",
       " \n",
       "         [[6.97861324e-05],\n",
       "          [2.99839649e-05],\n",
       "          [2.93131870e-05],\n",
       "          ...,\n",
       "          [5.52482425e-06],\n",
       "          [2.98639293e-06],\n",
       "          [1.59076189e-05]]]], dtype=float32)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the tree entity centroids and draw the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_centroids = lib_dict.get(\"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 28, 28, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save\n",
    "np.save('lib_dict.npy', lib_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.71729719e-09]\n",
      "   [7.48089299e-11]\n",
      "   [8.32307313e-12]\n",
      "   ...\n",
      "   [9.04680150e-12]\n",
      "   [4.74702534e-11]\n",
      "   [1.46332425e-07]]\n",
      "\n",
      "  [[1.36726644e-10]\n",
      "   [2.68368522e-10]\n",
      "   [2.34751635e-10]\n",
      "   ...\n",
      "   [5.64527203e-10]\n",
      "   [5.55639368e-10]\n",
      "   [1.61560398e-09]]\n",
      "\n",
      "  [[1.27150536e-12]\n",
      "   [2.31827377e-10]\n",
      "   [1.46914547e-09]\n",
      "   ...\n",
      "   [8.32708658e-09]\n",
      "   [4.86112983e-10]\n",
      "   [3.39323347e-10]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.73876503e-11]\n",
      "   [1.82397841e-09]\n",
      "   [2.39571851e-09]\n",
      "   ...\n",
      "   [1.28762041e-08]\n",
      "   [3.30272920e-09]\n",
      "   [8.28861335e-09]]\n",
      "\n",
      "  [[3.22754296e-10]\n",
      "   [1.16402274e-08]\n",
      "   [1.42796512e-08]\n",
      "   ...\n",
      "   [4.37312941e-08]\n",
      "   [2.19610143e-08]\n",
      "   [2.74244286e-07]]\n",
      "\n",
      "  [[1.32516277e-07]\n",
      "   [3.00441272e-08]\n",
      "   [1.17419559e-08]\n",
      "   ...\n",
      "   [2.67999845e-09]\n",
      "   [1.23216159e-09]\n",
      "   [2.97691276e-08]]]\n",
      "\n",
      "\n",
      " [[[7.22950091e-08]\n",
      "   [3.15602144e-09]\n",
      "   [1.48678583e-10]\n",
      "   ...\n",
      "   [3.63357846e-12]\n",
      "   [5.44957551e-11]\n",
      "   [6.47072568e-07]]\n",
      "\n",
      "  [[2.63780606e-08]\n",
      "   [3.35552812e-08]\n",
      "   [1.12381322e-08]\n",
      "   ...\n",
      "   [3.55289853e-10]\n",
      "   [8.85587048e-10]\n",
      "   [4.35475869e-08]]\n",
      "\n",
      "  [[1.23897772e-08]\n",
      "   [2.34443633e-07]\n",
      "   [2.19323695e-07]\n",
      "   ...\n",
      "   [5.21390087e-09]\n",
      "   [3.46312534e-09]\n",
      "   [6.93956039e-08]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.73608894e-05]\n",
      "   [1.29742621e-04]\n",
      "   [1.35968381e-04]\n",
      "   ...\n",
      "   [1.89276034e-05]\n",
      "   [1.81542473e-05]\n",
      "   [3.82895705e-05]]\n",
      "\n",
      "  [[2.45482788e-05]\n",
      "   [7.27306397e-05]\n",
      "   [1.02445309e-04]\n",
      "   ...\n",
      "   [1.69365903e-05]\n",
      "   [2.10276266e-05]\n",
      "   [1.03110076e-04]]\n",
      "\n",
      "  [[1.21799450e-04]\n",
      "   [2.62747726e-05]\n",
      "   [1.49580401e-05]\n",
      "   ...\n",
      "   [5.95606537e-07]\n",
      "   [8.95145149e-07]\n",
      "   [1.16310775e-05]]]\n",
      "\n",
      "\n",
      " [[[1.76365820e-08]\n",
      "   [9.61152602e-10]\n",
      "   [1.07446801e-10]\n",
      "   ...\n",
      "   [1.40837758e-10]\n",
      "   [6.78173462e-10]\n",
      "   [8.74436694e-07]]\n",
      "\n",
      "  [[1.91068183e-09]\n",
      "   [2.17712004e-09]\n",
      "   [1.37665623e-09]\n",
      "   ...\n",
      "   [2.76237189e-09]\n",
      "   [2.36282238e-09]\n",
      "   [7.28164284e-09]]\n",
      "\n",
      "  [[1.85013636e-11]\n",
      "   [1.01876985e-09]\n",
      "   [5.35077538e-09]\n",
      "   ...\n",
      "   [1.86248865e-08]\n",
      "   [1.45384726e-09]\n",
      "   [1.06379949e-09]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.00655705e-08]\n",
      "   [7.34913920e-06]\n",
      "   [5.69714393e-05]\n",
      "   ...\n",
      "   [4.86655044e-05]\n",
      "   [1.20814102e-05]\n",
      "   [3.45258513e-07]]\n",
      "\n",
      "  [[6.38871924e-08]\n",
      "   [4.34247750e-06]\n",
      "   [5.53416467e-05]\n",
      "   ...\n",
      "   [3.29218055e-05]\n",
      "   [1.19240440e-05]\n",
      "   [2.02714705e-06]]\n",
      "\n",
      "  [[4.28358589e-06]\n",
      "   [1.89222658e-06]\n",
      "   [2.30288151e-06]\n",
      "   ...\n",
      "   [8.31707268e-07]\n",
      "   [5.24044822e-07]\n",
      "   [1.06268658e-06]]]\n",
      "\n",
      "\n",
      " [[[1.06417382e-07]\n",
      "   [8.04577471e-09]\n",
      "   [1.03147102e-09]\n",
      "   ...\n",
      "   [3.91078905e-11]\n",
      "   [2.39327835e-10]\n",
      "   [8.55825874e-07]]\n",
      "\n",
      "  [[1.61862754e-08]\n",
      "   [4.33517648e-08]\n",
      "   [4.37172858e-08]\n",
      "   ...\n",
      "   [6.28501562e-09]\n",
      "   [6.56338939e-09]\n",
      "   [2.72069816e-08]]\n",
      "\n",
      "  [[7.73361708e-10]\n",
      "   [7.93248489e-08]\n",
      "   [3.18062206e-07]\n",
      "   ...\n",
      "   [2.65133508e-07]\n",
      "   [2.12296776e-08]\n",
      "   [2.23534897e-08]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.66385088e-08]\n",
      "   [5.90770333e-06]\n",
      "   [4.75727320e-05]\n",
      "   ...\n",
      "   [8.16741252e-09]\n",
      "   [4.59927696e-09]\n",
      "   [6.22132887e-08]]\n",
      "\n",
      "  [[4.49692095e-07]\n",
      "   [5.04231411e-06]\n",
      "   [5.47029813e-05]\n",
      "   ...\n",
      "   [1.61468670e-08]\n",
      "   [1.96463041e-08]\n",
      "   [5.72672889e-07]]\n",
      "\n",
      "  [[3.01078326e-05]\n",
      "   [8.43793077e-06]\n",
      "   [8.82878339e-06]\n",
      "   ...\n",
      "   [2.20857527e-10]\n",
      "   [2.72049328e-10]\n",
      "   [1.36592284e-08]]]\n",
      "\n",
      "\n",
      " [[[5.60996341e-07]\n",
      "   [6.32237516e-08]\n",
      "   [8.23809909e-09]\n",
      "   ...\n",
      "   [2.14074802e-09]\n",
      "   [1.04371782e-08]\n",
      "   [9.40515201e-06]]\n",
      "\n",
      "  [[1.24622346e-07]\n",
      "   [7.43740998e-07]\n",
      "   [8.98840653e-07]\n",
      "   ...\n",
      "   [2.04047097e-07]\n",
      "   [1.89088851e-07]\n",
      "   [5.94534015e-07]]\n",
      "\n",
      "  [[1.50526027e-08]\n",
      "   [2.36418646e-06]\n",
      "   [8.33909417e-06]\n",
      "   ...\n",
      "   [1.22622914e-05]\n",
      "   [1.53983183e-06]\n",
      "   [1.23759810e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.20992797e-06]\n",
      "   [4.23544370e-05]\n",
      "   [1.73933440e-04]\n",
      "   ...\n",
      "   [8.02053983e-05]\n",
      "   [1.90279025e-05]\n",
      "   [8.07691958e-06]]\n",
      "\n",
      "  [[2.67655219e-06]\n",
      "   [3.16114820e-05]\n",
      "   [1.48512554e-04]\n",
      "   ...\n",
      "   [7.47767408e-05]\n",
      "   [3.78297154e-05]\n",
      "   [5.16867040e-05]]\n",
      "\n",
      "  [[6.97861324e-05]\n",
      "   [2.99839649e-05]\n",
      "   [2.93131870e-05]\n",
      "   ...\n",
      "   [5.52482425e-06]\n",
      "   [2.98639293e-06]\n",
      "   [1.59076189e-05]]]]\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "read_dictionary = np.load('lib_dict.npy').item()\n",
    "print(read_dictionary['tree']) # displays \"world\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
